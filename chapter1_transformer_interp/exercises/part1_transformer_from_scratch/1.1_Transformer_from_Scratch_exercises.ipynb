{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOTUIxASCS_4"
      },
      "source": [
        "# [1.1] - Transformers from scratch (exercises)\n",
        "\n",
        "> **ARENA [Streamlit Page](https://arena-chapter1-transformer-interp.streamlit.app/01_[1.1]_Transformer_from_Scratch)**\n",
        ">\n",
        "> **Colab: [exercises](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter1_transformer_interp/exercises/part1_transformer_from_scratch/1.1_Transformer_from_Scratch_exercises.ipynb?t=20250915) | [solutions](https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter1_transformer_interp/exercises/part1_transformer_from_scratch/1.1_Transformer_from_Scratch_solutions.ipynb?t=20250915)**\n",
        "\n",
        "Please send any problems / bugs on the `#errata` channel in the [Slack group](https://join.slack.com/t/arena-uk/shared_invite/zt-3afdmdhye-Mdb3Sv~ss_V_mEaXEbkABA), and ask any questions on the dedicated channels for this chapter of material.\n",
        "\n",
        "You can collapse each section so only the headers are visible, by clicking the arrow symbol on the left hand side of the markdown header cells.\n",
        "\n",
        "Links to all other chapters: [(0) Fundamentals](https://arena-chapter0-fundamentals.streamlit.app/), [(1) Transformer Interpretability](https://arena-chapter1-transformer-interp.streamlit.app/), [(2) RL](https://arena-chapter2-rl.streamlit.app/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MGQTUs8CS_5"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/headers/header-11.png\" width=\"350\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw9_0QHKCS_5"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3JH5GmOCS_5"
      },
      "source": [
        "This is a clean, first principles implementation of GPT-2 in PyTorch. The architectural choices closely follow those used by the TransformerLens library (which you'll be using a lot more in later exercises).\n",
        "\n",
        "The exercises are written to accompany Neel Nanda's [TransformerLens library](https://github.com/neelnanda-io/TransformerLens) for doing mechanistic interpretability research on GPT-2 style language models. We'll be working with this library extensively in this chapter of the course.\n",
        "\n",
        "Each exercise will have a difficulty and importance rating out of 5, as well as an estimated maximum time you should spend on these exercises and sometimes a short annotation. You should interpret the ratings & time estimates relatively (e.g. if you find yourself spending about 50% longer on the exercises than the time estimates, adjust accordingly). Please do skip exercises / look at solutions if you don't feel like they're important enough to be worth doing, and you'd rather get to the good stuff!\n",
        "\n",
        "For a lecture on the material today, which provides some high-level understanding before you dive into the material, watch the video below:\n",
        "\n",
        "<iframe width=\"540\" height=\"304\" src=\"https://www.youtube.com/embed/11Z50mi8dSg\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZSWBTFOCS_5"
      },
      "source": [
        "## Content & Learning Objectives\n",
        "\n",
        "### 1️⃣ Understanding Inputs & Outputs of a Transformer\n",
        "\n",
        "In this section, we'll take a first look at transformers - what their function is, how information moves inside a transformer, and what inputs & outputs they take.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand what a transformer is used for\n",
        "> - Understand causal attention, and what a transformer's output represents—algebra operations on tensors\n",
        "> - Learn what tokenization is, and how models do it\n",
        "> - Understand what logits are, and how to use them to derive a probability distribution over the vocabulary\n",
        "\n",
        "### 2️⃣ Clean Transformer Implementation\n",
        "\n",
        "Here, we'll implement a transformer from scratch, using only PyTorch's tensor operations. This will give us a good understanding of how transformers work, and how to use them. We do this by going module-by-module, in an experience which should feel somewhat similar to last week's ResNet exercises. Much like with ResNets, you'll conclude by loading in pretrained weights and verifying that your model works as expected.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand that a transformer is composed of attention heads and MLPs, with each one performing operations on the residual stream\n",
        "> * Understand that the attention heads in a single layer operate independently, and that they have the role of calculating attention patterns (which determine where information is moved to & from in the residual stream)\n",
        "> * Learn about & implement the following transformer modules:\n",
        ">     * LayerNorm (transforming the input to have zero mean and unit variance)\n",
        ">     * Positional embedding (a lookup table from position indices to residual stream vectors)\n",
        ">     * Attention (the method of computing attention patterns for residual stream vectors)\n",
        ">     * MLP (the collection of linear and nonlinear transformations which operate on each residual stream vector in the same way)\n",
        ">     * Embedding (a lookup table from tokens to residual stream vectors)\n",
        ">     * Unembedding (a matrix for converting residual stream vectors into a distribution over tokens)\n",
        "\n",
        "### 3️⃣ Training a Transformer\n",
        "\n",
        "Next, you'll learn how to train your transformer from scratch. This will be quite similar to the training loops you wrote for ResNet in your first week.\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand how to train a transformer from scratch\n",
        "> * Write a basic transformer training loop\n",
        "> * Interpret the transformer's falling cross entropy loss with reference to features of the training data (e.g. bigram frequencies)\n",
        "\n",
        "### 4️⃣ Sampling from a Transformer\n",
        "\n",
        "Lastly, you'll learn how to sample from a transformer. This will involve implementing a few different sampling methods, and writing a caching system which can reuse computations from previous forward passes to improve your model's text generation speed.\n",
        "\n",
        "*The second half of this section is less important, and you can skip it if you want.*\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn how to sample from a transformer\n",
        ">     * This includes basic methods like greedy search or top-k, and more advanced methods like beam search\n",
        "> * Learn how to cache the output of a transformer, so that it can be used to generate text more efficiently\n",
        ">     * Optionally, rewrite your sampling functions to make use of your caching methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb1QtWnjCS_6"
      },
      "source": [
        "## Setup code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyfLUDH7CS_6",
        "outputId": "e61a939c-3f10-4c8d-a145-38b36e9ee07b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-11 17:57:29--  https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/callummcdougall/ARENA_3.0/zip/refs/heads/main [following]\n",
            "--2026-01-11 17:57:29--  https://codeload.github.com/callummcdougall/ARENA_3.0/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.116.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.116.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/content/main.zip’\n",
            "\n",
            "main.zip                [         <=>        ]  21.33M  9.18MB/s    in 2.3s    \n",
            "\n",
            "2026-01-11 17:57:32 (9.18 MB/s) - ‘/content/main.zip’ saved [22370918]\n",
            "\n",
            "Archive:  /content/main.zip\n",
            "efbe1d35bdf3655bb5224f61993d3d217fa2e3c2\n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/\n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/\n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/august23_unique_char/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/august23_unique_char/dataset.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/august23_unique_char/first_unique_char_model.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/august23_unique_char/model.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/august23_unique_char/training.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/august23_unique_char/training_model.ipynb  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/caesar_cipher_model_easy.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/caesar_cipher_model_hard.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/caesar_cipher_model_medium.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/dataset.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/hitchhikers.txt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/model.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/training.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/training_model.ipynb  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/july23_palindromes/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/july23_palindromes/dataset.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/july23_palindromes/model.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/july23_palindromes/palindrome_classifier.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/july23_palindromes/training.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/july23_palindromes/training_model.ipynb  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november23_cumsum/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november23_cumsum/cumsum_model.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november23_cumsum/dataset.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november23_cumsum/model.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november23_cumsum/training.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november23_cumsum/training_model.ipynb  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november24_trigrams/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november24_trigrams/dataset.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november24_trigrams/model.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november24_trigrams/test_dataset.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november24_trigrams/training.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november24_trigrams/training_model.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november24_trigrams/trigram_model.pt  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/october23_sorted_list/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/october23_sorted_list/dataset.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/october23_sorted_list/model.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/october23_sorted_list/sorted_list_model.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/october23_sorted_list/training.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/october23_sorted_list/training_model.ipynb  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/september23_sum/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/september23_sum/dataset.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/september23_sum/model.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/september23_sum/sum_model.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/september23_sum/training.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/september23_sum/training_model.ipynb  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part1_transformer_from_scratch/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part1_transformer_from_scratch/1.1_Transformer_from_Scratch_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part1_transformer_from_scratch/1.1_Transformer_from_Scratch_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part1_transformer_from_scratch/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part1_transformer_from_scratch/tests.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part2_intro_to_mech_interp/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part2_intro_to_mech_interp/1.2_Intro_to_Mech_Interp_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part2_intro_to_mech_interp/1.2_Intro_to_Mech_Interp_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part2_intro_to_mech_interp/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part2_intro_to_mech_interp/tests.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part31_superposition_and_saes/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part31_superposition_and_saes/1.3.1_Toy_Models_of_Superposition_&_SAEs_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part31_superposition_and_saes/1.3.1_Toy_Models_of_Superposition_&_SAEs_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part31_superposition_and_saes/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part31_superposition_and_saes/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part31_superposition_and_saes/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part32_interp_with_saes/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part32_interp_with_saes/1.3.2_Interpretability_with_SAEs_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part32_interp_with_saes/1.3.2_Interpretability_with_SAEs_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part32_interp_with_saes/solutions.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part41_indirect_object_identification/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part41_indirect_object_identification/1.4.1_Indirect_Object_Identification_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part41_indirect_object_identification/1.4.1_Indirect_Object_Identification_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part41_indirect_object_identification/ioi_circuit_extraction.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part41_indirect_object_identification/ioi_dataset.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part41_indirect_object_identification/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part41_indirect_object_identification/tests.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/1.4.2_Function_Vectors_&_Model_Steering_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/1.4.2_Function_Vectors_&_Model_Steering_solutions.ipynb  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/data/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/data/antonym_pairs.txt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/data/country_capital_pairs.txt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/data/test_fn_vector.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/data/test_fn_vector_1.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/data/test_fn_vector_2.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/data/test_h.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/tests.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part51_balanced_bracket_classifier/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part51_balanced_bracket_classifier/1.5.1_Balanced_Bracket_Classifier_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part51_balanced_bracket_classifier/1.5.1_Balanced_Bracket_Classifier_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part51_balanced_bracket_classifier/brackets_data.json  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part51_balanced_bracket_classifier/brackets_datasets.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part51_balanced_bracket_classifier/brackets_model_state_dict.pt  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part51_balanced_bracket_classifier/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part51_balanced_bracket_classifier/tests.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part52_grokking_and_modular_arithmetic/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part52_grokking_and_modular_arithmetic/1.5.2_Grokking_&_Modular_Arithmetic_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part52_grokking_and_modular_arithmetic/1.5.2_Grokking_&_Modular_Arithmetic_solutions.ipynb  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part52_grokking_and_modular_arithmetic/Grokking/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part52_grokking_and_modular_arithmetic/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part52_grokking_and_modular_arithmetic/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part52_grokking_and_modular_arithmetic/utils.py  \n",
            "   creating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part53_othellogpt/\n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part53_othellogpt/1.5.3_OthelloGPT_exercises.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part53_othellogpt/1.5.3_OthelloGPT_solutions.ipynb  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part53_othellogpt/board_seqs_id_small.npy  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part53_othellogpt/board_seqs_square_small.npy  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part53_othellogpt/main_linear_probe.pth  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part53_othellogpt/solutions.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part53_othellogpt/tests.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/part53_othellogpt/utils.py  \n",
            "  inflating: /content/ARENA_3.0-main/chapter1_transformer_interp/exercises/plotly_utils.py  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "chapter = \"chapter1_transformer_interp\"\n",
        "repo = \"ARENA_3.0\"\n",
        "branch = \"main\"\n",
        "\n",
        "# Install dependencies\n",
        "try:\n",
        "    import transformer_lens\n",
        "except:\n",
        "    %pip install transformer_lens==2.11.0 einops jaxtyping git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
        "\n",
        "# Get root directory, handling 3 different cases: (1) Colab, (2) notebook not in ARENA repo, (3) notebook in ARENA repo\n",
        "root = (\n",
        "    \"/content\"\n",
        "    if IN_COLAB\n",
        "    else \"/root\"\n",
        "    if repo not in os.getcwd()\n",
        "    else str(next(p for p in Path.cwd().parents if p.name == repo))\n",
        ")\n",
        "\n",
        "if Path(root).exists() and not Path(f\"{root}/{chapter}\").exists():\n",
        "    if not IN_COLAB:\n",
        "        !sudo apt-get install unzip\n",
        "        %pip install jupyter ipython --upgrade\n",
        "\n",
        "    if not os.path.exists(f\"{root}/{chapter}\"):\n",
        "        !wget -P {root} https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/{branch}.zip\n",
        "        !unzip {root}/{branch}.zip '{repo}-{branch}/{chapter}/exercises/*' -d {root}\n",
        "        !mv {root}/{repo}-{branch}/{chapter} {root}/{chapter}\n",
        "        !rm {root}/{branch}.zip\n",
        "        !rmdir {root}/ARENA_3.0-{branch}\n",
        "\n",
        "\n",
        "if f\"{root}/{chapter}/exercises\" not in sys.path:\n",
        "    sys.path.append(f\"{root}/{chapter}/exercises\")\n",
        "\n",
        "os.chdir(f\"{root}/{chapter}/exercises\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4OlK-fcfCS_6"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import sys\n",
        "from collections import defaultdict\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Callable\n",
        "\n",
        "import datasets\n",
        "import einops\n",
        "import numpy as np\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "from jaxtyping import Float, Int\n",
        "from rich import print as rprint\n",
        "from rich.table import Table\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "from transformer_lens import HookedTransformer\n",
        "from transformer_lens.utils import gelu_new, tokenize_and_concatenate\n",
        "from transformers.models.gpt2.tokenization_gpt2_fast import GPT2TokenizerFast\n",
        "\n",
        "device = t.device(\n",
        "    \"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Make sure exercises are in the path\n",
        "chapter = \"chapter1_transformer_interp\"\n",
        "section = \"part1_transformer_from_scratch\"\n",
        "root_dir = next(p for p in Path.cwd().parents if (p / chapter).exists())\n",
        "exercises_dir = root_dir / chapter / \"exercises\"\n",
        "section_dir = exercises_dir / section\n",
        "\n",
        "import part1_transformer_from_scratch.solutions as solutions\n",
        "import part1_transformer_from_scratch.tests as tests\n",
        "from plotly_utils import imshow\n",
        "\n",
        "MAIN = __name__ == \"__main__\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxAndu9CCS_6"
      },
      "source": [
        "# 1️⃣ Understanding Inputs & Outputs of a Transformer\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> - Understand what a transformer is used for\n",
        "> - Understand causal attention, and what a transformer's output represents—algebra operations on tensors\n",
        "> - Learn what tokenization is, and how models do it\n",
        "> - Understand what logits are, and how to use them to derive a probability distribution over the vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ApI-h4ECS_6"
      },
      "source": [
        "## What is the point of a transformer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiR5x-CKCS_7"
      },
      "source": [
        "**Transformers exist to model text!**\n",
        "\n",
        "We're going to focus GPT-2 style transformers. Key feature: They generate text! You feed in language, and the model generates a probability distribution over tokens. And you can repeatedly sample from this to generate text!\n",
        "\n",
        "(To explain this in more detail - you feed in a sequence of length $N$, then sample from the probability distribution over the $N+1$-th word, use this to construct a new sequence of length $N+1$, then feed this new sequence into the model to get a probability distribution over the $N+2$-th word, and so on.)\n",
        "\n",
        "### How is the model trained?\n",
        "\n",
        "You give it a bunch of text, and train it to predict the next token.\n",
        "\n",
        "Importantly, if you give a model 100 tokens in a sequence, it predicts the next token for *each* prefix, i.e. it produces 100 logit vectors (= probability distributions) over the set of all words in our vocabulary, with the `i`-th logit vector representing the probability distribution over the token *following* the `i`-th token in the sequence. This is a key part of what allows transformers to be trained so efficiently; for every sequence of length $n$ we get $n$ different predictions to train on:\n",
        "\n",
        "$$\n",
        "p(x_1), \\; p(x_2|x_1), \\; p(x_3|x_1x_2), \\; \\ldots, \\; p(x_n|x_1 \\ldots x_{n-1})\n",
        "$$\n",
        "\n",
        "<details>\n",
        "<summary>Aside - logits</summary>\n",
        "\n",
        "If you haven't encountered the term \"logits\" before, here's a quick refresher.\n",
        "\n",
        "Given an arbitrary vector $x$, we can turn it into a probability distribution via the **softmax** function: $x_i \\to \\frac{e^{x_i}}{\\sum e^{x_j}}$. The exponential makes everything positive; the normalization makes it add to one.\n",
        "\n",
        "The model's output is the vector $x$ (one for each prediction it makes). We call this vector a logit because it represents a probability distribution, and it is related to the actual probabilities via the softmax function.\n",
        "</details>\n",
        "\n",
        "How do we stop the transformer by \"cheating\" by just looking at the tokens it's trying to predict? Answer - we make the transformer have *causal attention* (as opposed to *bidirectional attention*). Causal attention only allows information to move forwards in the sequence, never backwards. The prediction of what comes after token 50 is only a function of the first 50 tokens, *not* of token 51. We say the transformer is **autoregressive**, because it only predicts future words based on past data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw14JFhQCS_7"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/transformer-overview-new.png\" width=\"900\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YafqxyHUCS_7"
      },
      "source": [
        "Another way to view this is through the following analogy: we have a series of people standing in a line, each with one word or chunk of the sentence. Each person has the ability to look up information from the people behind them (we'll explore how this works in later sections) but they can't look at any information in front of them. Their goal is to guess what word the person in front of them is holding.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/intro-image-v2.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YqZuNZsCS_7"
      },
      "source": [
        "## Tokens - Transformer Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALKpxQ-aCS_7"
      },
      "source": [
        "Our tranformer's input is natural language (i.e. a sequence of characters, strings, etc). But ML models generally take vectors as input, not language. How do we convert language to vectors?\n",
        "\n",
        "We can factor this into 2 questions:\n",
        "\n",
        "1. How do we split up language into small sub-units?\n",
        "2. How do we convert these sub-units into vectors?\n",
        "\n",
        "Let's start with the second of these questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PiAtUtLCS_7"
      },
      "source": [
        "### Converting sub-units to vectors\n",
        "\n",
        "We basically make a massive lookup table, which is called an **embedding**. It has one vector for each possible sub-unit of language we might get (we call this set of all sub-units our **vocabulary**). We label every element in our vocabulary with an integer (this labelling never changes), and we use this integer to index into the embedding.\n",
        "\n",
        "A key intuition is that one-hot encodings let you think about each integer independently. We don't bake in any relation between words when we perform our embedding, because every word has a completely separate embedding vector.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - one-hot encodings</summary>\n",
        "\n",
        "We sometimes think about **one-hot encodings** of words. These are vectors with zeros everywhere, except for a single one in the position corresponding to the word's index in the vocabulary. This means that indexing into the embedding is equivalent to multiplying the **embedding matrix** by the one-hot encoding (where the embedding matrix is the matrix we get by stacking all the embedding vectors on top of each other).\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "W_E &= \\begin{bmatrix}\n",
        "\\leftarrow v_0 \\rightarrow \\\\\n",
        "\\leftarrow v_1 \\rightarrow \\\\\n",
        "\\vdots \\\\\n",
        "\\leftarrow v_{d_{vocab}-1} \\rightarrow \\\\\n",
        "\\end{bmatrix} \\quad \\text{is the embedding matrix (size }d_{vocab} \\times d_{embed}\\text{),} \\\\\n",
        "\\\\\n",
        "t_i &= (0, \\dots, 0, 1, 0, \\dots, 0) \\quad \\text{is the one-hot encoding for the }i\\text{th word (length }d_{vocab}\\text{)} \\\\\n",
        "\\\\\n",
        "v_i &= t_i W_E \\quad \\text{is the embedding vector for the }i\\text{th word (length }d_{embed}\\text{).} \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "</details>\n",
        "\n",
        "Now, let's answer the first question - how do we split language into sub-units?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72BTET5kCS_7"
      },
      "source": [
        "### Splitting language into sub-units\n",
        "\n",
        "We need to define a standard way of splitting up language into a series of substrings, where each substring is a member of our **vocabulary** set.\n",
        "\n",
        "Could we use a dictionary, and have our vocabulary be the set of all words in the dictionary? No, because this couldn't handle arbitrary text (e.g. URLs, punctuation, etc). We need a more general way of splitting up language.\n",
        "\n",
        "Could we just use the 256 ASCII characters? This fixes the previous problem, but it loses structure of language - some sequences of characters are more meaningful than others. For example, \"language\" is a lot more meaningful than \"hjksdfiu\". We want \"language\" to be a single token, but not \"hjksdfiu\" - this is a more efficient use of our vocab.\n",
        "\n",
        "What actually happens? The most common strategy is called **Byte-Pair encodings**.\n",
        "\n",
        "We begin with the 256 ASCII characters as our tokens, and then find the most common pair of tokens, and merge that into a new token. Note that we do have a space character as one of our 256 tokens, and merges using space are very common. For instance, here are the five first merges for the tokenizer used by GPT-2 (you'll be able to verify this below).\n",
        "\n",
        "```\n",
        "\" t\"\n",
        "\" a\"\n",
        "\"he\"\n",
        "\"in\"\n",
        "\"re\"\n",
        "```\n",
        "\n",
        "Note - you might see the character `Ġ` in front of some tokens. This is a special token that indicates that the token begins with a space. Tokens with a leading space vs not are different.\n",
        "\n",
        "You can run the code below to load in the `gpt2-small` model, and see more of its tokenizer's vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404,
          "referenced_widgets": [
            "bd34097c7e1f44f98b4d9676ce4d8f33",
            "f3b56bd754794086a2d0df6fefe51213",
            "777bcd125ec64cc0aa4c2c4401442abd",
            "f2011c34faa3424bb5258803d801bbcd",
            "50d4e18241c94094802473aecca76540",
            "39fa5aa5df934cdc826ba753d5b171a0",
            "a22b2453f95c4cf6abd1361ca86430cf",
            "272d8410497a47db8f6ed6c6913a49f8",
            "4f164cb24ed94c968274e85f2ddc07d6",
            "f3d3f2fc8f6f4b85bd2d8058506c3f9f",
            "ea2f641c5f534744a36ba622e8e9a6f3",
            "af63e596459f45e0b0bfbf23b6b4328c",
            "3807997e73a845948c60e7f22e5ad72d",
            "baba64560f214107bc58fc18fe4f029b",
            "2a9c9a8aee4a4dfcaa37f5697da5e9a8",
            "46c6e4121d2b45dcb832314a5d2090f2",
            "be06f5e89cb64217a87a3afab42a8040",
            "15e6c1af22a04211b5a627dfc90999f2",
            "1941756833c44975a9ce00fdd6e4882b",
            "0c2eb2c1da9d4e11aeaf8675e39a068f",
            "1796509e245648f792c2018a27c7637f",
            "ca0fa30e53c14e35bda326b0a0718974",
            "3dd02f76ae2d4bb5a16208aaa0771f9a",
            "cce6aaefee26498bae26caab88a8f1d1",
            "e4a4ddc71a88462da0aac1467f55572c",
            "d707315f104b47a69268f10be6a51c22",
            "d3f6d60f1ef04d7faf074d0b31126195",
            "21507ec5fb8c4a1fbc9441d62f62b602",
            "74096fb579dc45ec9c170f7255cfcb30",
            "9b5b68b99dfb4e089dc5b418c0e338c6",
            "c3214494b92d45d5b337c89fb1e721d9",
            "49455aecfcd545bcb3c7ec8daa0933da",
            "0427733a44564250943e2bf8a8ed0a1a",
            "901c2c953d5a4fdf9e92e713f1f2212a",
            "11187632b06547399c14e536623d8a5d",
            "c5017760ba1c4fc3bdda265257bf5d34",
            "b9e3d66ba20143568ef7c3fc1b86d23f",
            "b38d773c70994cc18cbe8389fa647fcc",
            "896c745cf1fb414c8eaf1a85b65528dc",
            "58ed304c2bc1445e8966dd5d315947a0",
            "5e5ab8e607144e1499aa3a7f97c7895f",
            "76ab5334a61440b888107e8a122ed1bf",
            "9dfeb227fc784479bff29705c507e295",
            "2a1881400874421d82ff8e32c56bba36",
            "fa8c668513a249f88b5e974421dfb4c2",
            "3de1a626f3e94c7ba42aa097b522816d",
            "23c34a8176ef4a9facbc1ff173970776",
            "69994edc2bda483084748e1bde6f89f9",
            "75909de0d1ad4b5885b55c330f7a68ca",
            "5ae72e10be834e879bf62b46269a1194",
            "7c33e871ee9240a5a5b6509c22b014c0",
            "1b9d354cdbb3445e97f9ded5b959cac7",
            "3116caed58134e72a8eb7481742cd7b1",
            "798713949601459e8bc5adf3d6577e26",
            "30c17afc26dd41a694dc6e905a1a36ec",
            "fb81a0de815742248bb2e7780a58ec87",
            "073b0c9473c847daa80fbac111b2724e",
            "c9e938b17d864088bf2c1bdfd27ae0df",
            "938f758f859648babd178745435ccdcf",
            "bc6e384601f84921a83c7bfba432c350",
            "e1c97e3df9d7457aaef2ca9baa9bdc2b",
            "08bb11ac87f241318786014e28eeb4fc",
            "4fd7db5fa768425490f09dfe44a2816b",
            "d72e7c3480684d4dadf0637d5755ad3c",
            "e8ee9c7b8ec240ecb0320e2900660d6c",
            "3f05504c5e5a4ff6b21ded0ee431d287",
            "93d1163d036043d9b5f2d04f8c6c9fe2",
            "d782a3f1b092467d9db7e718a54d8d8d",
            "c7f170701f5444afb719e71625f1d021",
            "64d81c414fb4413ca4c8a8d97fdd02fe",
            "974676de89244458b320004e150a6b2d",
            "49300a6622814723a327de8ec48ee4a7",
            "fa3ec4af481648118660c7f2904c9e38",
            "7cc3cf9884d547a393296c748c194edd",
            "8b1c6ec1634a493994fa45020a11a03f",
            "c4ef574c56574b148e6166c65f2dd99e",
            "f8f8eafa80b047739b927abec73826f8"
          ]
        },
        "id": "0ZkX4q4pCS_7",
        "outputId": "9b6c47f5-d85d-430c-ca8f-20bb1122347b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd34097c7e1f44f98b4d9676ce4d8f33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af63e596459f45e0b0bfbf23b6b4328c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dd02f76ae2d4bb5a16208aaa0771f9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "901c2c953d5a4fdf9e92e713f1f2212a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa8c668513a249f88b5e974421dfb4c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb81a0de815742248bb2e7780a58ec87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93d1163d036043d9b5f2d04f8c6c9fe2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n",
            "[('!', 0), ('\"', 1), ('#', 2), ('$', 3), ('%', 4), ('&', 5), (\"'\", 6), ('(', 7), (')', 8), ('*', 9), ('+', 10), (',', 11), ('-', 12), ('.', 13), ('/', 14), ('0', 15), ('1', 16), ('2', 17), ('3', 18), ('4', 19)]\n",
            "\n",
            "[('ľ', 250), ('Ŀ', 251), ('ŀ', 252), ('Ł', 253), ('ł', 254), ('Ń', 255), ('Ġt', 256), ('Ġa', 257), ('he', 258), ('in', 259), ('re', 260), ('on', 261), ('Ġthe', 262), ('er', 263), ('Ġs', 264), ('at', 265), ('Ġw', 266), ('Ġo', 267), ('en', 268), ('Ġc', 269)]\n",
            "\n",
            "[('Ġprodu', 990), ('Ġstill', 991), ('led', 992), ('ah', 993), ('Ġhere', 994), ('Ġworld', 995), ('Ġthough', 996), ('Ġnum', 997), ('arch', 998), ('imes', 999), ('ale', 1000), ('ĠSe', 1001), ('ĠIf', 1002), ('//', 1003), ('ĠLe', 1004), ('Ġret', 1005), ('Ġref', 1006), ('Ġtrans', 1007), ('ner', 1008), ('ution', 1009)]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "reference_gpt2 = HookedTransformer.from_pretrained(\n",
        "    \"gpt2-small\",\n",
        "    fold_ln=False,\n",
        "    center_unembed=False,\n",
        "    center_writing_weights=False,  # you'll learn about these arguments later!\n",
        ")\n",
        "\n",
        "sorted_vocab = sorted(list(reference_gpt2.tokenizer.vocab.items()), key=lambda n: n[1])\n",
        "\n",
        "print(sorted_vocab[:20])\n",
        "print()\n",
        "print(sorted_vocab[250:270])\n",
        "print()\n",
        "print(sorted_vocab[990:1010])\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCNBe2vGCS_7"
      },
      "source": [
        "As you get to the end of the vocabulary, you'll be producing some pretty weird-looking esoteric tokens (because you'll already have exhausted all of the short frequently-occurring ones):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdC2dvtOCS_7",
        "outputId": "74654c54-5870-443f-a8cd-06c66983591f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Revolution', 50237), ('Ġsnipers', 50238), ('Ġreverted', 50239), ('Ġconglomerate', 50240), ('Terry', 50241), ('794', 50242), ('Ġharsher', 50243), ('Ġdesolate', 50244), ('ĠHitman', 50245), ('Commission', 50246), ('Ġ(/', 50247), ('âĢ¦.\"', 50248), ('Compar', 50249), ('Ġamplification', 50250), ('ominated', 50251), ('Ġregress', 50252), ('ĠCollider', 50253), ('Ġinformants', 50254), ('Ġgazed', 50255), ('<|endoftext|>', 50256)]\n"
          ]
        }
      ],
      "source": [
        "print(sorted_vocab[-20:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhS0sebvCS_7"
      },
      "source": [
        "<details>\n",
        "<summary>Fun (completely optional) exercise - can you guess what the first-formed 3/4/5/6/7-letter encodings in GPT-2's vocabulary are?</summary>\n",
        "Run this code to find out:\n",
        "\n",
        "```python\n",
        "lengths = dict.fromkeys(range(3, 8), \"\")\n",
        "for tok, idx in sorted_vocab:\n",
        "    if not lengths.get(len(tok), True):\n",
        "        lengths[len(tok)] = tok\n",
        "\n",
        "for length, tok in lengths.items():\n",
        "    print(f\"{length}: {tok}\")\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h428ukUDCS_7"
      },
      "source": [
        "Transformers in the `transformer_lens` library have a `to_tokens` method that converts text to numbers. It also prepends them with a special token called BOS (beginning of sequence) to indicate the start of a sequence. You can disable this with the `prepend_bos=False` argument.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - BOS token</summary>\n",
        "\n",
        "The beginning of sequence (BOS) token is a special token used to mark the beginning of the sequence. Confusingly, in GPT-2, the End of Sequence (EOS), Beginning of Sequence (BOS) and Padding (PAD) tokens are all the same, `<|endoftext|>` with index `50256`.\n",
        "\n",
        "Why is this token added? Some basic intuitions are:\n",
        "\n",
        "* It provides context that this is the start of a sequence, which can help the model generate more appropriate text.\n",
        "* It can act as a \"rest position\" for attention heads (more on this later, when we discuss attention).\n",
        "\n",
        "TransformerLens adds this token automatically (including in forward passes of transformer models, e.g. it's implicitly added when you call `model(\"Hello World\")`). You can disable this behaviour by setting the flag `prepend_bos=False` in `to_tokens`, `to_str_tokens`, `model.forward` and any other function that converts strings to multi-token tensors.\n",
        "\n",
        "**Key Point: *If you get weird off-by-one errors, check whether there's an unexpected `prepend_bos`!***\n",
        "\n",
        "Why are the BOS, EOS and PAD tokens the same? This is because GPT-2 is an autoregressive model, and uses these kinds of tokens in a slightly different way to other transformer families (e.g. BERT). For instance, GPT has no need to distinguish between BOS and EOS tokens, because it only processes text from left to right.\n",
        "\n",
        "</details>\n",
        "\n",
        "### Some tokenization annoyances\n",
        "\n",
        "There are a few funky and frustrating things about tokenization, which causes it to behave differently than you might expect. For instance:\n",
        "\n",
        "#### Whether a word begins with a capital or space matters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjo_Lkz_CS_7",
        "outputId": "ae8e693b-ad43-486e-9f01-4ff84dcc27cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<|endoftext|>', 'R', 'alph']\n",
            "['<|endoftext|>', ' Ralph']\n",
            "['<|endoftext|>', ' r', 'alph']\n",
            "['<|endoftext|>', 'ral', 'ph']\n"
          ]
        }
      ],
      "source": [
        "print(reference_gpt2.to_str_tokens(\"Ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\" Ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\" ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\"ralph\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qdqJ5_lCS_7"
      },
      "source": [
        "#### Arithmetic is a mess.\n",
        "\n",
        "Length is inconsistent, common numbers bundle together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSwtTJEwCS_7",
        "outputId": "d859e337-7a22-4a7f-b2be-ee63b2fcb93f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<|endoftext|>', '568', '73', '+', '318', '46', '23', '=', '123', '45', '67', '89', '-', '1', '000000', '000']\n"
          ]
        }
      ],
      "source": [
        "print(reference_gpt2.to_str_tokens(\"56873+3184623=123456789-1000000000\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJyXSyonCS_7"
      },
      "source": [
        "> ### Key Takeaways\n",
        ">\n",
        "> * We learn a dictionary of vocab of tokens (sub-words).\n",
        "> * We (approx) losslessly convert language to integers via tokenizing it.\n",
        "> * We convert integers to vectors via a lookup table.\n",
        "> * Note: input to the transformer is a sequence of *tokens* (ie integers), not vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSNf-UN8CS_7"
      },
      "source": [
        "## Text generation\n",
        "\n",
        "Now that we understand the basic ideas here, let's go through the entire process of text generation, from our original string to a new token which we can append to our string and plug back into the model.\n",
        "\n",
        "#### **Step 1:** Convert text to tokens\n",
        "\n",
        "The sequence gets tokenized, so it has shape `[batch, seq_len]`. Here, the batch dimension is just one (because we only have one sequence)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6_SGvrcCS_8",
        "outputId": "aee1c98c-6175-4975-a11d-61e708453e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
            "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
            "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
            "          1011,   625,   262,   995,     0]])\n",
            "torch.Size([1, 35])\n",
            "['<|endoftext|>', 'I', ' am', ' an', ' amazing', ' aut', 'ore', 'gressive', ',', ' dec', 'oder', '-', 'only', ',', ' G', 'PT', '-', '2', ' style', ' transformer', '.', ' One', ' day', ' I', ' will', ' exceed', ' human', ' level', ' intelligence', ' and', ' take', ' over', ' the', ' world', '!']\n"
          ]
        }
      ],
      "source": [
        "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
        "tokens = reference_gpt2.to_tokens(reference_text).to(device)\n",
        "print(tokens)\n",
        "print(tokens.shape)\n",
        "print(reference_gpt2.to_str_tokens(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYz91J-hCS_8"
      },
      "source": [
        "#### **Step 2:** Map tokens to logits\n",
        "\n",
        "\n",
        "From our input of shape `[batch, seq_len]`, we get output of shape `[batch, seq_len, vocab_size]`. The `[i, j, :]`-th element of our output is a vector of logits representing our prediction for the `j+1`-th token in the `i`-th sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnKxe9yfCS_8",
        "outputId": "7aabcb14-44d1-4c2b-8c08-62849d026347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3EjrSnsCS_8"
      },
      "source": [
        "(`run_with_cache` tells the model to cache all intermediate activations. This isn't important right now; we'll look at it in more detail later.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D8yulsBCS_8"
      },
      "source": [
        "#### **Step 3:** Convert the logits to a distribution with a softmax\n",
        "\n",
        "This doesn't change the shape, it is still `[batch, seq_len, vocab_size]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhR4wL5WCS_8",
        "outputId": "9609a081-9aeb-4130-cafa-23ee314d3a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "probs = logits.softmax(dim=-1)\n",
        "print(probs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg3PNsdeCS_8"
      },
      "source": [
        "#### **Bonus step:** What is the most likely next token at each position?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxUAm9xiCS_8",
        "outputId": "f36534bb-e408-4278-8589-a3c8ca94053c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<|endoftext|>', '\\n'), ('I', \"'m\"), (' am', ' a'), (' an', ' avid'), (' amazing', ' person'), (' aut', 'od'), ('ore', 'sp'), ('gressive', '.'), (',', ' and'), (' dec', 'ently'), ('oder', ','), ('-', 'driven'), ('only', ' programmer'), (',', ' and'), (' G', 'IM'), ('PT', '-'), ('-', 'only'), ('2', '.'), (' style', ','), (' transformer', '.'), ('.', ' I'), (' One', ' of'), (' day', ' I'), (' I', ' will'), (' will', ' be'), (' exceed', ' my'), (' human', 'ly'), (' level', ' of'), (' intelligence', ' and'), (' and', ' I'), (' take', ' over'), (' over', ' the'), (' the', ' world'), (' world', '.'), ('!', ' I')]\n"
          ]
        }
      ],
      "source": [
        "most_likely_next_tokens = reference_gpt2.tokenizer.batch_decode(logits.argmax(dim=-1)[0])\n",
        "\n",
        "print(list(zip(reference_gpt2.to_str_tokens(tokens), most_likely_next_tokens)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTaIJUXkCS_8"
      },
      "source": [
        "We can see that, in a few cases (particularly near the end of the sequence), the model accurately predicts the next token in the sequence. We might guess that `\"take over the world\"` is a common phrase that the model has seen in training, which is why the model can predict it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEpSoqrwCS_8"
      },
      "source": [
        "#### **Step 4:** Map distribution to a token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuHkLjpPCS_8",
        "outputId": "138d56f1-065f-40a7-bf90-2eb4aa85117f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "' I'\n"
          ]
        }
      ],
      "source": [
        "next_token = logits[0, -1].argmax(dim=-1)\n",
        "next_char = reference_gpt2.to_string(next_token)\n",
        "print(repr(next_char))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXp7RLckCS_8"
      },
      "source": [
        "Note that we're indexing `logits[0, -1]`. This is because logits have shape `[1, sequence_length, vocab_size]`, so this indexing returns the vector of length `vocab_size` representing the model's prediction for what token follows the **last** token in the input sequence.\n",
        "\n",
        "In this case, we can see that the model predicts the token `' I'`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5xZgwP6CTAG"
      },
      "source": [
        "### **Step 5:** Add this to the end of the input, re-run\n",
        "\n",
        "There are more efficient ways to do this (e.g. where we cache some of the values each time we run our input, so we don't have to do as much calculation each time we generate a new value), but this doesn't matter conceptually right now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgiNuHnbCTAG",
        "outputId": "854a1bd7-f4e6-4ad8-fcf1-845ea327d823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence so far: '<|endoftext|>I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!'\n",
            "36th char = ' I'\n",
            "37th char = ' am'\n",
            "38th char = ' a'\n",
            "39th char = ' very'\n",
            "40th char = ' talented'\n",
            "41th char = ' and'\n",
            "42th char = ' talented'\n",
            "43th char = ' person'\n",
            "44th char = ','\n",
            "45th char = ' and'\n"
          ]
        }
      ],
      "source": [
        "print(f\"Sequence so far: {reference_gpt2.to_string(tokens)[0]!r}\")\n",
        "\n",
        "for i in range(10):\n",
        "    print(f\"{tokens.shape[-1] + 1}th char = {next_char!r}\")\n",
        "    # Define new input sequence, by appending the previously generated token\n",
        "    tokens = t.cat([tokens, next_token[None, None]], dim=-1)\n",
        "    # Pass our new sequence through the model, to get new output\n",
        "    logits = reference_gpt2(tokens)\n",
        "    # Get the predicted token at the end of our sequence\n",
        "    next_token = logits[0, -1].argmax(dim=-1)\n",
        "    # Decode and print the result\n",
        "    next_char = reference_gpt2.to_string(next_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlGavAFmCTAG"
      },
      "source": [
        "> ## Key takeaways\n",
        ">\n",
        "> * Transformer takes in language, predicts next token (for *each* token in a causal way)\n",
        "> * We convert language to a sequence of integers with a tokenizer.\n",
        "> * We convert integers to vectors with a lookup table.\n",
        "> * Output is a vector of logits (one for each input token), we convert to a probability distn with a softmax, and can then convert this to a token (eg taking the largest logit, or sampling).\n",
        "> * We append this to the input + run again to generate more text (Jargon: *autoregressive*)\n",
        "> * Meta level point: Transformers are sequence operation models, they take in a sequence, do processing in parallel at each position, and use attention to move information between positions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UHMFKgtCTAG"
      },
      "source": [
        "# 2️⃣ Clean Transformer Implementation\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand that a transformer is composed of attention heads and MLPs, with each one performing operations on the residual stream\n",
        "> * Understand that the attention heads in a single layer operate independently, and that they have the role of calculating attention patterns (which determine where information is moved to & from in the residual stream)\n",
        "> * Learn about & implement the following transformer modules:\n",
        ">     * LayerNorm (transforming the input to have zero mean and unit variance)\n",
        ">     * Positional embedding (a lookup table from position indices to residual stream vectors)\n",
        ">     * Attention (the method of computing attention patterns for residual stream vectors)\n",
        ">     * MLP (the collection of linear and nonlinear transformations which operate on each residual stream vector in the same way)\n",
        ">     * Embedding (a lookup table from tokens to residual stream vectors)\n",
        ">     * Unembedding (a matrix for converting residual stream vectors into a distribution over tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MJDvZKlCTAG"
      },
      "source": [
        "## High-Level architecture\n",
        "\n",
        "Go watch Neel's [Transformer Circuits walkthrough](https://www.youtube.com/watch?v=KV5gbOmHbjU) if you want more intuitions!\n",
        "\n",
        "(Diagram is bottom to top, right-click and open for higher resolution.)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/chloeli-15/ARENA_img/main/img/transformer-new2.png\" width=\"950\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3ULd8v2CTAG"
      },
      "source": [
        "### Tokenization & Embedding\n",
        "\n",
        "The input tokens $t$ are integers. We get them from taking a sequence, and tokenizing it (like we saw in the previous section).\n",
        "\n",
        "The token embedding is a lookup table mapping tokens to vectors, which is implemented as a matrix $W_E$. The matrix consists of a stack of token embedding vectors (one for each token)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVLlhT7vCTAG"
      },
      "source": [
        "### Residual stream\n",
        "\n",
        "The residual stream is the sum of all previous outputs of layers of the model, and is also the input to each new layer. It has shape `[batch, seq_len, d_model]` (where `d_model` is the length of a single embedding vector).\n",
        "\n",
        "The initial value of the residual stream is denoted $x_0$ in the diagram, and $x_i$ are later values of the residual stream (after more attention and MLP layers have been applied to the residual stream).\n",
        "\n",
        "The residual stream is *really* fundamental. It's the central object of the transformer. It's how model remembers things, moves information between layers for composition, and it's the medium used to store the information that attention moves between positions.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - <b>logit lens</b></summary>\n",
        "\n",
        "A key idea of transformers is the [residual stream as output accumulation](https://www.lesswrong.com/posts/X26ksz4p3wSyycKNB/gears-level-mental-models-of-transformer-interpretability#Residual_Stream_as_Output_Accumulation:~:text=The%20Models-,Residual%20Stream%20as%20Output%20Accumulation,-The%20residual%20stream). As we move through the layers of the model, shifting information around and processing it, the values in the residual stream represent the accumulation of all the inferences made by the transformer up to that point.\n",
        "\n",
        "This is neatly illustrated by the **logit lens**. Rather than getting predictions from the residual stream at the very end of the model, we can take the value of the residual stream midway through the model and convert it to a distribution over tokens. When we do this, we find surprisingly coherent predictions, especially in the last few layers before the end.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0e5R4jrCTAG"
      },
      "source": [
        "### Transformer blocks\n",
        "\n",
        "Then we have a series of `n_layers` **transformer blocks** (also sometimes called **residual blocks**).\n",
        "\n",
        "Note - a block contains an attention layer *and* an MLP layer, but we say a transformer has $k$ layers if it has $k$ blocks (i.e. $2k$ total layers).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/chloeli-15/ARENA_img/main/img/transformer-block2.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROFDTm8qCTAG"
      },
      "source": [
        "### Attention\n",
        "\n",
        "First we have attention. This moves information from prior positions in the sequence to the current token.\n",
        "\n",
        "We do this for *every* token in parallel using the same parameters. The only difference is that we look backwards only (to avoid \"cheating\"). This means later tokens have more of the sequence that they can look at.\n",
        "\n",
        "Attention layers are the only bit of a transformer that moves information between positions (i.e. between vectors at different sequence positions in the residual stream).\n",
        "\n",
        "Attention layers are made up of `n_heads` heads - each with their own parameters, own attention pattern, and own information how to copy things from source to destination. The heads act independently and additively, we just add their outputs together, and back to the stream.\n",
        "\n",
        "Each head does the following:\n",
        "* Produces an **attention pattern** for each destination token, a probability distribution of prior source tokens (including the current one) weighting how much information to copy.\n",
        "* Moves information (via a linear map) in the same way from each source token to each destination token.\n",
        "\n",
        "Each attention head is made up of three components: the keys, queries, and values (often abbreviated as K, Q and V). These names come from their analogy to retrieval systems. Broadly speaking:\n",
        "\n",
        "* **Queries** represent a question or request for information, e.g. \"I'm looking for a name that appeared earlier in this sentence\".\n",
        "* **Keys** represent whether a source token's information matches the query, e.g. if the source token is \"Mary\" then this causes the key to have a high dot product with the query (we call this an **attention score**), and it means that a lot of information will be taken from this token.\n",
        "* **Values** represent the information that actually gets moved. This sounds similar to keys, but it's actually different in an important way. For instance, the key might just contain the information \"this is a name\", but the value could be the actual name itself.\n",
        "\n",
        "The diagram below illustrates the three different parts, in the context of the analogy for transformers we introduced earlier. This is a simplified model for how the person holding the \"in\" token might come to figure out that the next token is \"Mary\". In later sections we'll look at the actual function performed by attention heads and see how the operations relate to this analogy.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/simple-attn-intuition.png\" width=\"600\">\n",
        "\n",
        "Another interesting intuition for attention is as a kind of \"generalized convolution\" - read the dropdown below if you want to learn more about this.\n",
        "\n",
        "<details>\n",
        "<summary>Intuition - attention as generalized convolution</summary>\n",
        "\n",
        "We can think of attention as a kind of generalized convolution. Standard convolution layers work by imposing a \"prior of locality\", i.e. the assumption that pixels which are close together are more likely to share information. Although language has some locality (two words next to each other are more likely to share information than two words 100 tokens apart), the picture is a lot more nuanced, because which tokens are relevant to which others depends on the context of the sentence. For instance, in the sentence `\"When Mary and John went to the store, John gave a drink to Mary\"`, the names in this sentence are the most important tokens for predicting that the final token will be `\"Mary\"`, and this is because of the particular context of this sentence rather than the tokens' position.\n",
        "\n",
        "Attention layers are effectively our way of saying to the transformer, \"don't impose a prior of locality, but instead develop your own algorithm to figure out which tokens are important to which other tokens in any given sequence.\"\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXm5J3JACTAH"
      },
      "source": [
        "Below is a schematic diagram of the attention layers. We'll go into much more detail during the actual implementation, so don't worry if this doesn't fully make sense yet.\n",
        "\n",
        "<!-- <img src=\"https://raw.githubusercontent.com/chloeli-15/ARENA_img/main/img/transformer-attn-new-v2.png\" width=\"1050\"> -->\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/transformer-attn-simple.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9Ke_IVKCTAH"
      },
      "source": [
        "### MLP\n",
        "\n",
        "The MLP layers are just a standard neural network, with a singular hidden layer and a nonlinear activation function. The exact activation isn't conceptually important ([GELU](https://paperswithcode.com/method/gelu) seems to perform best).\n",
        "\n",
        "Our hidden dimension is normally `d_mlp = 4 * d_model`. Exactly why the ratios are what they are isn't super important (people basically cargo-cult what GPT did back in the day!).\n",
        "\n",
        "Importantly, **the MLP operates on positions in the residual stream independently, and in exactly the same way**. It doesn't move information between positions.\n",
        "\n",
        "Once attention has moved relevant information to a single position in the residual stream, MLPs can actually do computation, reasoning, lookup information, etc. *What the hell is going on inside MLPs* is a pretty big open problem in transformer mechanistic interpretability - see the [Toy Model of Superposition Paper](https://transformer-circuits.pub/2022/toy_model/index.html) for more on why this is hard.\n",
        "\n",
        "To go back to our analogy for transformers, we can essentially view MLPs as the thinking that each person in the line does once they've grabbed the information they need from the people behind them (via attention). Usually the MLP layers make up a much larger fraction of the model's total parameter count than attention layers (often around 2/3 although this varies between architectures), which makes sense since processing the information is a bigger task than just moving it around.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/intro-image-for-mlps-v2.png\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7TCKc6dCTAH"
      },
      "source": [
        "Here are a few more intuitions for MLPs, which you might find interesting:\n",
        "\n",
        "<details>\n",
        "<summary>Intuition - MLPs as key-value pairs</summary>\n",
        "\n",
        "We can write the MLP's output as $f(x^T W^{in})W^{out}$, where $W^{in}$ and $W^{out}$ are the different weights of the MLP (ignoring biases), $f$ is the activation function, and $x$ is a vector in the residual stream. This can be rewritten as:\n",
        "\n",
        "$$\n",
        "f(x^T W^{in}) W^{out} = \\sum_{i=1}^{d_{mlp}} f(x^T W^{in}_{[:, i]}) W^{out}_{[i, :]}\n",
        "$$\n",
        "\n",
        "We can view the vectors $W^{in}_{[:, i]}$ as the **input directions**, and $W^{out}_{[i, :]}$ as the **output directions**. We say the input directions are **activated** by certain textual features, and when they are activated, vectors are written in the corresponding output direction. This is very similar to the concept of keys and values in attention layers, which is why these vectors are also sometimes called keys and values (e.g. see the paper [Transformer Feed-Forward Layers Are Key-Value Memories](https://arxiv.org/pdf/2012.14913.pdf)).\n",
        "\n",
        "Terminology note - sometimes we refer to each of these $d_{mlp}$ input-output pairs as **neurons**.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/img/mlp-neurons-2.png\" width=\"900\">\n",
        "\n",
        "---\n",
        "\n",
        "Here's a step-by-step breakdown of the linear algebra, if it was too fast above. We have:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "x^T W^{in} &= x^T [W^{in}_{[:, 1]}\\,, ...\\;, W^{in}_{[:, n]}] \\\\\n",
        "&= (x^T W^{in}_{[:, 1]}\\,, \\; ...\\;, \\; x^T W^{in}_{[:, n]})\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $W^{in}_{[:, i]}$ are the columns of $W^{in}$. In other words, these values (the pre-GELU activations) are projections of $x$ along the input directions of the neurons.\n",
        "\n",
        "If we add our activation function and the second matrix, then we get:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "f(x^T W^{in})W^{out} &= (f(x^T W^{in}_{[:, 1]})\\,, \\; ...\\;,\\; f(x^T W^{in}_{[:, n]})) \\begin{bmatrix} \\leftarrow W^{out}_{[1, :]} \\rightarrow \\\\ \\vdots \\\\ \\leftarrow W^{out}_{[n, :]} \\rightarrow \\end{bmatrix} \\\\\n",
        "&= f(x^T W^{in}_{[:, 1]}) W^{out}_{[1, :]} + \\;...\\; + f(x^T W^{in}_{[:, n]}) W^{out}_{[n, :]} \\\\\n",
        "&= \\sum_{i=1}^n f(x^T W^{in}_{[:, i]}) W^{out}_{[i, :]}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $W^{out}_{[i, :]}$ are the rows of $W^{out}$. In other words, our output is a linear combination of the rows of $W^{out}$, with the coefficients of that linear combination given by the projections of $x$ along the columns of $W^{in}$.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Intuition - MLPs as knowledge storage</summary>\n",
        "\n",
        "We can think of MLPs as where knowledge gets stored in our transformer. The attention mechanism is what moves information around between sequence positions, but the MLPs is where this information is processed, and new information is written into the residual stream which is a function of the old information.\n",
        "\n",
        "This is deeply connected to the key-value pairs model, since you can treat key-value pairs as a kind of associative memory system (where the key serves as a unique identifier, and the value holds the related information).\n",
        "\n",
        "Another related intuition (for which there is some evidence) is **MLPs as memory management**. In an idealized case, we might find that the $i$-th neuron satisfies $W^{in}_{[:, i]} \\approx - W^{out}_{[i, :]} \\approx \\vec v$ for some unit vector $\\vec v$, meaning it may be responsible for erasing the positive component of vector $\\vec x$ in the direction $\\vec v$ (exercise - can you show why this is the case?). This can free up space in the residual stream for other components to write to.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4dZa8YeCTAH"
      },
      "source": [
        "Lastly, here's a schematic diagram of the MLP layers. Again, we'll go into much more detail during the actual implementation, so don't worry if this doesn't fully make sense yet.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/chloeli-15/ARENA_img/main/img/transformer-mlp-new-2.png\" width=\"680\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB69X5MxCTAH"
      },
      "source": [
        "### Unembedding\n",
        "\n",
        "Finally, we unembed!\n",
        "\n",
        "This just consists of applying a linear map $W_U$, going from final residual stream to a vector of logits - this is the output.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - tied embeddings</summary>\n",
        "\n",
        "Note - sometimes we use something called a **tied embedding** - this is where we use the same weights for our $W_E$ and $W_U$ matrices. In other words, to get the logit score for a particular token at some sequence position, we just take the vector in the residual stream at that sequence position and take the inner product with the corresponding token embedding vector. This is more training-efficient (because there are fewer parameters in our model), and it might seem principled at first. After all, if two words have very similar meanings, shouldn't they have similar embedding vectors because the model will treat them the same, and similar unembedding vectors because they could both be substituted for each other in most output?\n",
        "\n",
        "However, this is actually not very principled, for the following main reason: **the direct path involving the embedding and unembedding should approximate bigram frequencies**.\n",
        "\n",
        "Let's break down this claim. **Bigram frequencies** refers to the frequencies of pairs of words in the english language (e.g. the bigram frequency of \"Barack Obama\" is much higher than the product of the individual frequencies of the words \"Barack\" and \"Obama\"). If our model had no attention heads or MLP layers, then all we have is a linear map from our one-hot encoded token `T` to a probability distribution over the token following `T`. This map is represented by the linear transformation $t \\to t^T W_E W_U$ (where $t$ is our one-hot encoded token vector). Since the output of this transformation can only be a function of the token `T` (and no earlier tokens), the best we can do is have this map approximate the true frequency of bigrams starting with `T`, which appear in the training data. Importantly, **this is not a symmetric map**. We want `T = \"Barack\"` to result in a high probability of the next token being `\"Obama\"`, but not the other way around!\n",
        "\n",
        "Even in multi-layer models, a similar principle applies. There will be more paths through the model than just the \"direct path\" $W_E W_U$, but because of the residual connections there will always exist a direct path, so there will always be some incentive for $W_E W_U$ to approximate bigram frequencies.\n",
        "\n",
        "That being said, smaller (<8B parameter) LLMs still often use tied embeddings to improve training and inference efficiency. It can be easier to start from tied weights and then use MLP0 to break the symmetry than to initialize encoder and decoder with no shared structure at all.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG52o07nCTAH"
      },
      "source": [
        "### Bonus things - less conceptually important but key technical details\n",
        "\n",
        "#### LayerNorm\n",
        "\n",
        "* Simple normalization function applied at the start of each layer (i.e. before each MLP, attention layer, and before the unembedding)\n",
        "* Converts each input vector (independently in parallel for each `(batch, seq)` residual stream vector) to have mean zero and variance 1.\n",
        "* Then applies an elementwise scaling and translation\n",
        "* Cool maths tangent: The scale ($\\odot \\gamma$) & translate ($+ \\beta$) is just a linear map. LayerNorm is only applied immediately before another linear map (either the MLP, or the query/key/value linear maps in the attention head, or the unembedding $W_U$). Linear compose linear = linear, so we can just fold this into a single effective linear layer and ignore it.\n",
        "    * `fold_ln=True` flag in `from_pretrained` does this for you.\n",
        "* LayerNorm is annoying for interpretability - it would be linear if not for the fact we divide by the variance, so you can't decompose the contributions of the input to the output independently. But it's *almost* linear - if you're changing a small part of the input you can pretend $\\sqrt{\\text{Var}[x] + \\epsilon}$ is constant, so the LayerNorm operation is linear, but if you're changing $x$ enough to alter the norm substantially it's not linear.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/chloeli-15/ARENA_img/main/img/transformer-ln.png\" width=\"750\">\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "#### Positional embeddings\n",
        "\n",
        "* **Problem:** Attention operates over all pairs of positions. This means it's symmetric with regards to position - the attention calculation from token 5 to token 1 and token 5 to token 2 are the same by default\n",
        "    * This is dumb because nearby tokens are more relevant.\n",
        "* There's a lot of dumb hacks for this.\n",
        "* We'll focus on **learned, absolute positional embeddings**. This means we learn a lookup table mapping the index of the position of each token to a residual stream vector, and add this to the embed.\n",
        "    * Note that we *add* rather than concatenate. This is because the residual stream is shared memory, and likely under significant superposition (the model compresses more features in there than the model has dimensions)\n",
        "    * We basically never concatenate inside a transformer, unless doing weird shit like generating text efficiently.\n",
        "* This connects to **attention as generalized convolution**\n",
        "    * We argued that language does still have locality, and so it's helpful for transformers to have access to the positional information so they \"know\" two tokens are next to each other (and hence probably relevant to each other)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbHsT0isCTAH"
      },
      "source": [
        "## Actual Code!\n",
        "\n",
        "Model architecture table (this will be helpful for understanding the results you get when running the code block below):\n",
        "\n",
        "| Parameter   | Value          |\n",
        "|-------------|----------------|\n",
        "| batch       | 1              |\n",
        "| position    | 35             |\n",
        "| d_model     | 768            |\n",
        "| n_heads     | 12             |\n",
        "| n_layers    | 12             |\n",
        "| d_mlp       | 3072 (= 4 * `d_model`) |\n",
        "| d_head      | 64 (= `d_model / n_heads`) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUstjxVACTAH"
      },
      "source": [
        "### Parameters and Activations\n",
        "\n",
        "It's important to distinguish between parameters and activations in the model.\n",
        "\n",
        "* **Parameters** are the weights and biases that are learned during training.\n",
        "    * These don't change when the model input changes.\n",
        "* **Activations** are temporary numbers calculated during a forward pass, that are functions of the input.\n",
        "    * We can think of these values as only existing for the duration of a single forward pass, and disappearing afterwards.\n",
        "    * We can use hooks to access these values during a forward pass (more on hooks later), but it doesn't make sense to talk about a model's activations outside the context of some particular input.\n",
        "    * Attention scores and patterns are activations (this is slightly non-intuitve because they're used in a matrix multiplication with another activation).\n",
        "\n",
        "#### Print All Activation Shapes of Reference Model\n",
        "\n",
        "Run the following code to print all the activation shapes of the reference model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UTfdy3OCTAH",
        "outputId": "d979638e-5ebd-4204-b5c0-a257d19b3520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hook_embed                     (1, 35, 768)\n",
            "hook_pos_embed                 (1, 35, 768)\n",
            "blocks.0.hook_resid_pre        (1, 35, 768)\n",
            "blocks.0.ln1.hook_scale        (1, 35, 1)\n",
            "blocks.0.ln1.hook_normalized   (1, 35, 768)\n",
            "blocks.0.attn.hook_q           (1, 35, 12, 64)\n",
            "blocks.0.attn.hook_k           (1, 35, 12, 64)\n",
            "blocks.0.attn.hook_v           (1, 35, 12, 64)\n",
            "blocks.0.attn.hook_attn_scores (1, 12, 35, 35)\n",
            "blocks.0.attn.hook_pattern     (1, 12, 35, 35)\n",
            "blocks.0.attn.hook_z           (1, 35, 12, 64)\n",
            "blocks.0.hook_attn_out         (1, 35, 768)\n",
            "blocks.0.hook_resid_mid        (1, 35, 768)\n",
            "blocks.0.ln2.hook_scale        (1, 35, 1)\n",
            "blocks.0.ln2.hook_normalized   (1, 35, 768)\n",
            "blocks.0.mlp.hook_pre          (1, 35, 3072)\n",
            "blocks.0.mlp.hook_post         (1, 35, 3072)\n",
            "blocks.0.hook_mlp_out          (1, 35, 768)\n",
            "blocks.0.hook_resid_post       (1, 35, 768)\n",
            "ln_final.hook_scale            (1, 35, 1)\n",
            "ln_final.hook_normalized       (1, 35, 768)\n"
          ]
        }
      ],
      "source": [
        "for activation_name, activation in cache.items():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
        "        print(f\"{activation_name:30} {tuple(activation.shape)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6ish6h9CTAH"
      },
      "source": [
        "#### Print All Parameters Shapes of Reference Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbEaB0FQCTAH",
        "outputId": "99232121-e517-42a1-c2bf-7a66093a4442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed.W_E          (50257, 768)\n",
            "pos_embed.W_pos    (1024, 768)\n",
            "blocks.0.ln1.w     (768,)\n",
            "blocks.0.ln1.b     (768,)\n",
            "blocks.0.ln2.w     (768,)\n",
            "blocks.0.ln2.b     (768,)\n",
            "blocks.0.attn.W_Q  (12, 768, 64)\n",
            "blocks.0.attn.W_O  (12, 64, 768)\n",
            "blocks.0.attn.b_Q  (12, 64)\n",
            "blocks.0.attn.b_O  (768,)\n",
            "blocks.0.attn.W_K  (12, 768, 64)\n",
            "blocks.0.attn.W_V  (12, 768, 64)\n",
            "blocks.0.attn.b_K  (12, 64)\n",
            "blocks.0.attn.b_V  (12, 64)\n",
            "blocks.0.mlp.W_in  (768, 3072)\n",
            "blocks.0.mlp.b_in  (3072,)\n",
            "blocks.0.mlp.W_out (3072, 768)\n",
            "blocks.0.mlp.b_out (768,)\n",
            "ln_final.w         (768,)\n",
            "ln_final.b         (768,)\n",
            "unembed.W_U        (768, 50257)\n",
            "unembed.b_U        (50257,)\n"
          ]
        }
      ],
      "source": [
        "for name, param in reference_gpt2.named_parameters():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in name or \"blocks\" not in name:\n",
        "        print(f\"{name:18} {tuple(param.shape)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KISrDG58CTAH"
      },
      "source": [
        "[This diagram](https://raw.githubusercontent.com/chloeli-15/ARENA_img/main/img/full-merm.svg) shows the name of all activations and parameters in a fully general transformer model from transformerlens (except for a few at the start and end, like the embedding and unembedding). Lots of this won't make sense at first, but you can return to this diagram later and check that you understand most/all parts of it.\n",
        "\n",
        "There's also an annotated version [here](https://raw.githubusercontent.com/chloeli-15/ARENA_img/main/img/transformer-full-updated.png)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csIAfy9LCTAH"
      },
      "source": [
        "### Config\n",
        "\n",
        "The config object contains all the hyperparameters of the model. We can print the config of the reference model to see what it contains:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt8SjwMyCTAH",
        "outputId": "1524a286-0617-4747-99d3-b20c4f2977d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HookedTransformerConfig:\n",
            "{'NTK_by_parts_factor': 8.0,\n",
            " 'NTK_by_parts_high_freq_factor': 4.0,\n",
            " 'NTK_by_parts_low_freq_factor': 1.0,\n",
            " 'act_fn': 'gelu_new',\n",
            " 'attention_dir': 'causal',\n",
            " 'attn_only': False,\n",
            " 'attn_scale': 8.0,\n",
            " 'attn_scores_soft_cap': -1.0,\n",
            " 'attn_types': None,\n",
            " 'checkpoint_index': None,\n",
            " 'checkpoint_label_type': None,\n",
            " 'checkpoint_value': None,\n",
            " 'd_head': 64,\n",
            " 'd_mlp': 3072,\n",
            " 'd_model': 768,\n",
            " 'd_vocab': 50257,\n",
            " 'd_vocab_out': 50257,\n",
            " 'decoder_start_token_id': None,\n",
            " 'default_prepend_bos': True,\n",
            " 'device': device(type='cpu'),\n",
            " 'dtype': torch.float32,\n",
            " 'eps': 1e-05,\n",
            " 'experts_per_token': None,\n",
            " 'final_rms': False,\n",
            " 'from_checkpoint': False,\n",
            " 'gated_mlp': False,\n",
            " 'init_mode': 'gpt2',\n",
            " 'init_weights': False,\n",
            " 'initializer_range': 0.02886751345948129,\n",
            " 'load_in_4bit': False,\n",
            " 'model_name': 'gpt2',\n",
            " 'n_ctx': 1024,\n",
            " 'n_devices': 1,\n",
            " 'n_heads': 12,\n",
            " 'n_key_value_heads': None,\n",
            " 'n_layers': 12,\n",
            " 'n_params': 84934656,\n",
            " 'normalization_type': 'LN',\n",
            " 'num_experts': None,\n",
            " 'original_architecture': 'GPT2LMHeadModel',\n",
            " 'output_logits_soft_cap': -1.0,\n",
            " 'parallel_attn_mlp': False,\n",
            " 'positional_embedding_type': 'standard',\n",
            " 'post_embedding_ln': False,\n",
            " 'relative_attention_max_distance': None,\n",
            " 'relative_attention_num_buckets': None,\n",
            " 'rotary_adjacent_pairs': False,\n",
            " 'rotary_base': 10000,\n",
            " 'rotary_dim': None,\n",
            " 'scale_attn_by_inverse_layer_idx': False,\n",
            " 'seed': None,\n",
            " 'tie_word_embeddings': False,\n",
            " 'tokenizer_name': 'gpt2',\n",
            " 'tokenizer_prepends_bos': False,\n",
            " 'trust_remote_code': False,\n",
            " 'ungroup_grouped_query_attention': False,\n",
            " 'use_NTK_by_parts_rope': False,\n",
            " 'use_attn_in': False,\n",
            " 'use_attn_result': False,\n",
            " 'use_attn_scale': True,\n",
            " 'use_hook_mlp_in': False,\n",
            " 'use_hook_tokens': False,\n",
            " 'use_local_attn': False,\n",
            " 'use_normalization_before_and_after': False,\n",
            " 'use_split_qkv_input': False,\n",
            " 'window_size': None}\n"
          ]
        }
      ],
      "source": [
        "# As a reference - note there's a lot of stuff we don't care about in here, to do with library internals or other architectures\n",
        "print(reference_gpt2.cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06i8WCw8CTAH"
      },
      "source": [
        "We define a stripped down config for our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_p6QRJ9CTAH",
        "outputId": "aab6a7ba-96af-4435-b36b-f3722b8b1a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    d_model: int = 768\n",
        "    debug: bool = True\n",
        "    layer_norm_eps: float = 1e-5\n",
        "    d_vocab: int = 50257\n",
        "    init_range: float = 0.02\n",
        "    n_ctx: int = 1024\n",
        "    d_head: int = 64\n",
        "    d_mlp: int = 3072\n",
        "    n_heads: int = 12\n",
        "    n_layers: int = 12\n",
        "\n",
        "\n",
        "cfg = Config()\n",
        "print(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smn38iRuCTAH"
      },
      "source": [
        "### Tests\n",
        "\n",
        "Tests are great, write lightweight ones to use as you go!\n",
        "\n",
        "**Naive test:** Generate random inputs of the right shape, input to your model, check whether there's an error and print the correct output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IzucYtblCTAH"
      },
      "outputs": [],
      "source": [
        "def rand_float_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg).to(device)\n",
        "    random_input = t.randn(shape).to(device)\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    if isinstance(output, tuple):\n",
        "        output = output[0]\n",
        "    print(\"Output shape:\", output.shape, \"\\n\")\n",
        "\n",
        "\n",
        "def rand_int_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg).to(device)\n",
        "    random_input = t.randint(100, 1000, shape).to(device)\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    if isinstance(output, tuple):\n",
        "        output = output[0]\n",
        "    print(\"Output shape:\", output.shape, \"\\n\")\n",
        "\n",
        "\n",
        "def load_gpt2_test(cls, gpt2_layer, input):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg).to(device)\n",
        "    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n",
        "    print(\"Input shape:\", input.shape)\n",
        "    orig_input = input.clone()\n",
        "    output = layer(orig_input)\n",
        "    assert t.allclose(input, orig_input), \"Input has been modified, make sure operations are not done in place\"\n",
        "    if isinstance(output, tuple):\n",
        "        output = output[0]\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    try:\n",
        "        reference_output = gpt2_layer(input)\n",
        "    except:\n",
        "        reference_output = gpt2_layer(input, input, input)\n",
        "    print(\"Reference output shape:\", reference_output.shape, \"\\n\")\n",
        "    comparison = t.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
        "    print(f\"{comparison.sum() / comparison.numel():.2%} of the values are correct\\n\")\n",
        "    assert 1 - (comparison.sum() / comparison.numel()) < 1e-5, (\n",
        "        \"More than 0.01% of the values are incorrect\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGgxj08OCTAH"
      },
      "source": [
        "### Exercise - implement `LayerNorm`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should fill in the code below, and then run the tests to verify that your layer is working correctly.\n",
        "\n",
        "Your LayerNorm should do the following:\n",
        "\n",
        "* Make mean 0\n",
        "* Normalize to have variance 1\n",
        "* Scale with learned weights\n",
        "* Translate with learned bias\n",
        "\n",
        "You can use the PyTorch [LayerNorm documentation](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html) as a reference. A few more notes:\n",
        "\n",
        "* Your layernorm implementation always has `affine=True`, i.e. you do learn parameters `w` and `b` (which are represented as $\\gamma$ and $\\beta$ respectively in the PyTorch documentation).\n",
        "* Remember that, after the centering and normalization, each vector of length `d_model` in your input should have mean 0 and variance 1.\n",
        "* As the PyTorch documentation page says, your variance should be computed using `unbiased=False`.\n",
        "* The `layer_norm_eps` argument in your config object corresponds to the $\\epsilon$ term in the PyTorch documentation (it is included to avoid division-by-zero errors).\n",
        "* We've given you a `debug` argument in your config. If `debug=True`, then you can print output like the shape of objects in your `forward` function to help you debug (this is a very useful trick to improve your coding speed).\n",
        "\n",
        "Fill in the function, where it says `raise NotImplementedError()` (this will be the basic pattern for most other exercises in this section)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AqL_QP8CTAI",
        "outputId": "0c30b745-4bd1-4a94-cf5d-b2030d7e5fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768]) \n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.w = nn.Parameter(t.ones(cfg.d_model))\n",
        "        self.b = nn.Parameter(t.zeros(cfg.d_model))\n",
        "\n",
        "    def forward(\n",
        "        self, residual: Float[Tensor, \"batch posn d_model\"]\n",
        "    ) -> Float[Tensor, \"batch posn d_model\"]:\n",
        "        residual_mean = residual.mean(dim=-1, keepdim=True)\n",
        "        residual_std = (\n",
        "            residual.var(dim=-1, keepdim=True, unbiased=False) + self.cfg.layer_norm_eps\n",
        "        ).sqrt()\n",
        "\n",
        "        residual = (residual-residual_mean)/residual_std * self.w + self.b\n",
        "        return residual\n",
        "\n",
        "\n",
        "\n",
        "rand_float_test(LayerNorm, [2, 4, 768])\n",
        "load_gpt2_test(LayerNorm, reference_gpt2.ln_final, cache[\"resid_post\", 11])\n",
        "tests.test_layer_norm_epsilon(LayerNorm, cache[\"resid_post\", 11])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G5eLmyiCTAI"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.w = nn.Parameter(t.ones(cfg.d_model))\n",
        "        self.b = nn.Parameter(t.zeros(cfg.d_model))\n",
        "\n",
        "    def forward(\n",
        "        self, residual: Float[Tensor, \"batch posn d_model\"]\n",
        "    ) -> Float[Tensor, \"batch posn d_model\"]:\n",
        "        residual_mean = residual.mean(dim=-1, keepdim=True)\n",
        "        residual_std = (\n",
        "            residual.var(dim=-1, keepdim=True, unbiased=False) + self.cfg.layer_norm_eps\n",
        "        ).sqrt()\n",
        "\n",
        "        residual = (residual - residual_mean) / residual_std\n",
        "        return residual * self.w + self.b\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSWhlt8wCTAI"
      },
      "source": [
        "### Exercise - implement `Embed`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 5-10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "This is basically a lookup table from tokens to residual stream vectors.\n",
        "\n",
        "(Hint - you can implement this in just one line, without any complicated functions. If you've been working on it for >10 mins, you're probably overthinking it!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOLnxxNXCTAI",
        "outputId": "017e80c3-d4ea-4f02-a2bc-a19f5beca065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Output shape: torch.Size([2, 4, 768]) \n",
            "\n",
            "Input shape: torch.Size([1, 45])\n",
            "Output shape: torch.Size([1, 45, 768])\n",
            "Reference output shape: torch.Size([1, 45, 768]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class Embed(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_E = nn.Parameter(t.empty((cfg.d_vocab, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(\n",
        "        self, tokens: Int[Tensor, \"batch position\"]\n",
        "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        return self.W_E[tokens]\n",
        "\n",
        "\n",
        "rand_int_test(Embed, [2, 4])\n",
        "load_gpt2_test(Embed, reference_gpt2.embed, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4UHSdBICTAI"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I keep getting <code>RuntimeError: CUDA error: device-side assert triggered</code>.</summary>\n",
        "\n",
        "This is a uniquely frustrating type of error message, because it (1) forces you to restart the kernel, and (2) often won't tell you where the error message actually originated from!\n",
        "\n",
        "You can fix the second problem by adding the line `os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"` to the very top of your file (after importing `os`). This won't fix your bug, but it makes sure the correct origin point is identified.\n",
        "\n",
        "As for actually fixing the bug, this error usually ends up being the result of bad indexing, e.g. you're trying to apply an embedding layer to tokens which are larger than your maximum embedding.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Embed(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_E = nn.Parameter(t.empty((cfg.d_vocab, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(\n",
        "        self, tokens: Int[Tensor, \"batch position\"]\n",
        "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        return self.W_E[tokens]\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3Gw_KzsCTAI"
      },
      "source": [
        "### Exercise - implement `PosEmbed`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Positional embedding can also be thought of as a lookup table, but rather than the indices being our token IDs, the indices are just the numbers `0`, `1`, `2`, ..., `seq_len-1` (i.e. the position indices of the tokens in the sequence)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByRwSZcSCTAI",
        "outputId": "adf6037a-02ce-424c-8a33-cdf46c4261c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Output shape: torch.Size([2, 4, 768]) \n",
            "\n",
            "Input shape: torch.Size([1, 45])\n",
            "Output shape: torch.Size([1, 45, 768])\n",
            "Reference output shape: torch.Size([1, 45, 768]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(t.empty((cfg.n_ctx, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(\n",
        "        self, tokens: Int[Tensor, \"batch position\"]\n",
        "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        batch, seq_len = tokens.shape\n",
        "        return einops.repeat(self.W_pos[:seq_len], \"seq d_model -> batch seq d_model\", batch=batch)\n",
        "\n",
        "\n",
        "rand_int_test(PosEmbed, [2, 4])\n",
        "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnO0ViwlCTAI"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(t.empty((cfg.n_ctx, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(\n",
        "        self, tokens: Int[Tensor, \"batch position\"]\n",
        "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        batch, seq_len = tokens.shape\n",
        "        return einops.repeat(self.W_pos[:seq_len], \"seq d_model -> batch seq d_model\", batch=batch)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "binom9AjCTAI"
      },
      "source": [
        "### Exercise - implement `apply_causal_mask`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵🔵\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "The causal mask function will be a method of the `Attention` class.\n",
        "It will take in attention scores, and apply a mask to them so that the model\n",
        "can only attend to previous positions (i.e. the model can't cheat by looking at future positions).\n",
        "We will implement this function first, and test it, before moving onto the `forward` method\n",
        "of the `Attention` class.\n",
        "\n",
        "A few hints:\n",
        "\n",
        "* You can use [`torch.where`](https://pytorch.org/docs/stable/generated/torch.where.html), or the [`torch.masked_fill_`](https://pytorch.org/docs/stable/generated/torch.Tensor.masked_fill.html) function when masking the attention scores.\n",
        "* The [`torch.triu`](https://pytorch.org/docs/stable/generated/torch.triu.html) function is useful for creating a mask that is True for all positions we want to set probabilities to zero for.\n",
        "* Make sure to use the `self.IGNORE` attribute to set the masked positions to negative infinity.\n",
        "<details>\n",
        "<summary>Question - why do you think we mask the attention scores by setting them to negative infinity, rather than the attention probabilities by setting them to zero?</summary>\n",
        "\n",
        "If we masked the attention probabilities, then the probabilities would no longer sum to 1.\n",
        "\n",
        "We want to mask the scores and *then* take softmax, so that the probabilities are still valid probabilities (i.e. they sum to 1), and the values in the masked positions have no influence on the model's output.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xETJOfEXCTAI",
        "outputId": "658f925e-76f3-4f5c-a89a-b2189394f1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_causal_mask` passed!\n"
          ]
        }
      ],
      "source": [
        "class Attention(nn.Module):\n",
        "    IGNORE: Float[Tensor, \"\"]\n",
        "\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.register_buffer(\"IGNORE\", t.tensor(float(\"-inf\"), dtype=t.float32, device=device))\n",
        "\n",
        "    def apply_causal_mask(\n",
        "        self,\n",
        "        attn_scores: Float[Tensor, \"batch n_heads query_pos key_pos\"],\n",
        "    ) -> Float[Tensor, \"batch n_heads query_pos key_pos\"]:\n",
        "        \"\"\"\n",
        "        Applies a causal mask to attention scores, and returns masked scores.\n",
        "        \"\"\"\n",
        "        all_ones = t.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device)\n",
        "        mask = t.triu(all_ones, diagonal=1).bool()\n",
        "        # Apply the mask to attention scores, then return the masked scores\n",
        "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
        "        return attn_scores\n",
        "\n",
        "\n",
        "tests.test_causal_mask(Attention.apply_causal_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdC69YhYCTAI"
      },
      "source": [
        "<details>\n",
        "<summary>Hint (pseudocode)</summary>\n",
        "\n",
        "```python\n",
        "def apply_causal_mask(\n",
        "    self, attn_scores: Float[Tensor, \"batch n_heads query_pos key_pos\"]\n",
        "    ) -> Float[Tensor, \"batch n_heads query_pos key_pos\"]:\n",
        "\n",
        "    # Define a mask that is True for all positions we want to set probabilities to zero for\n",
        "\n",
        "    # Apply the mask to attention scores, then return the masked scores\n",
        "```\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Attention(nn.Module):\n",
        "    IGNORE: Float[Tensor, \"\"]\n",
        "\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.register_buffer(\"IGNORE\", t.tensor(float(\"-inf\"), dtype=t.float32, device=device))\n",
        "\n",
        "    def apply_causal_mask(\n",
        "        self,\n",
        "        attn_scores: Float[Tensor, \"batch n_heads query_pos key_pos\"],\n",
        "    ) -> Float[Tensor, \"batch n_heads query_pos key_pos\"]:\n",
        "        \"\"\"\n",
        "        Applies a causal mask to attention scores, and returns masked scores.\n",
        "        \"\"\"\n",
        "        # Define a mask that is True for all positions we want to set probabilities to zero for\n",
        "        all_ones = t.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device)\n",
        "        mask = t.triu(all_ones, diagonal=1).bool()\n",
        "        # Apply the mask to attention scores, then return the masked scores\n",
        "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
        "        return attn_scores\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAt3tAfzCTAI"
      },
      "source": [
        "### Exercise - implement `Attention`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵🔵🔵\n",
        ">\n",
        "> You should spend up to 30-45 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "* **Step 1:** Produce an attention pattern - for each destination token, probability distribution over previous tokens (including current token)\n",
        "    * Linear map from input -> query, key shape `[batch, seq_posn, head_index, d_head]`\n",
        "    * Dot product every *pair* of queries and keys to get attn_scores `[batch, head_index, query_pos, key_pos]` (query = dest, key = source)\n",
        "    * **Scale** and mask `attn_scores` to make it lower triangular, i.e. causal\n",
        "    * Softmax along the `key_pos` dimension, to get a probability distribution for each query (destination) token - this is our attention pattern!\n",
        "* **Step 2:** Move information from source tokens to destination token using attention pattern (move = apply linear map)\n",
        "    * Linear map from input -> value `[batch, key_pos, head_index, d_head]`\n",
        "    * Mix along the `key_pos` with attn pattern to get `z`, which is a weighted average of the value vectors `[batch, query_pos, head_index, d_head]`\n",
        "    * Map to output, `[batch, position, d_model]` (position = query_pos, we've summed over all heads)\n",
        "\n",
        "Note - when we say **scale**, we mean dividing by `sqrt(d_head)`. The purpose of this is to avoid vanishing gradients (which is a big problem when we're dealing with a function like softmax - if one of the values is much larger than all the others, the probabilities will be close to 0 or 1, and the gradients will be close to 0).\n",
        "\n",
        "Below is a much larger, more detailed version of the attention head diagram from earlier. This should give you an idea of the actual tensor operations involved. A few clarifications on this diagram:\n",
        "\n",
        "* Whenever there is a third dimension shown in the pictures, this refers to the `head_index` dimension. We can see that all operations within the attention layer are done independently for each head.\n",
        "* The objects in the box are activations; they have a batch dimension (for simplicity, we assume the batch dimension is 1 in the diagram). The objects to the right of the box are our parameters (weights and biases); they have no batch dimension.\n",
        "* We arrange the keys, queries and values as `(batch, seq_pos, head_idx, d_head)`, because the biases have shape `(head_idx, d_head)`, so this makes it convenient to add the biases (recall the rules of array broadcasting!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZjesbj6CTAI"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/chloeli-15/ARENA_img/main/img/transformer-attn-30.png\" width=\"1400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeMU19D0CTAI"
      },
      "source": [
        "<details>\n",
        "<summary><b>A few extra notes on attention (optional)</b></summary>\n",
        "\n",
        "<!-- Usually we have the relation `e = n * h` (i.e. `d_model = num_heads * d_head`). There are some computational justifications for this, but mostly this is just done out of convention (just like how we usually have `d_mlp = 4 * d_model`!). -->\n",
        "\n",
        "Here, we cover some details related to the mathematical formulation of attention heads (and in particular the separation of **QK** and **OV** circuits), which is something we dive a lot deeper into in the next set of exercises in this chapter.\n",
        "\n",
        "The **QK** circuit consists of the operation of the $W_Q$ and $W_K$ matrices. In other words, it determines the attention pattern, i.e. where information is moved to and from in the residual stream. The functional form of the attention pattern $A$ is:\n",
        "\n",
        "$$\n",
        "A = \\text{softmax}\\left(\\frac{x W_Q W_K^T x^T}{\\sqrt{d_{head}}}\\right)\n",
        "$$\n",
        "\n",
        "where $x$ is the residual stream (shape `[seq_len, d_model]`), and $W_Q$, $W_K$ are the weight matrices for a single head (i.e. shape `[d_model, d_head]`).\n",
        "\n",
        "The **OV** circuit consists of the operation of the $W_V$ and $W_O$ matrices. Once attention patterns are fixed, these matrices operate on the residual stream at the source position, and their output is the thing which gets moved from source to destination position.\n",
        "\n",
        "The diagram below shows the functional form of the OV circuit. The QK circuit (pink) is responsible for causing the destination token to attend to the source token, and the OV circuit (light brown) is what actually maps the source token data into the information we'll send to the destination token.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/chloeli-15/ARENA_img/refs/heads/main/img/qkv.png\" width=\"800\">\n",
        "\n",
        "The functional form of an entire attention head is:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\text{output} &= \\text{softmax}\\left(\\frac{x W_Q W_K^T x^T}{\\sqrt{d_{head}}}\\right) (x W_V W_O) \\\\\n",
        "    &= Ax W_V W_O\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $W_V$ has shape `[d_model, d_head]`, and $W_O$ has shape `[d_head, d_model]`.\n",
        "\n",
        "Here, we can clearly see that the **QK circuit** and **OV circuit** are doing conceptually different things, and should be thought of as two distinct parts of the attention head.\n",
        "\n",
        "Again, don't worry if you don't follow all of this right now - we'll go into **much** more detail on all of this in subsequent exercises. The purpose of the discussion here is just to give you a flavour of what's to come!\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9lITJ7bCTAI"
      },
      "source": [
        "First, it's useful to visualize and play around with attention patterns - what exactly are we looking at here? (Click on a head to lock onto just showing that head's pattern, it'll make it easier to interpret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "ICOvXsoyCTAI",
        "outputId": "32b33461-62c8-4cb7-e608-6ccbee27a714"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x79d2c5cfb680>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-2b1cf5b9-1688\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-2b1cf5b9-1688\",\n",
              "      AttentionPatterns,\n",
              "      {\"tokens\": [\"<|endoftext|>\", \"I\", \" am\", \" an\", \" amazing\", \" aut\", \"ore\", \"gressive\", \",\", \" dec\", \"oder\", \"-\", \"only\", \",\", \" G\", \"PT\", \"-\", \"2\", \" style\", \" transformer\", \".\", \" One\", \" day\", \" I\", \" will\", \" exceed\", \" human\", \" level\", \" intelligence\", \" and\", \" take\", \" over\", \" the\", \" world\", \"!\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9679255485534668, 0.0320744626224041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8024237155914307, 0.16839197278022766, 0.0291843693703413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6959055066108704, 0.12269632518291473, 0.1458849012851715, 0.03551323711872101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5661025047302246, 0.1470518857240677, 0.08665253221988678, 0.11258414387702942, 0.08760891109704971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.462187260389328, 0.13512833416461945, 0.09698352217674255, 0.1747375875711441, 0.04624601826071739, 0.08471736311912537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.43251603841781616, 0.1038287803530693, 0.08330139517784119, 0.06995753198862076, 0.074793741106987, 0.21568654477596283, 0.01991591602563858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2223673164844513, 0.09167695045471191, 0.0879632756114006, 0.25168734788894653, 0.08263692259788513, 0.10428164899349213, 0.06469017267227173, 0.09469638019800186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4049955904483795, 0.09078018367290497, 0.052373599261045456, 0.0262018870562315, 0.11047185957431793, 0.036674030125141144, 0.025538913905620575, 0.24528279900550842, 0.007681123912334442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39985957741737366, 0.04361315816640854, 0.061838846653699875, 0.072983518242836, 0.03661305829882622, 0.09147472679615021, 0.07241711020469666, 0.07013335078954697, 0.06429056823253632, 0.08677607029676437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09702547639608383, 0.03552757576107979, 0.02321481518447399, 0.03676706179976463, 0.025158395990729332, 0.2775617241859436, 0.07676512748003006, 0.1950119137763977, 0.05580100789666176, 0.14529386162757874, 0.03187303990125656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24143841862678528, 0.03971059247851372, 0.07687386870384216, 0.02804269827902317, 0.12435996532440186, 0.05601578578352928, 0.06063668429851532, 0.1284010261297226, 0.015699446201324463, 0.09114035964012146, 0.13185440003871918, 0.005826778244227171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1436309814453125, 0.05110500380396843, 0.05505896359682083, 0.07798513025045395, 0.0785427913069725, 0.03501971438527107, 0.13498607277870178, 0.2263406664133072, 0.041628528386354446, 0.03513140603899956, 0.020236020907759666, 0.04114445671439171, 0.05919027701020241, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3156284689903259, 0.06791999191045761, 0.037872400134801865, 0.01787460409104824, 0.08683164417743683, 0.02922779880464077, 0.017664164304733276, 0.18301638960838318, 0.0049878014251589775, 0.043228648602962494, 0.05172263830900192, 0.008913453668355942, 0.1289924532175064, 0.006119511555880308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28410202264785767, 0.0534539632499218, 0.023969221860170364, 0.022562265396118164, 0.04619826003909111, 0.06391074508428574, 0.04539212957024574, 0.07758504152297974, 0.027644319459795952, 0.05804117023944855, 0.17727358639240265, 0.0340060219168663, 0.03052728995680809, 0.03213079646229744, 0.023203188553452492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14103911817073822, 0.02857781946659088, 0.03760399669408798, 0.031378280371427536, 0.03697337582707405, 0.07347071915864944, 0.07151783257722855, 0.09211233258247375, 0.03358155116438866, 0.036391302943229675, 0.18937668204307556, 0.03244517743587494, 0.06021039932966232, 0.03916927054524422, 0.040409550070762634, 0.05574262514710426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20265290141105652, 0.030252812430262566, 0.060034118592739105, 0.021786168217658997, 0.10314235836267471, 0.045168377459049225, 0.04681026563048363, 0.10542114078998566, 0.011398817412555218, 0.07159949094057083, 0.10570329427719116, 0.004199369810521603, 0.11079790443181992, 0.013912520371377468, 0.02892351895570755, 0.03286949172616005, 0.005327519495040178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20498354732990265, 0.040072306990623474, 0.042298149317502975, 0.024939019232988358, 0.04992292821407318, 0.02937168814241886, 0.030769700184464455, 0.10315565019845963, 0.025490228086709976, 0.07886795699596405, 0.10560182482004166, 0.017352715134620667, 0.0808369442820549, 0.031286969780921936, 0.05451060086488724, 0.05288316681981087, 0.021742800250649452, 0.005913801025599241, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24350900948047638, 0.036364879459142685, 0.04196164757013321, 0.026215722784399986, 0.0404457151889801, 0.09965364634990692, 0.02575223334133625, 0.03249461576342583, 0.024459948763251305, 0.03520263731479645, 0.03383538872003555, 0.03347689285874367, 0.04664862900972366, 0.0279679112136364, 0.01864079385995865, 0.1176426038146019, 0.03875287249684334, 0.022786680608987808, 0.05418812856078148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14194567501544952, 0.03406403586268425, 0.033009905368089676, 0.020238704979419708, 0.03927316889166832, 0.026005549356341362, 0.006318638101220131, 0.04079786315560341, 0.03638003021478653, 0.14631050825119019, 0.016386179253458977, 0.023598456755280495, 0.01584276556968689, 0.04227606579661369, 0.022458229213953018, 0.06867397576570511, 0.027878474444150925, 0.03722239285707474, 0.08677610009908676, 0.13454324007034302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21778127551078796, 0.026903681457042694, 0.023647215217351913, 0.00710256164893508, 0.035170022398233414, 0.013998538255691528, 0.010392273776233196, 0.09431248158216476, 0.002962291007861495, 0.03783804550766945, 0.037923313677310944, 0.003733975812792778, 0.06506100296974182, 0.0036364595871418715, 0.014758051373064518, 0.12028629332780838, 0.004900882486253977, 0.008107366971671581, 0.01744985394179821, 0.24998730421066284, 0.004047101363539696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12187217175960541, 0.07663210481405258, 0.030231976881623268, 0.016371840611100197, 0.05268789455294609, 0.02140214666724205, 0.023403892293572426, 0.1064968928694725, 0.018582485616207123, 0.035091664642095566, 0.08394153416156769, 0.017393294721841812, 0.04183054342865944, 0.021453870460391045, 0.033331021666526794, 0.05027424544095993, 0.020740864798426628, 0.04090358689427376, 0.0305409524589777, 0.09200657159090042, 0.028245704248547554, 0.036564696580171585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2126019150018692, 0.02028411440551281, 0.050003714859485626, 0.015904176980257034, 0.05722508579492569, 0.022857310250401497, 0.046045877039432526, 0.03530842438340187, 0.011784469708800316, 0.041404832154512405, 0.016803612932562828, 0.015782058238983154, 0.02020842581987381, 0.013090190477669239, 0.020854240283370018, 0.06297556310892105, 0.018039435148239136, 0.018052963539958, 0.024445300921797752, 0.17059145867824554, 0.01593976467847824, 0.04152190312743187, 0.048275113105773926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2671400308609009, 0.035646166652441025, 0.0204229187220335, 0.006622722838073969, 0.04034103453159332, 0.019110344350337982, 0.01457529328763485, 0.05641632899641991, 0.008403637446463108, 0.015526894479990005, 0.04414669796824455, 0.011055916547775269, 0.040019966661930084, 0.009353090077638626, 0.019351882860064507, 0.07054154574871063, 0.01279882900416851, 0.012832626700401306, 0.014165611937642097, 0.1173698902130127, 0.0073127844370901585, 0.09727416932582855, 0.020751141011714935, 0.03882049769163132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.145912304520607, 0.03319380059838295, 0.03138771280646324, 0.009927908889949322, 0.052096571773290634, 0.01984088495373726, 0.01940172351896763, 0.0758240818977356, 0.012863251380622387, 0.03345127031207085, 0.016568399965763092, 0.014797154814004898, 0.059083860367536545, 0.015597395598888397, 0.011369233019649982, 0.021859485656023026, 0.019473880529403687, 0.014793704263865948, 0.05341865494847298, 0.0952148362994194, 0.01620457135140896, 0.06210917606949806, 0.06182851642370224, 0.06657972186803818, 0.03720196336507797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06265700608491898, 0.014285162091255188, 0.025387225672602654, 0.030092529952526093, 0.02124691754579544, 0.02952989935874939, 0.026446690782904625, 0.014830494299530983, 0.015861934050917625, 0.043314315378665924, 0.021963968873023987, 0.0199701189994812, 0.043428532779216766, 0.01869288831949234, 0.00947535876184702, 0.024197492748498917, 0.023853639140725136, 0.026908745989203453, 0.01406070590019226, 0.17528504133224487, 0.03583676367998123, 0.047922566533088684, 0.0357506163418293, 0.01207052357494831, 0.05927427485585213, 0.14765654504299164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09766793996095657, 0.03152173385024071, 0.02668641321361065, 0.03645578399300575, 0.034923702478408813, 0.08635788410902023, 0.013895384036004543, 0.03018672578036785, 0.019402572885155678, 0.035141680389642715, 0.04878159612417221, 0.012551559135317802, 0.04099079594016075, 0.020208820700645447, 0.012653263285756111, 0.007451050914824009, 0.013522980734705925, 0.024078071117401123, 0.043027088046073914, 0.15066799521446228, 0.02925257943570614, 0.018810182809829712, 0.016104495152831078, 0.028549866750836372, 0.029875919222831726, 0.05121561139822006, 0.040018316358327866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0915180891752243, 0.011421110481023788, 0.039799030870199203, 0.011658592149615288, 0.033443327993154526, 0.041076067835092545, 0.009538297541439533, 0.04061253368854523, 0.00911439023911953, 0.04690400883555412, 0.027317609637975693, 0.010844956152141094, 0.024547509849071503, 0.010004599578678608, 0.008095644414424896, 0.008396814577281475, 0.011855490505695343, 0.00818414706736803, 0.041040632873773575, 0.36258113384246826, 0.007537384983152151, 0.009961559437215328, 0.021045763045549393, 0.01185503788292408, 0.03005831502377987, 0.032811954617500305, 0.02886321023106575, 0.009912791661918163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1094629317522049, 0.025872724130749702, 0.023928716778755188, 0.020045259967446327, 0.035904448479413986, 0.031679846346378326, 0.029145298525691032, 0.11399827897548676, 0.013954722322523594, 0.03480715677142143, 0.0181056447327137, 0.01762225478887558, 0.01900731585919857, 0.015307595022022724, 0.009703018702566624, 0.01240796223282814, 0.020091699436306953, 0.02726253867149353, 0.0656459778547287, 0.02715539187192917, 0.02622661180794239, 0.018942993134260178, 0.04077142849564552, 0.019073303788900375, 0.021573422476649284, 0.030219439417123795, 0.07011830806732178, 0.06031463295221329, 0.041651081293821335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11406350880861282, 0.026556236669421196, 0.019958432763814926, 0.008931465446949005, 0.03494322672486305, 0.01683431677520275, 0.00937773659825325, 0.0445132739841938, 0.0037722205743193626, 0.02876030094921589, 0.020741166546940804, 0.0056509943678975105, 0.060077618807554245, 0.004424977116286755, 0.010821852833032608, 0.04112930968403816, 0.007085718214511871, 0.01043399702757597, 0.02654852531850338, 0.11019265651702881, 0.007190010044723749, 0.056519392877817154, 0.02802707441151142, 0.06370093673467636, 0.03407692909240723, 0.07150982320308685, 0.04093319550156593, 0.014252976514399052, 0.06984370201826096, 0.009128457866609097, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14399927854537964, 0.02045460231602192, 0.042623862624168396, 0.011592105031013489, 0.027789438143372536, 0.014342918992042542, 0.029106207191944122, 0.04215823858976364, 0.013669712468981743, 0.020581481978297234, 0.008641068823635578, 0.012402212247252464, 0.019577061757445335, 0.014879738911986351, 0.023319056257605553, 0.022367175668478012, 0.01441388763487339, 0.006065305322408676, 0.006985298823565245, 0.08859118074178696, 0.014219227246940136, 0.027541209012269974, 0.05707305297255516, 0.02498570829629898, 0.05733298510313034, 0.04808966442942619, 0.018268700689077377, 0.07940171658992767, 0.04377178102731705, 0.02484910562634468, 0.02090698853135109, 0.0, 0.0, 0.0, 0.0], [0.0778680145740509, 0.019732853397727013, 0.019906379282474518, 0.015179569832980633, 0.029269905760884285, 0.008963333442807198, 0.011427865363657475, 0.03169625625014305, 0.006965260952711105, 0.04064168408513069, 0.019985223188996315, 0.008789056912064552, 0.035749901086091995, 0.007953660562634468, 0.009612184949219227, 0.01496591791510582, 0.010367295704782009, 0.013544994406402111, 0.013747340068221092, 0.06818544864654541, 0.011837059631943703, 0.01935550943017006, 0.016761237755417824, 0.01630123145878315, 0.061250220984220505, 0.12023529410362244, 0.04739145189523697, 0.02382204681634903, 0.1494300365447998, 0.014121505431830883, 0.04741878807544708, 0.007523445412516594, 0.0, 0.0, 0.0], [0.14836610853672028, 0.03627423197031021, 0.02376876212656498, 0.005308398976922035, 0.03226036950945854, 0.01743944175541401, 0.015090282075107098, 0.04443071782588959, 0.004935787059366703, 0.021151496097445488, 0.02384909987449646, 0.006127791944891214, 0.04430980235338211, 0.005717848427593708, 0.006861453875899315, 0.016362618654966354, 0.007707127369940281, 0.009109631180763245, 0.028427591547369957, 0.14491389691829681, 0.0063516017980873585, 0.03453822806477547, 0.02327299490571022, 0.04803795367479324, 0.03441666439175606, 0.0697537213563919, 0.027561916038393974, 0.012016532011330128, 0.03535732254385948, 0.008575201965868473, 0.039163023233413696, 0.009715795516967773, 0.008826583623886108, 0.0, 0.0], [0.11389312893152237, 0.021931476891040802, 0.026447618380188942, 0.007602890953421593, 0.020530683919787407, 0.029713168740272522, 0.03694964200258255, 0.02875792607665062, 0.007981309667229652, 0.02935916930437088, 0.015349607914686203, 0.018420161679387093, 0.020850971341133118, 0.008514756336808205, 0.0109309246763587, 0.009227685630321503, 0.02127930149435997, 0.009222986176609993, 0.027651101350784302, 0.12458859384059906, 0.010509631596505642, 0.060961924493312836, 0.022033261135220528, 0.0303669311106205, 0.0274112019687891, 0.0345994271337986, 0.03202730417251587, 0.0395297072827816, 0.05353797599673271, 0.017732912674546242, 0.017497548833489418, 0.017771488055586815, 0.012080216780304909, 0.03473733365535736, 0.0], [0.13933587074279785, 0.02137126214802265, 0.014541374519467354, 0.00512328976765275, 0.0316351093351841, 0.010921812616288662, 0.012541361153125763, 0.02249288558959961, 0.004774261265993118, 0.024901418015360832, 0.01085835974663496, 0.010577717795968056, 0.02590608410537243, 0.005286504980176687, 0.016752300783991814, 0.04520438238978386, 0.012112239375710487, 0.014714688062667847, 0.014629189856350422, 0.08781161159276962, 0.007287844084203243, 0.07496534287929535, 0.015995554625988007, 0.043923430144786835, 0.041024137288331985, 0.07587804645299911, 0.0279245562851429, 0.015250173397362232, 0.013413447886705399, 0.01453278586268425, 0.027215447276830673, 0.03453554958105087, 0.018207423388957977, 0.0350533127784729, 0.02330125868320465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00041899713687598705, 0.9995810389518738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00013394799316301942, 0.00951186940073967, 0.990354061126709, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008606775081716478, 0.002610041992738843, 0.01506681740283966, 0.9814624786376953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.7170477298786864e-05, 0.0006769582978449762, 0.0012692962773144245, 0.00021407846361398697, 0.9978025555610657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.425408304901794e-05, 0.0007904706289991736, 0.0032152836211025715, 0.002708565443754196, 0.0013058249605819583, 0.9918956160545349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00014960514090489596, 0.001836186507716775, 0.0016375009436160326, 0.0010130589362233877, 0.004209812264889479, 8.004387927940115e-05, 0.9910737872123718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00026855681790038943, 0.0009259635698981583, 0.0008250513346865773, 0.0006819659029133618, 0.007268876302987337, 0.001351709826849401, 0.00034691678592935205, 0.9883310198783875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007326354272663593, 0.007828539237380028, 0.003931872546672821, 0.00018373994680587202, 6.433095404645428e-05, 0.00010083136294269934, 6.769891479052603e-05, 7.16408176231198e-05, 0.9804250597953796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.9175745769171044e-05, 9.137414599535987e-05, 0.0003339909017086029, 6.816770473960787e-05, 7.81233684392646e-05, 0.0009843030711635947, 0.00016941322246566415, 0.002541458932682872, 4.413309216033667e-05, 0.9956498742103577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.52032270206837e-06, 2.3466505808755755e-05, 9.186466195387766e-05, 8.013433398446068e-05, 3.939216912840493e-05, 8.521587733412161e-05, 2.5735900635481812e-05, 7.12082110112533e-05, 4.276964318705723e-06, 0.00015049769717734307, 0.9994226694107056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001040030736476183, 0.0022993639577180147, 0.0023920696694403887, 0.00031332348589785397, 0.00013362921890802681, 0.0005168464267626405, 0.0011971109779551625, 6.827456672908738e-05, 0.005444327834993601, 0.0002821744419634342, 4.3057352741016075e-05, 0.9862697720527649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.630400871974416e-05, 0.0003248225257266313, 0.0002445938589517027, 0.0015311642782762647, 0.0008613694808445871, 0.001294386456720531, 6.198453775141388e-05, 2.6642672310117632e-05, 4.8408594011561945e-05, 0.0019855634309351444, 0.0001397185551468283, 0.00011434270709287375, 0.9933207035064697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003044240642338991, 0.001822363119572401, 0.0009289864683523774, 4.880229971604422e-05, 1.6391151802963577e-05, 2.909561590058729e-05, 2.507976387278177e-05, 2.913023672590498e-05, 0.4563220143318176, 2.4578661395935342e-05, 2.4832152121234685e-05, 0.0030043956357985735, 1.6773799416114343e-06, 0.5346784591674805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003981802728958428, 0.0010285042226314545, 0.0008281139889732003, 0.0002375323383603245, 7.348884537350386e-05, 0.0014350343262776732, 6.76568306516856e-05, 0.0002954751253128052, 0.0001429583498975262, 9.929129737429321e-05, 4.608238214132143e-06, 0.0005140082212164998, 5.035671620134963e-06, 0.0001247556647285819, 0.9947452545166016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.074847912415862e-05, 0.0002652601688168943, 0.00011011176684405655, 0.00021231926803011447, 8.290550613310188e-05, 0.0011814204044640064, 1.5688703570049256e-05, 0.0016655954532325268, 1.1725322110578418e-05, 0.0020509432069957256, 0.00013842585030943155, 1.557362156745512e-05, 1.1507408089528326e-05, 9.066184247785714e-06, 0.00022655780776403844, 0.9939122200012207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00044135446660220623, 0.0006528966478072107, 0.0006495668785646558, 9.39807141548954e-05, 4.1127124859485775e-05, 0.00017028441652655602, 0.0005066706798970699, 2.889609277190175e-05, 0.002370184753090143, 0.00010454314178787172, 1.9230965335736983e-05, 0.47055861353874207, 1.6804015103843994e-05, 0.002284094225615263, 0.0002169813815271482, 3.276942879892886e-05, 0.5218120217323303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005350514547899365, 0.0006631249561905861, 0.00018957482825499028, 0.00011594546231208369, 3.930590901290998e-05, 8.452105976175517e-05, 0.0002685999497771263, 0.0003003481251653284, 0.00012727586727123708, 0.0001536341296741739, 2.152451270376332e-05, 0.00041020181379280984, 0.0015090395463630557, 0.00011659023584797978, 0.00013773961109109223, 7.38914095563814e-05, 0.00039899442344903946, 0.9948545694351196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002235247375210747, 0.0002502534771338105, 0.00011739339242922142, 1.8608268874231726e-05, 0.0006291492027230561, 0.0007579223602078855, 3.784089858527295e-05, 0.0033851468469947577, 1.791827889974229e-05, 0.00017818278865888715, 3.4344302548561245e-05, 7.747583731543273e-05, 6.471157394116744e-05, 1.5270292351488024e-05, 0.00029359618201851845, 0.0005734388250857592, 7.154398190323263e-05, 0.00015883143350947648, 0.993094801902771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00030641001649200916, 0.00041680067079141736, 0.00045197163126431406, 0.00015746380086056888, 0.0015800745459273458, 0.0022666300646960735, 0.00014483602717518806, 0.002518873196095228, 4.471185457077809e-05, 0.0027394674252718687, 0.0004348975489847362, 0.00015683105448260903, 2.8505710361059755e-05, 4.005823939223774e-05, 0.000593667384237051, 0.00011775208986364305, 0.00014039620873518288, 0.00018060374713968486, 0.000964188133366406, 0.9867159128189087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009046883322298527, 0.0007260903948917985, 6.491786189144477e-05, 4.578270090860315e-05, 3.669531724881381e-05, 3.389696212252602e-05, 4.1313247493235394e-05, 9.000120189739391e-05, 0.016163920983672142, 1.895378591143526e-05, 3.351377745275386e-05, 0.002181082731112838, 5.341176802176051e-06, 0.018749451264739037, 0.00017897749785333872, 0.00049936881987378, 0.0024355670902878046, 4.2716070311143994e-05, 7.329296204261482e-05, 1.9154376786900684e-05, 0.9495131969451904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00021946315246168524, 0.0011669575469568372, 0.00021983245096635073, 0.000987629871815443, 0.00031338492408394814, 0.00012072655226802453, 5.631538442685269e-06, 2.4260069039883092e-05, 4.5442018745234236e-05, 1.8529613953433e-05, 1.4025728887645528e-05, 1.0154997653444298e-05, 0.0004018025065306574, 4.052646545460448e-05, 0.0001710674405330792, 9.8690579761751e-06, 9.488572686677799e-06, 0.0003931091050617397, 5.709419838240137e-06, 1.78443115146365e-05, 2.8530441340990365e-05, 0.9957762360572815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00019360966689419, 0.0008434188202954829, 0.0005215293494984508, 2.5664539862191305e-05, 0.0004623319546226412, 0.00025401570019312203, 1.8471217117621563e-05, 0.00011509784235386178, 0.0002728897088672966, 0.0001543665857752785, 1.2149133908678778e-05, 0.0006913738907314837, 5.695979780284688e-05, 0.00024024760932661593, 3.827492764685303e-05, 9.934448462445289e-05, 0.0006488916114903986, 8.011733007151634e-05, 0.00019218819215893745, 2.552944715716876e-05, 0.00032434772583656013, 0.0010871071135625243, 0.9936420321464539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001607762067578733, 0.17697355151176453, 0.015483579598367214, 0.0003713874612003565, 0.0003786337038036436, 0.0001645270676817745, 0.0003277379728388041, 0.00016989692812785506, 0.002122961450368166, 3.573095455067232e-05, 6.090143870096654e-05, 0.0004562163958325982, 1.544778933748603e-05, 0.002254315186291933, 0.0015666879480704665, 0.00011843751417472959, 0.00046998911420814693, 5.0373157137073576e-05, 0.00012108059308957309, 6.008965283399448e-05, 0.0008920569671317935, 0.0007518448401242495, 0.0002689965476747602, 0.7952778339385986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003919860755559057, 0.00021421183191705495, 0.0005306116072461009, 1.0745787221821956e-05, 0.00011862369865411893, 4.2257714085280895e-05, 0.0002116035611834377, 4.6925462811486796e-05, 0.00044815789442509413, 0.0001069127902155742, 3.935461791115813e-05, 0.00016830845561344177, 0.00017352333816234022, 0.00045245056389831007, 0.00014294101856648922, 0.00011699317838065326, 0.00017526798183098435, 0.00010119943908648565, 4.251387144904584e-05, 2.037170452240389e-05, 3.837128315353766e-05, 0.00011344613449182361, 0.00025279278634116054, 6.991026748437434e-05, 0.995970606803894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00021530695084948093, 0.00010005839430959895, 0.002380918012931943, 0.0019831403624266386, 0.0011120118433609605, 5.563466766034253e-05, 0.0006109262467361987, 0.0002456435759086162, 8.819004870019853e-05, 0.0011510398471727967, 0.00010669898620108142, 0.00017554867372382432, 5.736272214562632e-05, 7.814793207217008e-05, 0.00024573446717113256, 9.59466979111312e-06, 0.00017032392497640103, 2.8972674044780433e-05, 1.4011699022375979e-05, 0.00016692081408109516, 1.2888869605376385e-05, 0.000244955561356619, 0.0005147012416273355, 4.942109444527887e-05, 0.0005746558308601379, 0.9896071553230286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00011423406976973638, 0.0008627417264506221, 0.0007732232334092259, 0.0007090753642842174, 0.0007292137597687542, 0.001403162837959826, 0.00021403594291768968, 0.0001766648201737553, 6.622044020332396e-05, 3.215937249478884e-05, 0.00045330580906011164, 0.00012008492194581777, 2.2129028366180137e-05, 5.807503475807607e-05, 0.00012917433923576027, 1.9079670892097056e-05, 0.00011076666851295158, 8.564189556636848e-06, 2.363054773013573e-05, 0.00033799809170886874, 5.2118928579147905e-05, 0.0001445568195777014, 0.00019694949151016772, 0.0004510525905061513, 2.057626443274785e-05, 8.764302765484899e-05, 0.9926835894584656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00019798318680841476, 0.00019567922572605312, 0.00022612222528550774, 0.00041943631367757916, 0.0005979692214168608, 0.0004517437773756683, 0.00034782872535288334, 0.0002585809852462262, 2.8019851015415043e-05, 0.0007220002007670701, 0.00013010443944949657, 0.0011632051318883896, 6.916901475051418e-05, 2.4789105736999772e-05, 0.00010386004578322172, 0.00038124900311231613, 0.0011587797198444605, 0.0003314440546091646, 0.00024494522949680686, 0.0001275516115128994, 0.0001609843602636829, 1.9267865354777314e-05, 0.0002717415918596089, 2.0765532099176198e-05, 6.82506724842824e-05, 0.0008764249505475163, 0.000678215641528368, 0.9907240271568298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.157182800350711e-05, 0.0006791104678995907, 0.0007090707076713443, 0.00024164833303075284, 0.00041205380694009364, 0.0009237417252734303, 0.00020848539134021848, 6.639285857090726e-05, 0.00011664817429846153, 8.601925947004929e-05, 0.010591291822493076, 0.00033729069400578737, 2.1898467821301892e-05, 0.00010110715084010735, 0.00010436092270538211, 5.8587360399542376e-05, 0.00032512095640413463, 1.5854115190450102e-05, 5.03360297443578e-06, 0.00040948984678834677, 1.3119491086399648e-05, 5.313343717716634e-05, 1.1887247637787368e-05, 5.5366654123645276e-05, 1.2197681826364715e-05, 8.952635107561946e-05, 0.002243548631668091, 0.0002104189625242725, 0.9818660616874695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007582924445159733, 0.0012331459438428283, 8.604941103840247e-05, 6.291332101682201e-05, 2.8791788281523623e-05, 3.316687434562482e-05, 7.622719567734748e-05, 0.00010868187382584438, 0.006450857501477003, 0.0001478909543948248, 1.0376495993114077e-05, 0.0023889727890491486, 7.883606303948909e-05, 0.007510701660066843, 0.0002874316123779863, 0.0001367574732284993, 0.002760297618806362, 0.0007447169627994299, 8.811110456008464e-05, 2.4702098016859964e-05, 0.006188873201608658, 0.00011647059727692977, 0.00017244012269657105, 0.0002621751045808196, 0.00018419795378576964, 4.432135756360367e-05, 4.855170482187532e-05, 8.903061097953469e-05, 2.6887826606980525e-05, 0.9698501229286194, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002462745178490877, 0.00035919941728934646, 0.00020521896658465266, 9.387754107592627e-05, 8.577331027481705e-05, 5.495216100825928e-05, 4.531839658739045e-05, 1.0722179467848036e-05, 4.867117604590021e-05, 0.00011017607903340831, 0.00010064091475214809, 9.772245539352298e-05, 0.0005496814846992493, 4.362943582236767e-05, 3.9457921957364306e-05, 7.140226807678118e-05, 9.81435805442743e-05, 5.7009699958143756e-05, 2.4251130525954068e-05, 2.3145676095737144e-06, 5.05694406456314e-05, 0.00011318492033751681, 0.00029069941956549883, 6.889968790346757e-05, 0.0006683265673927963, 0.0002321746142115444, 8.348713890882209e-06, 1.743464781611692e-05, 1.0273119187331758e-05, 0.0001388570381095633, 0.9960569143295288, 0.0, 0.0, 0.0, 0.0], [0.00011105906014563516, 3.59915939043276e-05, 4.416057709022425e-05, 0.000225963638513349, 0.00024025869788601995, 1.7348933397443034e-05, 7.204298162832856e-05, 0.0002373898751102388, 8.274747960967943e-05, 0.00010178551019635051, 7.876389645389281e-06, 6.391833449015394e-05, 3.295210990472697e-05, 7.889195694588125e-05, 0.00011627462663454935, 7.139148237911286e-06, 6.571759877260774e-05, 5.3963635764375795e-06, 8.33402282296447e-06, 1.9613898984971456e-05, 4.11063629144337e-05, 8.538003021385521e-05, 3.1616138585377485e-05, 9.91699198493734e-06, 2.3832410079194233e-05, 0.0018293517641723156, 2.6111230909009464e-05, 3.3135107514681295e-05, 1.461270858271746e-05, 0.0008547278121113777, 0.00016745159518904984, 0.9953078627586365, 0.0, 0.0, 0.0], [0.0022552248556166887, 0.0004647754249162972, 0.00012283753312658519, 0.006661214865744114, 8.828951831674203e-05, 0.00024942762684077024, 0.00017555151134729385, 2.656347533047665e-05, 0.004149142652750015, 0.00020833106827922165, 1.597336449776776e-05, 0.0007248223409987986, 1.231808346346952e-05, 0.004929245449602604, 0.0007067776750773191, 2.7460220735520124e-05, 0.0008252456318587065, 5.1487324526533484e-05, 9.107245205086656e-06, 0.0011702000629156828, 0.0011320505291223526, 0.0003872279485221952, 0.00010000276961363852, 0.0005395385669544339, 0.00012797686213161796, 7.418715540552512e-05, 0.0006351851625367999, 5.991848956909962e-05, 0.00020302357734180987, 0.022641262039542198, 7.111399463610724e-05, 0.003479855600744486, 0.947674572467804, 0.0, 0.0], [0.00010488830594113097, 0.0005403999239206314, 0.0002700613404158503, 2.7820002287626266e-05, 0.0008878550142981112, 0.00025317323161289096, 0.0002921410487033427, 0.0009951486717909575, 3.943215779145248e-05, 6.531640246976167e-05, 5.198342842049897e-05, 0.0006716360803693533, 1.9524222807376646e-05, 3.796441524173133e-05, 0.0003154709411319345, 0.00015760367386974394, 0.0006809124606661499, 0.00017366770771332085, 0.0002327592665096745, 0.0004935214528813958, 0.00015254261961672455, 8.968886686488986e-05, 0.0014225832419469953, 0.00022503116633743048, 0.0001539226941531524, 0.00010696918616304174, 0.005650249309837818, 0.0008653252734802663, 0.0002874955243896693, 0.00013868528185412288, 1.4354200175148435e-05, 2.81620305031538e-05, 0.00011612025991780683, 0.9844375848770142, 0.0], [0.001883037039078772, 0.0002301395288668573, 7.19053641660139e-05, 3.798290890699718e-06, 0.002256361534819007, 4.367974543129094e-05, 0.0001278294512303546, 0.0006368020549416542, 0.0005363994278013706, 5.325703568814788e-06, 7.917847688077018e-05, 2.60159868048504e-05, 1.1253255252086092e-05, 0.0005611243541352451, 9.103791853704024e-06, 0.00021052229567430913, 2.689111715881154e-05, 3.242438833694905e-05, 0.0002593934768810868, 0.00045266668894328177, 0.0011520993430167437, 1.1493529200379271e-05, 4.818234810954891e-05, 0.00010571501479716972, 8.452797919744626e-05, 0.00010020854097092524, 2.848370604624506e-05, 2.0415431208675727e-05, 1.8022955146079767e-06, 7.628954335814342e-05, 4.6043314796406776e-05, 9.9735647381749e-05, 5.258399141894188e-06, 0.00019488483667373657, 0.9905610680580139]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9424744844436646, 0.05752556398510933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8506749868392944, 0.09740973263978958, 0.051915328949689865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7641512751579285, 0.10970378667116165, 0.07497041672468185, 0.05117451399564743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6748190522193909, 0.08416198194026947, 0.054702531546354294, 0.07581549137830734, 0.11050093173980713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6857607364654541, 0.08229528367519379, 0.052021175622940063, 0.08139178901910782, 0.04085880517959595, 0.05767223984003067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6174606084823608, 0.05653452128171921, 0.09111695736646652, 0.06854882091283798, 0.06338420510292053, 0.03596974164247513, 0.066985122859478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6047279834747314, 0.06088966503739357, 0.05921151489019394, 0.09558156877756119, 0.042659129947423935, 0.031843431293964386, 0.042630650103092194, 0.06245602294802666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4008438289165497, 0.07533580809831619, 0.042708419263362885, 0.011760729365050793, 0.02668057195842266, 0.01349207665771246, 0.028465470299124718, 0.01390060130506754, 0.3868124783039093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49680259823799133, 0.06792881339788437, 0.05792006477713585, 0.07101531326770782, 0.06963258981704712, 0.018800102174282074, 0.06757563352584839, 0.06346483528614044, 0.06656690686941147, 0.020293204113841057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5176078081130981, 0.08289013803005219, 0.05239768326282501, 0.06842362135648727, 0.04608829692006111, 0.026865946128964424, 0.08181481808423996, 0.03230837732553482, 0.05516275763511658, 0.018549619242548943, 0.01789088360965252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3038182556629181, 0.03185644373297691, 0.02915770374238491, 0.011053649708628654, 0.013536774553358555, 0.016536902636289597, 0.015181961469352245, 0.01551173534244299, 0.026294974610209465, 0.0168909952044487, 0.011886665597558022, 0.5082739591598511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3585987985134125, 0.07880907505750656, 0.059028659015893936, 0.044458676129579544, 0.07822324335575104, 0.019679518416523933, 0.051331207156181335, 0.04009842500090599, 0.08024682104587555, 0.02781190536916256, 0.010250619612634182, 0.13610360026359558, 0.015359464101493359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2511676251888275, 0.04623398557305336, 0.02783856727182865, 0.007056493312120438, 0.01724417321383953, 0.008997929282486439, 0.017309946939349174, 0.009924139827489853, 0.25275108218193054, 0.012778297066688538, 0.008546075783669949, 0.04791995882987976, 0.006098275538533926, 0.28613337874412537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39800775051116943, 0.06433819979429245, 0.049798544496297836, 0.059495650231838226, 0.03182113543152809, 0.0307147353887558, 0.05899552255868912, 0.05480390414595604, 0.03919370844960213, 0.03556445986032486, 0.024916481226682663, 0.04571932554244995, 0.016671665012836456, 0.038943100720644, 0.051015838980674744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3903382420539856, 0.0754939392209053, 0.03844676911830902, 0.043667785823345184, 0.017820749431848526, 0.01271218154579401, 0.04530724138021469, 0.03603021055459976, 0.042170681059360504, 0.01675303280353546, 0.0422486774623394, 0.0509234182536602, 0.030772075057029724, 0.04072083905339241, 0.05648886784911156, 0.060105253010988235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1818235218524933, 0.018224777653813362, 0.017477909103035927, 0.006372256204485893, 0.007922588847577572, 0.01006288081407547, 0.008703161962330341, 0.010297482833266258, 0.015354447066783905, 0.011538181453943253, 0.007091047707945108, 0.3139554262161255, 0.0060198185965418816, 0.015887578949332237, 0.015422005206346512, 0.013188592158257961, 0.3406583368778229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23881423473358154, 0.07684360444545746, 0.04843559488654137, 0.028319768607616425, 0.042976249009370804, 0.019430750980973244, 0.03321721404790878, 0.027472922578454018, 0.018975932151079178, 0.04046749696135521, 0.020095612853765488, 0.05857318267226219, 0.03530573472380638, 0.019691884517669678, 0.09703770279884338, 0.03909805044531822, 0.061994519084692, 0.09324946999549866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3563612401485443, 0.04354535788297653, 0.0543937012553215, 0.03599720075726509, 0.055608730763196945, 0.03285680338740349, 0.019443854689598083, 0.06911692023277283, 0.020649442449212074, 0.03360532596707344, 0.027618741616606712, 0.03408000245690346, 0.02684745565056801, 0.020337311550974846, 0.022298937663435936, 0.036227356642484665, 0.034644752740859985, 0.022655004635453224, 0.05371185019612312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3967011272907257, 0.05178235098719597, 0.039961930364370346, 0.06630745530128479, 0.045571859925985336, 0.02398340031504631, 0.01939675584435463, 0.021365977823734283, 0.020253777503967285, 0.036855824291706085, 0.009492042474448681, 0.041810017079114914, 0.014498689211905003, 0.019783735275268555, 0.029715238139033318, 0.046315453946590424, 0.042466454207897186, 0.03147520124912262, 0.02202763967216015, 0.020235029980540276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2315138727426529, 0.13258197903633118, 0.0602610819041729, 0.01138360146433115, 0.024262722581624985, 0.01455346867442131, 0.016979562118649483, 0.013957405462861061, 0.02247590944170952, 0.027721282094717026, 0.02060709521174431, 0.040846824645996094, 0.027723226696252823, 0.02455071359872818, 0.03857921063899994, 0.04770100861787796, 0.04407113417983055, 0.07720746099948883, 0.046044714748859406, 0.04773344472050667, 0.02924429252743721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20264172554016113, 0.04893084242939949, 0.038946814835071564, 0.026632292196154594, 0.040943484753370285, 0.016175054013729095, 0.04388014227151871, 0.04927310347557068, 0.0374428927898407, 0.018747955560684204, 0.010438336059451103, 0.03027418442070484, 0.011668812483549118, 0.03915901109576225, 0.0836191177368164, 0.026806535199284554, 0.03237595781683922, 0.026771049946546555, 0.041368670761585236, 0.04380548745393753, 0.09921547025442123, 0.03088301047682762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22999967634677887, 0.029275385662913322, 0.024823682382702827, 0.030747536569833755, 0.024439770728349686, 0.0250781811773777, 0.01904827542603016, 0.04161752015352249, 0.02524642087519169, 0.05536346510052681, 0.013840350322425365, 0.03206312283873558, 0.023373719304800034, 0.02689637988805771, 0.037655871361494064, 0.02870968170464039, 0.03498142957687378, 0.038269270211458206, 0.05304878577589989, 0.07750774174928665, 0.042357511818408966, 0.0629706084728241, 0.02268563210964203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2523007094860077, 0.04309259355068207, 0.047794342041015625, 0.02153482288122177, 0.05364762991666794, 0.014357623644173145, 0.016968194395303726, 0.012399846687912941, 0.028107941150665283, 0.022964561358094215, 0.013637302443385124, 0.03462432697415352, 0.013057571835815907, 0.029753565788269043, 0.025925690308213234, 0.03689541295170784, 0.03646587207913399, 0.020091162994503975, 0.03424844145774841, 0.032270632684230804, 0.07516519725322723, 0.033814020454883575, 0.05794446915388107, 0.04293809086084366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24815592169761658, 0.0418383851647377, 0.03725353255867958, 0.019914183765649796, 0.060311757028102875, 0.013761507347226143, 0.01023701298981905, 0.027118362486362457, 0.021247489377856255, 0.014996419660747051, 0.015956413000822067, 0.019741930067539215, 0.01694285310804844, 0.02278241701424122, 0.021159427240490913, 0.01341978833079338, 0.02113155648112297, 0.015880078077316284, 0.03851574286818504, 0.03509928658604622, 0.06386469304561615, 0.04215894639492035, 0.05595177412033081, 0.06510591506958008, 0.057454630732536316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24590614438056946, 0.039794620126485825, 0.034050047397613525, 0.03872010111808777, 0.028344355523586273, 0.024568263441324234, 0.013687246479094028, 0.01988093927502632, 0.017507929354906082, 0.04131213203072548, 0.024649064987897873, 0.017028072848916054, 0.015493782237172127, 0.01803991198539734, 0.02871253527700901, 0.00894533284008503, 0.017858823761343956, 0.029846539720892906, 0.026982231065630913, 0.06119256466627121, 0.03972141072154045, 0.04008691385388374, 0.04656379669904709, 0.04659209027886391, 0.046358175575733185, 0.028156954795122147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.242995023727417, 0.03093666210770607, 0.037281107157468796, 0.029979800805449486, 0.03951822966337204, 0.020689722150564194, 0.02446378953754902, 0.016162265092134476, 0.02351461909711361, 0.015184110961854458, 0.009779488667845726, 0.010400430299341679, 0.00883074663579464, 0.02398892305791378, 0.024419227614998817, 0.03784200921654701, 0.010589987970888615, 0.013367552310228348, 0.0162633266299963, 0.09984056651592255, 0.02563280053436756, 0.027902817353606224, 0.05468779057264328, 0.03170407935976982, 0.027479570358991623, 0.016517242416739464, 0.08002806454896927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24383299052715302, 0.021781539544463158, 0.01905849762260914, 0.02660839818418026, 0.03740561008453369, 0.02708663046360016, 0.0050316075794398785, 0.026656057685613632, 0.017429368570446968, 0.028662465512752533, 0.012151014991104603, 0.03022322990000248, 0.0140682989731431, 0.018160909414291382, 0.015435303561389446, 0.01572182960808277, 0.03215308487415314, 0.024972990155220032, 0.04793378338217735, 0.045989975333213806, 0.031192155554890633, 0.03841525316238403, 0.037881236523389816, 0.03472229093313217, 0.035507507622241974, 0.03336033970117569, 0.05460802838206291, 0.023949556052684784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3087880611419678, 0.040824342519044876, 0.010766173712909222, 0.02708977274596691, 0.019433291628956795, 0.03355548530817032, 0.010839526541531086, 0.01149557065218687, 0.011286423541605473, 0.019319292157888412, 0.03442364186048508, 0.010595869272947311, 0.019463734701275826, 0.011577978730201721, 0.014172404073178768, 0.02159341238439083, 0.010569152422249317, 0.01821252517402172, 0.007991206832230091, 0.05231866613030434, 0.019707782194018364, 0.035325199365615845, 0.02959824912250042, 0.028512969613075256, 0.02101978100836277, 0.018976135179400444, 0.031007932499051094, 0.017736954614520073, 0.10379855334758759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11270298063755035, 0.013211610727012157, 0.015115493908524513, 0.008062336593866348, 0.018075060099363327, 0.020267315208911896, 0.009121795184910297, 0.021654397249221802, 0.024600312113761902, 0.012220281176269054, 0.005230679642409086, 0.021195195615291595, 0.007505763787776232, 0.027240077033638954, 0.0168289877474308, 0.009307198226451874, 0.0237741656601429, 0.009840190410614014, 0.02352040819823742, 0.0180962011218071, 0.11592711508274078, 0.008296091109514236, 0.01503841858357191, 0.016261838376522064, 0.022837121039628983, 0.007970292121171951, 0.010345992632210255, 0.013601294718682766, 0.009923162870109081, 0.36222824454307556, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19907145202159882, 0.023352961987257004, 0.02753552421927452, 0.02074119821190834, 0.049442391842603683, 0.039645493030548096, 0.011580482125282288, 0.038496050983667374, 0.012212725356221199, 0.012634873390197754, 0.018897853791713715, 0.011502721346914768, 0.014417950063943863, 0.012855138629674911, 0.01591630093753338, 0.009284348227083683, 0.011929103173315525, 0.014574798755347729, 0.02956238016486168, 0.030921466648578644, 0.049348846077919006, 0.026833010837435722, 0.03316975012421608, 0.02651391550898552, 0.038417842239141464, 0.03666592016816139, 0.03740684315562248, 0.03744916990399361, 0.041813697665929794, 0.04080501198768616, 0.027000796049833298, 0.0, 0.0, 0.0, 0.0], [0.13580846786499023, 0.02159818820655346, 0.028431465849280357, 0.021366795524954796, 0.03184176981449127, 0.028310758993029594, 0.011232445947825909, 0.016139335930347443, 0.023436741903424263, 0.025144271552562714, 0.012804528698325157, 0.01200050301849842, 0.02091227099299431, 0.025003299117088318, 0.027692237868905067, 0.017305919900536537, 0.012859742157161236, 0.01606629602611065, 0.03279004245996475, 0.03829026594758034, 0.060804788023233414, 0.03674997761845589, 0.0352473147213459, 0.03857800364494324, 0.03904816508293152, 0.036643389612436295, 0.014530431479215622, 0.02163226343691349, 0.010490997694432735, 0.06733931601047516, 0.03867284581065178, 0.04122709482908249, 0.0, 0.0, 0.0], [0.13088135421276093, 0.023744333535432816, 0.0201143529266119, 0.009702397510409355, 0.02695222944021225, 0.013591095805168152, 0.009517530910670757, 0.013271704316139221, 0.027617931365966797, 0.011498380452394485, 0.008886140771210194, 0.016865815967321396, 0.009971975348889828, 0.031318601220846176, 0.01495381724089384, 0.015636594966053963, 0.01875588297843933, 0.008822468109428883, 0.02425832487642765, 0.01859987899661064, 0.06659714132547379, 0.02393534407019615, 0.030215002596378326, 0.038479700684547424, 0.06054788827896118, 0.03886096179485321, 0.021039558574557304, 0.026919951662421227, 0.03078671544790268, 0.0633939579129219, 0.053022902458906174, 0.07499753683805466, 0.016242535784840584, 0.0, 0.0], [0.21679528057575226, 0.03523937612771988, 0.01448057685047388, 0.03231681138277054, 0.021502694115042686, 0.019766855984926224, 0.007716964464634657, 0.03142577409744263, 0.011421254836022854, 0.03985080122947693, 0.005697546061128378, 0.013826759532094002, 0.011217723600566387, 0.011028866283595562, 0.0143423555418849, 0.01669159345328808, 0.013800648972392082, 0.00905416626483202, 0.016551576554775238, 0.04516449198126793, 0.01674339734017849, 0.04049498215317726, 0.04600658640265465, 0.039180245250463486, 0.020771801471710205, 0.04241836071014404, 0.029444055631756783, 0.01654653064906597, 0.0433904305100441, 0.01802881620824337, 0.017493009567260742, 0.031954456120729446, 0.023179978132247925, 0.026455210521817207, 0.0], [0.12406577169895172, 0.05575519800186157, 0.025793127715587616, 0.007745688781142235, 0.019214725121855736, 0.011872387491166592, 0.009303719736635685, 0.0158426184207201, 0.012728424742817879, 0.012888258323073387, 0.013962898403406143, 0.01662725768983364, 0.015507101081311703, 0.013195222243666649, 0.01732509955763817, 0.021147968247532845, 0.017335494980216026, 0.015824295580387115, 0.024794377386569977, 0.01190303172916174, 0.03651022911071777, 0.023874733597040176, 0.04022133722901344, 0.06286037713289261, 0.10149350762367249, 0.053322602063417435, 0.02168961614370346, 0.018244285136461258, 0.00840698555111885, 0.023202305659651756, 0.04960416257381439, 0.020869310945272446, 0.016017954796552658, 0.011101935058832169, 0.04974794387817383]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10778012126684189, 0.8922198414802551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011847443878650665, 0.5536144971847534, 0.4345380365848541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06322271376848221, 0.021719155833125114, 0.09427293390035629, 0.8207851648330688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005095744971185923, 0.0005348753184080124, 0.0010105489054694772, 0.004657563753426075, 0.9887012243270874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005585952196270227, 0.00030240038176998496, 0.0007955086184665561, 0.000678032694850117, 0.028760135173797607, 0.9638778567314148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00026657298440113664, 0.00015396179514937103, 4.344203625805676e-05, 0.0003163387009408325, 0.007582378573715687, 0.008635696955025196, 0.9830015897750854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006940618040971458, 4.8331738071283326e-05, 4.51133782917168e-05, 2.3520799004472792e-05, 0.0022377653513103724, 0.001208052271977067, 0.00932135060429573, 0.9864218235015869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04771990329027176, 0.006346914451569319, 0.0055076126009225845, 0.012776720337569714, 0.012552589178085327, 0.012200524099171162, 0.0077606067061424255, 0.017114857211709023, 0.8780202269554138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.403780859429389e-05, 7.299120738935017e-07, 1.2948523817613022e-06, 1.0040552069767728e-06, 1.519242869107984e-05, 3.6095178074901924e-05, 3.1514438887825236e-05, 0.0010808249935507774, 4.2368381400592625e-05, 0.9986969828605652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00029844240634702146, 1.0225176993117202e-05, 2.077381759590935e-05, 1.0716730685089715e-05, 7.45383367757313e-05, 0.00016580561350565404, 0.001366860349662602, 0.0025834825355559587, 5.024059646530077e-05, 0.3243955075740814, 0.6710233688354492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009233689866960049, 0.0007820426253601909, 0.0006810433696955442, 0.0018207868561148643, 0.0043833889067173, 0.01750914193689823, 0.0033242488279938698, 0.0176074355840683, 0.08099658787250519, 0.10943042486906052, 0.014291894622147083, 0.739939272403717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002393030736129731, 3.3237915886275005e-06, 2.283279172843322e-05, 1.024476659949869e-05, 1.0253623258904554e-05, 4.496401015785523e-05, 2.357668745389674e-05, 6.216618930920959e-05, 0.00032929476583376527, 0.00874954555183649, 0.001878871233202517, 0.0014183465391397476, 0.9872072339057922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012295344844460487, 0.0005298624164424837, 0.00035605113953351974, 0.000600671861320734, 0.000532753299921751, 0.0005349713028408587, 0.00034733518259599805, 0.0008671165560372174, 0.03432308882474899, 0.013273634947836399, 0.007531193550676107, 0.059418000280857086, 0.09377512335777283, 0.775614857673645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.850895053707063e-05, 1.18633588499506e-05, 5.970547135802917e-06, 4.359468675829703e-06, 6.933053100510733e-06, 5.567324842559174e-05, 8.762052857491653e-06, 2.213004518125672e-05, 0.000222383372602053, 0.0002802505623549223, 0.0008127276669256389, 0.0015677304472774267, 0.00018956426356453449, 0.005879418458789587, 0.9908536672592163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.475000115344301e-05, 8.603436072007753e-06, 3.744852165254997e-06, 1.4634181866313156e-07, 2.7017360935133183e-06, 1.1417348105169367e-05, 8.62081469676923e-06, 9.928095096256584e-05, 3.1195138490147656e-06, 0.00022620789241045713, 0.0005323346122168005, 2.980485987791326e-05, 0.0013675636146217585, 5.107997276354581e-05, 0.009570816531777382, 0.9879898428916931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003944714087992907, 0.00013029150431975722, 9.947719081537798e-05, 0.00019776365661527961, 0.00042658488382585347, 0.0014889850281178951, 0.0002834683400578797, 0.001535675604827702, 0.004810090642422438, 0.005567723419517279, 0.0010473616421222687, 0.040826573967933655, 0.009189031086862087, 0.09278517216444016, 0.015853017568588257, 0.027940914034843445, 0.7938732504844666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00021723586542066187, 2.3531161787104793e-05, 7.806292160239536e-06, 4.7329585868283175e-06, 1.567117919876182e-06, 8.667402653372847e-06, 1.2646223694900982e-05, 6.129271787358448e-05, 0.00018869442283175886, 0.000590129173360765, 0.0004205662407912314, 0.000974651426076889, 0.0004217766399960965, 0.004066708497703075, 0.001442242180928588, 0.011960018426179886, 0.022401923313736916, 0.9571957588195801, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000736045534722507, 3.0168180273904e-06, 1.355472249997547e-06, 1.4014716498422786e-06, 3.387705146451481e-05, 3.752294651349075e-05, 1.0748700333351735e-05, 0.0004302710294723511, 1.6196761862374842e-05, 0.0006748265004716814, 0.0005265924264676869, 0.00012409152986947447, 4.7107158025028184e-05, 0.00024138158187270164, 0.000688658154103905, 0.0003870209329761565, 0.002144154626876116, 0.0017651687376201153, 0.99213045835495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.529821803269442e-06, 4.013174681460896e-09, 4.275890752580835e-09, 9.052372185180957e-09, 5.135176479598158e-07, 3.731759534275625e-06, 1.4824270522240113e-07, 4.655122666008538e-06, 1.663049964406582e-08, 3.0296805562102236e-06, 3.1919844332151115e-05, 1.4017439298186218e-07, 4.954938503942685e-07, 2.3671027804539335e-07, 7.952955343171197e-07, 0.00018607293895911425, 2.446675580358715e-06, 1.198231075250078e-05, 0.0005082339630462229, 0.9992390871047974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0094178831204772, 0.00017362393555231392, 0.00019593223987612873, 0.00010542469681240618, 0.00012100092135369778, 0.00013750340440310538, 0.00020822319493163377, 0.00026208770577795804, 0.0009803799912333488, 0.00017425195255782455, 0.0013313923263922334, 0.0032773104030638933, 0.004840620793402195, 0.012378789484500885, 0.0018258984200656414, 0.024282028898596764, 0.054799634963274, 0.07428482919931412, 0.07759273052215576, 0.10845338553190231, 0.6251571178436279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00017886326531879604, 2.971776439153473e-06, 1.2879190762760118e-06, 1.6619660527794622e-06, 3.1533879791822983e-06, 7.608537998748943e-06, 4.4805625520893955e-07, 4.628845999832265e-06, 4.462066499399953e-06, 4.640815404854948e-06, 4.678119239542866e-06, 2.225518983323127e-05, 0.0006885039038024843, 5.880855314899236e-05, 5.511291601578705e-05, 0.0013147679856047034, 0.0004210406041238457, 0.0005279280012473464, 0.0003059153677895665, 0.0011363023659214377, 0.004935138393193483, 0.9903197884559631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0009000818245112896, 3.4609118301887065e-05, 6.000087068969151e-06, 1.3317927596290247e-06, 8.38242340250872e-06, 7.950181498017628e-06, 8.352956228918629e-07, 5.017455350753153e-06, 1.10855626189732e-05, 1.5506166164414026e-05, 2.244969073217362e-05, 3.239461511839181e-05, 7.153368642320856e-05, 0.00011106140300398692, 6.552076229127124e-06, 3.557855961844325e-05, 0.00046084250789135695, 0.0006021021399646997, 0.007735583931207657, 0.004731385502964258, 0.012920125387609005, 0.01699913665652275, 0.9552805423736572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.094504300970584e-05, 5.4195235861698166e-05, 2.1191000996623188e-05, 8.66032394242211e-07, 5.2413856792554725e-06, 2.8113959160691593e-06, 9.647644674259936e-07, 4.259611614543246e-06, 6.819939244451234e-06, 2.6370025807409547e-06, 1.0387340807938017e-05, 3.1177733035292476e-05, 2.5747020117705688e-05, 8.829349098959938e-05, 0.00010530044528422877, 0.00037444676854647696, 0.000583377608563751, 0.000901932711713016, 0.00043120095506310463, 0.004991116467863321, 0.0035159247927367687, 0.015127472579479218, 0.01838499866425991, 0.9552486538887024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001992677425732836, 5.897880441807501e-07, 4.093087113687943e-07, 5.283650352794211e-07, 4.0437427628603473e-07, 6.811440016463166e-07, 2.501958533684956e-07, 3.190993993484881e-07, 5.018010142521234e-06, 3.0599362617067527e-06, 4.776871264766669e-06, 8.10624987934716e-06, 1.7871061572805047e-05, 5.904932913836092e-05, 7.019503300398355e-06, 5.101946953800507e-05, 0.00015419672126881778, 0.00015557766892015934, 0.0004630949115380645, 0.00018736722995527089, 0.0029354498255997896, 0.006998695898801088, 0.004895060323178768, 0.010302482172846794, 0.9735496640205383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.041884312755428e-05, 7.668157664397768e-09, 6.183969958328817e-08, 4.109947226993427e-08, 3.1613333817404055e-07, 1.000401113060434e-07, 6.658505213863464e-08, 4.780262656822742e-07, 4.035145551029018e-08, 6.753223260602681e-06, 8.574266985306167e-08, 1.0514212078760465e-07, 3.2702735097700497e-06, 4.896527343589696e-07, 1.2450341273506638e-06, 9.069827683561016e-06, 2.0693071292043896e-06, 8.541695024177898e-06, 4.513616659096442e-05, 8.528171747457236e-05, 8.476238144794479e-05, 0.0010267900070175529, 0.0013347743079066277, 0.00029600696871057153, 0.005626779980957508, 0.9914274215698242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003747456066776067, 1.2430081142156268e-07, 2.5229135758308985e-07, 3.052446118090302e-07, 4.772525699081598e-06, 6.075436544961121e-07, 8.501713182340609e-07, 1.1030826499336399e-05, 8.098967185787842e-08, 9.651284926803783e-07, 7.193352189460711e-07, 3.233935217394901e-07, 1.760539589668042e-06, 4.446817740699771e-07, 3.2987631470859924e-07, 2.4300254153786227e-05, 3.6642647955886787e-06, 3.0616429285146296e-06, 2.627123103593476e-05, 0.0003426712064538151, 2.0788162146345712e-05, 0.00013409748498816043, 0.0003047241480089724, 9.803599095903337e-05, 0.0004919680068269372, 0.004237066023051739, 0.9939160943031311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00023197566042654216, 7.363608460764226e-07, 1.0658028486432158e-06, 4.7497891841885576e-07, 2.187780410167761e-06, 2.0741656499012606e-06, 1.3842078772086097e-07, 2.5106405701080803e-06, 1.971591530036676e-07, 6.6719812821247615e-06, 8.991777349365293e-07, 6.362178623930959e-07, 6.54478981232387e-07, 7.71795953369292e-07, 4.801884188054828e-07, 1.1122274372610264e-05, 5.561904345086077e-06, 3.862742687488208e-06, 6.753690831828862e-05, 0.0002897945523727685, 4.372486364445649e-05, 0.0001520898222224787, 0.0009337703813798726, 0.00018159403407480568, 8.423287363257259e-05, 0.009933846071362495, 0.00872314628213644, 0.9793182611465454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001570491585880518, 3.1231866159942e-07, 2.931937217454106e-07, 3.137160149435658e-07, 2.196094328610343e-06, 1.416437385159952e-06, 1.1236390946578467e-06, 1.3091786286167917e-06, 5.921503998251865e-08, 7.978082408044429e-07, 2.8036795356456423e-06, 1.9766959269418294e-07, 3.9940181295605726e-07, 2.3048993114116456e-07, 2.2642550447926624e-06, 1.6729478375054896e-05, 1.6667632962708012e-06, 2.8725464744638884e-06, 2.4946944904513657e-05, 0.000255328108323738, 4.849699962505838e-06, 4.708060805569403e-05, 5.325665188138373e-05, 4.240333510097116e-05, 0.00020874878100585192, 0.002043810673058033, 0.08346720784902573, 0.003673004684969783, 0.9099873304367065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010030783014371991, 7.6059291131969076e-06, 5.478914772538701e-06, 4.704095772467554e-06, 1.081826439985889e-06, 7.246848667818995e-07, 6.05722732416325e-07, 1.5847862187001738e-06, 3.183097578585148e-05, 1.8444867464495474e-06, 1.372381689179747e-06, 6.841019057901576e-06, 4.996121333533665e-06, 0.00014220476441551, 2.102600319631165e-06, 2.046115514531266e-05, 6.875464896438643e-05, 8.339442138094455e-05, 7.060833013383672e-05, 0.0002227009244961664, 0.001345351804047823, 0.0011953135253861547, 0.0007637708331458271, 0.0034127647522836924, 0.009595116600394249, 0.008245964534580708, 0.004028412513434887, 0.015673451125621796, 0.03710906207561493, 0.916948676109314, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001459806226193905, 1.3442446800127072e-07, 3.0679700557811884e-07, 1.270083913595954e-07, 9.539687795268037e-08, 4.421364252493731e-08, 7.270958946037354e-09, 2.1630643232128932e-07, 1.7861789558537566e-07, 1.1440956626529442e-07, 4.546703280539077e-08, 1.1406693545268354e-07, 1.7846363675744215e-07, 8.568713383283466e-07, 1.0497500113615388e-07, 1.2474934010242578e-06, 1.1682669764923048e-06, 6.484989967248111e-07, 9.92306559055578e-06, 2.663562190718949e-05, 2.1481049770954996e-05, 7.192366319941357e-05, 0.00015873332449700683, 0.00014563243894372135, 0.002426169579848647, 0.0015144959324970841, 0.0007063171942718327, 0.0022442848421633244, 0.004566820338368416, 0.0098323505371809, 0.9781236052513123, 0.0, 0.0, 0.0, 0.0], [1.069877362169791e-05, 5.128429236833654e-08, 7.382501365782446e-08, 9.797533095934341e-08, 4.944888019053906e-07, 6.26972450845642e-07, 2.625736783556931e-07, 7.361940106420661e-07, 2.510118690679519e-07, 2.1764876692031976e-06, 5.363761488297314e-07, 8.606898518337402e-07, 2.15158095784318e-07, 1.0358799045206979e-06, 2.489508972303156e-07, 1.3481056157615967e-05, 8.521090421709232e-06, 5.148511263541877e-06, 4.645090939447982e-06, 1.6832656910992227e-05, 5.864661216037348e-05, 3.652455416158773e-05, 0.0001648572797421366, 1.194501146528637e-05, 0.0005173988756723702, 0.0024279106874018908, 0.00034773556399159133, 0.001596406102180481, 0.009022929705679417, 0.0131637342274189, 0.06333828717470169, 0.9092466831207275, 0.0, 0.0, 0.0], [0.0012287315912544727, 8.40765733300941e-06, 8.36397612147266e-06, 8.199041985790245e-06, 3.972181730205193e-06, 3.98727206629701e-06, 1.5942525806167396e-06, 4.764995537698269e-06, 4.4619187065109145e-06, 8.699216778040864e-06, 3.4823106034309603e-06, 4.087222350790398e-06, 4.383185569167836e-06, 1.2878696907137055e-05, 2.7650021365843713e-06, 1.1550820090633351e-05, 2.8508402465377003e-05, 1.972618883883115e-05, 8.00795532995835e-05, 0.00016381594468839467, 0.00027661045896820724, 0.0004829977115150541, 0.0005903012352064252, 0.0011750631965696812, 0.003466710913926363, 0.005802728235721588, 0.011907555162906647, 0.016952987760305405, 0.028466511517763138, 0.06137577071785927, 0.1151759997010231, 0.20177730917930603, 0.5509369969367981, 0.0, 0.0], [3.7825222534593195e-05, 6.459638512978927e-08, 1.9273654672247176e-08, 7.97582799805241e-08, 6.70032989091851e-07, 1.246432361767802e-07, 3.072165100093116e-08, 3.367146348409733e-07, 9.954005975032487e-08, 4.541520297607349e-07, 3.406023196816932e-08, 1.7256137141430372e-07, 3.3590222869861464e-07, 3.2563374929850397e-07, 1.1636628549638317e-08, 3.2042125894804485e-06, 1.2533513427115395e-06, 1.7663039670878788e-06, 1.1125961464131251e-05, 2.0410294382600114e-05, 8.103446816676296e-06, 1.2881072507298086e-05, 0.0001419320615241304, 1.1411116247472819e-05, 0.00010671327618183568, 0.00010951135482173413, 0.0017927108565345407, 0.0015404949663206935, 0.0012465217150747776, 0.001597587252035737, 0.0008927045855671167, 0.009557021781802177, 0.009279942139983177, 0.9736242294311523, 0.0], [0.0003539702738635242, 2.644042524480028e-06, 1.7576187474332983e-06, 1.2348102700343588e-06, 5.949696969764773e-06, 1.3091880646243226e-06, 3.362112579452514e-07, 2.4850550062183174e-07, 6.705453188260435e-07, 6.699517740571537e-08, 6.061940212021e-07, 4.6190581315386225e-07, 2.3573320504510775e-06, 1.4622218031945522e-06, 2.976372286411788e-07, 1.6005819816200528e-06, 2.4609041702206014e-06, 1.93171831597283e-06, 3.200153514626436e-05, 2.4652015781612135e-05, 3.429641219554469e-05, 0.00016550855070818216, 7.883973739808425e-05, 0.00018387149611953646, 0.0011651519453153014, 0.00012255352339707315, 0.0011725194053724408, 0.0004984785919077694, 0.003501486498862505, 0.0034007455687969923, 0.011839520186185837, 0.005179095547646284, 0.01671386882662773, 0.02912766858935356, 0.9263803958892822]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9238102436065674, 0.076189786195755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3758925199508667, 0.10050597041845322, 0.5236014723777771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4121372103691101, 0.08231587707996368, 0.18084770441055298, 0.32469916343688965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14052286744117737, 0.005812318529933691, 0.02827639877796173, 0.057330358773469925, 0.7680581212043762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01923070289194584, 0.0014746824745088816, 0.0016810809029266238, 0.004905843175947666, 0.02590659074485302, 0.9468010663986206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006040879059582949, 0.00465822359547019, 0.012865043245255947, 0.008953888900578022, 0.07021678984165192, 0.12025337666273117, 0.7770117521286011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016248270869255066, 0.003929380793124437, 0.01283666305243969, 0.0050996290519833565, 0.017354188486933708, 0.015599329024553299, 0.13602769374847412, 0.7929048538208008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13423295319080353, 0.07014799863100052, 0.03862922266125679, 0.03592688590288162, 0.057204850018024445, 0.06419351696968079, 0.039089810103178024, 0.2145734429359436, 0.3460012674331665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0035958767402917147, 0.00038495013723149896, 0.0004921660292893648, 0.0008088782778941095, 0.0025900956243276596, 0.0024076495319604874, 0.00017131817003246397, 0.011153002269566059, 0.0021147800143808126, 0.9762812852859497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00022834539413452148, 4.666255335905589e-05, 8.20648274384439e-05, 7.73067949921824e-05, 0.00012034264364046976, 0.004319249652326107, 0.003844224149361253, 0.0011965001467615366, 0.00016446944209747016, 0.8530561923980713, 0.13686463236808777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06578907370567322, 0.019290771335363388, 0.020492712035775185, 0.02195679023861885, 0.02668667584657669, 0.08618342131376266, 0.031040910631418228, 0.16103023290634155, 0.03016255795955658, 0.21323662996292114, 0.07554485648870468, 0.24858537316322327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0091233616694808, 0.003399315755814314, 0.016818268224596977, 0.004648813512176275, 0.014602279290556908, 0.05833255499601364, 0.07909014075994492, 0.01766362413764, 0.016087286174297333, 0.15053559839725494, 0.3343389332294464, 0.05438896268606186, 0.24097083508968353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04253435879945755, 0.016550593078136444, 0.00781342014670372, 0.006833470892161131, 0.009650973603129387, 0.009173317812383175, 0.005910308565944433, 0.030093083158135414, 0.05324167385697365, 0.035758912563323975, 0.11968675255775452, 0.07133748382329941, 0.2969222068786621, 0.2944934666156769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01015804149210453, 0.004377418663352728, 0.006503189913928509, 0.0035466866102069616, 0.006157051771879196, 0.005149823613464832, 0.00415825005620718, 0.014994033612310886, 0.017724117264151573, 0.008609655313193798, 0.01355727482587099, 0.02768983505666256, 0.027776136994361877, 0.08518616110086441, 0.7644124031066895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005760938511230052, 3.7584886740660295e-05, 3.10057403112296e-05, 2.8090940759284422e-05, 0.00011757229367503896, 0.0010626487201079726, 0.0008489798638038337, 0.0023644287139177322, 0.0003171181015204638, 0.0005040704854764044, 0.0005438972148112953, 0.0009964655619114637, 0.004787205718457699, 0.0016582146054133773, 0.021181106567382812, 0.9649454951286316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05710114166140556, 0.012982725165784359, 0.012463358230888844, 0.012371201068162918, 0.013064763508737087, 0.03530251979827881, 0.013208819553256035, 0.06362833827733994, 0.01058889739215374, 0.06113193929195404, 0.027357207611203194, 0.08200789242982864, 0.039974603801965714, 0.043028347194194794, 0.06893416494131088, 0.06733901053667068, 0.37951505184173584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0503818579018116, 0.010253237560391426, 0.0090173976495862, 0.007853331044316292, 0.008382104337215424, 0.01603054441511631, 0.007579756900668144, 0.01656814105808735, 0.009558068588376045, 0.020098412409424782, 0.028027672320604324, 0.03172842040657997, 0.02179395779967308, 0.03942328318953514, 0.11988719552755356, 0.047830868512392044, 0.14773686230182648, 0.4078488349914551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009583805687725544, 0.000512220780365169, 0.0006106934160925448, 0.0009717896464280784, 0.0022611040621995926, 0.004041267558932304, 0.0003397607943043113, 0.0023014822509139776, 0.0014669822994619608, 0.004360880237072706, 0.01003958098590374, 0.003883794415742159, 0.0019065379165112972, 0.004968367516994476, 0.003599880263209343, 0.00279565853998065, 0.015628818422555923, 0.014497026801109314, 0.916230320930481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03377581015229225, 0.000847293937113136, 0.000936156720854342, 0.0006967576337046921, 0.004600140266120434, 0.0032576012890785933, 0.00042183659388683736, 0.007556704338639975, 0.0010570589220151305, 0.0036437923554331064, 0.00017823875532485545, 0.0020456223282963037, 0.0014812109293416142, 0.002918047597631812, 0.0056848181411623955, 0.06616660207509995, 0.006820718292146921, 0.005966115742921829, 0.02230619266629219, 0.8296393752098083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014338110573589802, 0.004506281577050686, 0.0022934817243367434, 0.004502634052187204, 0.006348524242639542, 0.006440699566155672, 0.0030759212095290422, 0.0034293788485229015, 0.008825044147670269, 0.013563881628215313, 0.008806233294308186, 0.015333065763115883, 0.010930363088846207, 0.03256243094801903, 0.041650157421827316, 0.029358427971601486, 0.06823207437992096, 0.10101231187582016, 0.1282440572977066, 0.08141805976629257, 0.41512882709503174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012516949325799942, 0.003707381198182702, 0.0011323615908622742, 0.002044015796855092, 0.0021037994883954525, 0.0007217562524601817, 0.0003587715036701411, 0.001065456890501082, 0.003341867122799158, 0.003534771502017975, 0.0018008319893851876, 0.005131382495164871, 0.005956846289336681, 0.011681467294692993, 0.023353110998868942, 0.02462637796998024, 0.023082591593265533, 0.02405393123626709, 0.04505402594804764, 0.04447478801012039, 0.09848442673683167, 0.6617730855941772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.023378070443868637, 0.0029700936283916235, 0.0022721635177731514, 0.003121254500001669, 0.010448776185512543, 0.0027957085985690355, 0.0009500705054961145, 0.006640286184847355, 0.0025093024596571922, 0.0062158978544175625, 0.0018756617791950703, 0.004366475157439709, 0.00589492404833436, 0.007904240861535072, 0.011842506937682629, 0.01178030576556921, 0.01693400926887989, 0.015606722794473171, 0.03699192404747009, 0.0567626953125, 0.03885180875658989, 0.3010689318180084, 0.4288182556629181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04225084185600281, 0.009647662751376629, 0.013069666922092438, 0.0034939260222017765, 0.008718243800103664, 0.000871762225870043, 0.002113070571795106, 0.002520154230296612, 0.0028259295504540205, 0.0030562577303498983, 0.005475995130836964, 0.0044675893150269985, 0.005966206081211567, 0.008145663887262344, 0.027670925483107567, 0.013382639735937119, 0.01818912662565708, 0.0327802412211895, 0.028848370537161827, 0.05995951220393181, 0.09605949372053146, 0.20931926369667053, 0.10138271749019623, 0.299784779548645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02581804059445858, 0.0012453027302399278, 0.0012367722811177373, 0.003155822865664959, 0.002605457790195942, 0.00111783214379102, 0.00023053256154526025, 0.0010614549973979592, 0.0012552995467558503, 0.0014470183523371816, 0.000608303293120116, 0.0021444340236485004, 0.0017222757451236248, 0.003063679439947009, 0.0021307107526808977, 0.001739518134854734, 0.007489562500268221, 0.004201179835945368, 0.016367288306355476, 0.017187541350722313, 0.016647031530737877, 0.06787324696779251, 0.07546130567789078, 0.04369649291038513, 0.7004938721656799, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007508307229727507, 0.000129139210912399, 0.0002290404518134892, 0.0003099401656072587, 0.001587574020959437, 0.00015740787785034627, 0.0003654661704786122, 0.0002631948736961931, 0.000246187555603683, 0.004963845480233431, 0.000849328760523349, 0.00020542528363876045, 0.0035996558144688606, 0.0006757518276572227, 0.0006743200938217342, 0.0028660325333476067, 0.0007401989423669875, 0.0012410666095092893, 0.003433941164985299, 0.0033488052431493998, 0.005896294955164194, 0.015315243974328041, 0.013584447093307972, 0.0038060718216001987, 0.10587524622678757, 0.8221280574798584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015146811492741108, 0.0002837269857991487, 0.0004323886532802135, 0.0012392130447551608, 0.0026600700803101063, 0.0003459537692833692, 0.0002954266674350947, 0.0018772060284391046, 0.00023691226670052856, 0.0001321921736234799, 0.00033548023202456534, 0.00022997868654783815, 0.0002714901929721236, 0.00042095404933206737, 0.0008192576933652163, 0.00030394643545150757, 0.0006469363579526544, 0.00038042673259042203, 0.002392594236880541, 0.002976798452436924, 0.0025756123941391706, 0.005941804498434067, 0.005901212338358164, 0.005208782851696014, 0.025423740968108177, 0.023241249844431877, 0.9002798795700073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02088216505944729, 0.0006866250187158585, 0.0014190289657562971, 0.0016247222665697336, 0.00546672660857439, 0.0019930703565478325, 0.00034445608616806567, 0.0014866290148347616, 0.00038602756103500724, 0.00029867971898056567, 0.0003715484344866127, 0.0005332494038157165, 0.0002567080082371831, 0.0006083346670493484, 0.0003786252054851502, 0.0013748218771070242, 0.0013781338930130005, 0.0009236651239916682, 0.02337499149143696, 0.0377323217689991, 0.004063979256898165, 0.021846620365977287, 0.01851237565279007, 0.005047195125371218, 0.018440252169966698, 0.063994862139225, 0.33002781867980957, 0.4365464150905609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0027297879569232464, 0.00011315734445815906, 0.00025743208243511617, 0.00030652937130071223, 0.000801237765699625, 0.0008870935998857021, 0.00010111573647009209, 0.002048567635938525, 0.0001429120311513543, 0.0001989804586628452, 0.0004309819487389177, 7.435747102135792e-05, 0.00011077825183747336, 0.00022297585383057594, 0.0001040010538417846, 0.0007566184503957629, 0.00018428782641422004, 0.0003102098125964403, 0.0010590286692604423, 0.005394387524574995, 0.001371139194816351, 0.0017238226719200611, 0.003438346553593874, 0.0007791529642418027, 0.0027107952628284693, 0.01124660111963749, 0.261861652135849, 0.04286465793848038, 0.6577694416046143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007169218733906746, 0.002651232061907649, 0.002445027930662036, 0.0030232518911361694, 0.002686190651729703, 0.0007135469932109118, 0.0005127682234160602, 0.0003864864120259881, 0.0009532018448226154, 0.00044078443897888064, 0.0008591757505200803, 0.0012491066008806229, 0.0009424777235835791, 0.0016617255751043558, 0.00044353160774335265, 0.0014648421201854944, 0.00357746216468513, 0.003767341375350952, 0.01212292816489935, 0.006853919476270676, 0.005249569658190012, 0.019704239442944527, 0.026669243350625038, 0.04096020385622978, 0.23853963613510132, 0.05725704878568649, 0.04040539637207985, 0.10933997482061386, 0.0773630291223526, 0.3305874168872833, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011626669205725193, 0.0019658172968775034, 0.000917952274903655, 0.0018197438912466168, 0.002078979043290019, 0.00029357150197029114, 0.00010028555698227137, 0.0005799982463940978, 0.00048541222349740565, 9.764838614501059e-05, 0.00015712776803411543, 0.0004106420965399593, 0.00048777772462926805, 0.0007517866906709969, 0.0007532837917096913, 0.001224212464876473, 0.0010826849611476064, 0.0014821895165368915, 0.002774250227957964, 0.003610333427786827, 0.002137242117896676, 0.009361447766423225, 0.014277668669819832, 0.01184671651571989, 0.04729335382580757, 0.0450628325343132, 0.041560713201761246, 0.0428079329431057, 0.07079774886369705, 0.10084830224514008, 0.581305742263794, 0.0, 0.0, 0.0, 0.0], [0.003873431822285056, 0.0002557098923716694, 0.0006259249639697373, 0.000584395369514823, 0.0012326474534347653, 0.0003945602220483124, 0.0003326675505377352, 0.000155819216161035, 0.00016472722927574068, 0.0007726292824372649, 0.00038669779314659536, 0.00027824417338706553, 0.00015239718777593225, 0.00025198518414981663, 6.452928209910169e-05, 0.0001726413902360946, 0.0007133573526516557, 0.0005384791293181479, 0.007539561949670315, 0.006723249331116676, 0.0013963915407657623, 0.003110357094556093, 0.005501283798366785, 0.0024135871790349483, 0.03896054998040199, 0.023422332480549812, 0.009641138836741447, 0.025750914588570595, 0.12702471017837524, 0.040059298276901245, 0.5142089128494263, 0.183296799659729, 0.0, 0.0, 0.0], [0.015151124447584152, 0.0013760678702965379, 0.001556050730869174, 0.002171710366383195, 0.0025110093411058187, 0.0017854940379038453, 0.00047008675755932927, 0.0006788119790144265, 0.0003899070725310594, 0.000990037340670824, 0.00038026587571948767, 0.0004182497796136886, 0.0004435285518411547, 0.0005140134016983211, 0.00016592239262536168, 0.0006932563264854252, 0.0009629515116102993, 0.0007656944217160344, 0.004365222062915564, 0.006436268333345652, 0.0018688277341425419, 0.008356153033673763, 0.006384759210050106, 0.005890706554055214, 0.0311870276927948, 0.04100944846868515, 0.028566081076860428, 0.041577309370040894, 0.04076458513736725, 0.06712851673364639, 0.30426710844039917, 0.21618831157684326, 0.1645854264497757, 0.0, 0.0], [0.01735411025583744, 0.0005264717037789524, 0.0006208933773450553, 0.0016926310490816832, 0.0062972563318908215, 0.0010202114935964346, 7.362550968537107e-05, 0.0006762267439626157, 0.0004448311519809067, 7.778873259667307e-05, 4.973804243491031e-05, 0.00030359765514731407, 0.00017341799684800208, 0.0005162435118108988, 0.00027352795586921275, 0.0007444001385010779, 0.0006022222223691642, 0.0004544502589851618, 0.002665339270606637, 0.0026638780254870653, 0.00255159311927855, 0.007818794809281826, 0.009490984492003918, 0.0009830398485064507, 0.007624231278896332, 0.01155234407633543, 0.09579716622829437, 0.08069915324449539, 0.09889809042215347, 0.03799614682793617, 0.058356162160634995, 0.11718904972076416, 0.11656810343265533, 0.317244291305542, 0.0], [0.010796324349939823, 0.0030184590723365545, 0.001701078494079411, 0.0027613970451056957, 0.005546445492655039, 0.0005509481416083872, 0.00022208325390238315, 0.00023305864306166768, 0.0008555068634450436, 8.429402078036219e-05, 0.00013491010759025812, 0.00040303386049345136, 0.000215685271541588, 0.0009122335468418896, 0.0007261995342560112, 0.000381884747184813, 0.0007406792719848454, 0.0007301223231479526, 0.0007852279813960195, 0.0013473377330228686, 0.004313784185796976, 0.007729172706604004, 0.005422808229923248, 0.006747075822204351, 0.013981975615024567, 0.0046309903264045715, 0.01939181238412857, 0.02813372202217579, 0.016861911863088608, 0.07724329829216003, 0.054351557046175, 0.13139016926288605, 0.15014052391052246, 0.08434383571147919, 0.36317044496536255]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19326065480709076, 0.806739330291748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09132398664951324, 0.002221891889348626, 0.9064540863037109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07127534598112106, 0.010394592769443989, 0.014608741737902164, 0.9037212133407593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007525176741182804, 8.942753629526123e-05, 7.544117397628725e-05, 3.4135705391236115e-06, 0.9923065304756165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004521052353084087, 4.280496796127409e-06, 9.23039042390883e-05, 2.3636208425159566e-05, 1.1194401849934366e-05, 0.9953475594520569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007938149385154247, 0.00010465264494996518, 4.188252205494791e-05, 8.376279765798245e-06, 0.0002111142239300534, 3.129796368739335e-06, 0.9916926622390747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0024528438225388527, 1.0800486961670686e-05, 1.541069650556892e-05, 2.252152597748136e-07, 3.925116834579967e-05, 5.133605554874521e-06, 2.3800452254363336e-05, 0.9974525570869446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1994485706090927, 0.17831814289093018, 0.06548021733760834, 0.13276450335979462, 0.038584496825933456, 0.010353409685194492, 0.02143358625471592, 0.006723292637616396, 0.3468937277793884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0014458474470302463, 8.054695967985026e-07, 3.064583142986521e-05, 7.412913873849902e-07, 2.0274023881938774e-06, 1.1259035090915859e-05, 1.8223380493509467e-06, 8.012933540157974e-05, 1.0569633701607017e-07, 0.9984266757965088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002338021993637085, 1.2498689102358185e-05, 2.2450123651651666e-05, 4.236504537402652e-06, 2.952029092284647e-07, 1.8947090438814485e-06, 7.769858348183334e-05, 8.969064765551593e-06, 4.6951996068855806e-08, 1.1347678992024157e-06, 0.9975327253341675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.047514598816633224, 0.05268267169594765, 0.020408129319548607, 0.05853002145886421, 0.007166564930230379, 0.008201424963772297, 0.011846396140754223, 0.0017474401975050569, 0.02496333047747612, 0.002697254763916135, 0.0014261913020163774, 0.7628161311149597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006070799194276333, 0.00012957923172507435, 5.9433408750919625e-05, 5.6593407862237655e-06, 0.000261532433796674, 0.0001224183215526864, 1.039932612911798e-05, 1.1076393093389925e-05, 4.060476612721686e-07, 0.0003600465424824506, 2.0115392544539645e-05, 1.364392119285185e-07, 0.9929484128952026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09530565142631531, 0.14180326461791992, 0.050381824374198914, 0.10299666970968246, 0.02981208637356758, 0.0065894098952412605, 0.016824396327137947, 0.004481856245547533, 0.2310645431280136, 0.01943543553352356, 0.01087439525872469, 0.0554320253431797, 0.035438716411590576, 0.19955970346927643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027447892352938652, 0.00014065386494621634, 0.00019846689247060567, 3.4967801184393466e-05, 5.2821637837041635e-06, 0.00015024232561700046, 8.128373883664608e-05, 1.2125184184696991e-05, 6.303911504801363e-05, 6.543227209476754e-05, 2.832501195371151e-06, 3.8907375710550696e-05, 5.673653049598215e-07, 4.210495171719231e-05, 0.9717161655426025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004212113097310066, 3.069683225476183e-05, 6.369430047925562e-05, 8.254540944108157e-07, 8.262124993052566e-07, 3.868334897560999e-05, 4.268802967999363e-06, 3.819402536464622e-06, 1.2628001400116773e-07, 0.00013782735913991928, 1.7806096366257407e-05, 1.7100200366826357e-08, 5.979872184980195e-06, 6.190298051933496e-08, 2.2941551378607983e-06, 0.9954808950424194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01984681561589241, 0.03168346360325813, 0.012553269974887371, 0.03571881726384163, 0.004399014636874199, 0.004350571893155575, 0.007427369710057974, 0.0009372886270284653, 0.012662888504564762, 0.0016050540143623948, 0.0007319960277527571, 0.45634064078330994, 0.002010870724916458, 0.009759286418557167, 0.008237500675022602, 0.0002594128018245101, 0.39147573709487915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027297193184494972, 0.002435704693198204, 0.000270681717665866, 7.525561522925273e-05, 1.3686832062376197e-05, 5.773221346316859e-06, 0.00043018313590437174, 1.4438141079153866e-05, 4.835136132896878e-05, 5.3261013817973435e-05, 9.613298971089534e-06, 6.846687028883025e-05, 0.0003037676215171814, 2.878388659155462e-05, 3.8663900340907276e-05, 2.592678902146872e-05, 4.680045822169632e-05, 0.9688333868980408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006310692988336086, 3.294691487099044e-05, 9.895685252558906e-06, 7.334591032304161e-07, 9.119849710259587e-05, 4.094936593901366e-05, 8.511712621839251e-06, 9.950720414053649e-05, 1.9264832928911346e-07, 8.829235298435378e-07, 1.8906122249973123e-06, 1.1808716635641758e-06, 3.1165220661932835e-06, 9.474767637129844e-08, 3.3017577152349986e-06, 2.5855299099930562e-05, 7.711314538028091e-07, 2.670870799192926e-06, 0.993365466594696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0011340547353029251, 6.961935469007585e-06, 1.2364386748231482e-05, 4.0065501138997206e-07, 5.351819345378317e-05, 5.240101017989218e-06, 4.4595133658731356e-05, 0.0001645079319132492, 1.43445042510848e-08, 1.0388027931185206e-06, 4.778887523571029e-05, 5.058683782976914e-08, 9.468226949138625e-07, 7.475676078172455e-09, 6.603933684345975e-07, 3.843118065560702e-06, 3.346431398654204e-08, 2.4119779595821456e-07, 1.664778210397344e-05, 0.9985070824623108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08800850063562393, 0.18921291828155518, 0.04556255787611008, 0.08163286745548248, 0.017358072102069855, 0.004830402787774801, 0.01895878091454506, 0.0046201348304748535, 0.06910265237092972, 0.012970476411283016, 0.01034302357584238, 0.053664132952690125, 0.009830275550484657, 0.05797472596168518, 0.011936412192881107, 0.009446634911000729, 0.04662337899208069, 0.07882610708475113, 0.010427414439618587, 0.0020946746226400137, 0.1765759140253067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015971189364790916, 0.0030620202887803316, 0.0001418951724190265, 0.0007885742816142738, 4.2993720853701234e-05, 4.131205059820786e-05, 6.306861905613914e-05, 3.5465150176605675e-06, 2.173127722926438e-05, 1.7860953448689543e-05, 1.021398747980129e-05, 2.659637902979739e-05, 3.785558510571718e-05, 1.3186871001380496e-05, 0.00018817662203218788, 4.96388247483992e-06, 1.808511296985671e-05, 4.8640275053912774e-05, 4.463595359993633e-06, 2.4802482130326098e-06, 1.2178916222183034e-05, 0.9794788956642151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007472248747944832, 0.0003719076921697706, 7.639092655153945e-05, 1.1135921340610366e-05, 3.014870708284434e-05, 1.1014448318746872e-05, 5.4528827604372054e-05, 2.2444413843913935e-05, 1.1283866115263663e-05, 2.858791958715301e-05, 5.627749487757683e-06, 7.513612217735499e-05, 7.73430074332282e-05, 6.5297231230943e-06, 8.796931069809943e-06, 8.651516509416979e-06, 5.072796193417162e-05, 7.040868240437703e-06, 3.187646871083416e-05, 1.4034918649485917e-06, 7.0035935095802415e-06, 7.040079799480736e-05, 0.9915595650672913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.022045431658625603, 0.2804945707321167, 0.01667475514113903, 0.00015087143401615322, 0.0006804479635320604, 2.739412411756348e-05, 0.000893833814188838, 1.2499208423832897e-05, 0.00026655328110791743, 5.584168320638128e-06, 5.109103221911937e-05, 9.500434680376202e-05, 1.8194792573922314e-05, 0.00018282832752447575, 0.0016493599396198988, 2.793522253341507e-05, 6.991919508436695e-05, 7.67756937420927e-05, 2.088613109663129e-05, 4.512568466452649e-06, 0.00014541397104039788, 0.00044705031905323267, 5.5147884268080816e-05, 0.6759039163589478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018799467012286186, 0.0019184600096195936, 0.001052386942319572, 7.228145841509104e-05, 0.00013796599523629993, 5.2088158554397523e-05, 6.334375211736187e-05, 9.731957106851041e-06, 8.120811253320426e-05, 5.998387496219948e-05, 9.635974492994137e-06, 4.818717934540473e-05, 4.688356784754433e-05, 5.250570393400267e-05, 0.00044942021486349404, 0.00028932970599271357, 3.537202792358585e-05, 0.00022377951245289296, 0.00020208986825309694, 3.112006879746332e-06, 3.522854967741296e-05, 9.85500228125602e-05, 0.0001810147223295644, 0.00012300792150199413, 0.9759548306465149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0016589773586019874, 6.632470558542991e-06, 3.9323436794802547e-05, 5.512135885510361e-06, 7.328279025387019e-05, 5.176194690648117e-07, 8.362664084415883e-05, 1.611540574231185e-05, 1.840793260043938e-07, 0.00020032616157550365, 1.8497462406230625e-06, 7.683021863158501e-08, 1.8051048755296506e-05, 9.2597367995495e-08, 6.612178822251735e-06, 1.9627846086223144e-06, 5.0048470257024746e-08, 6.371125493842555e-08, 4.881635504716542e-07, 3.839143118966604e-06, 1.8601461704292888e-08, 1.6708657994968235e-06, 8.81660753293545e-07, 6.673329977502362e-08, 1.8785125632803101e-07, 0.9978796243667603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005040663294494152, 0.0003915553097613156, 0.0005618694121949375, 0.0001452302240068093, 3.9371810999000445e-05, 5.409949881141074e-05, 0.0002847950381692499, 4.8287358367815614e-05, 3.1043107355799293e-06, 6.896255217725411e-05, 0.0002681412152014673, 4.210924998915289e-06, 1.211988455906976e-05, 2.0253935417713365e-06, 3.188776099705137e-05, 1.1356515642546583e-05, 3.0187973152351333e-06, 1.2622882422874682e-05, 7.4655627031461336e-06, 3.027799039045931e-06, 4.951110668116598e-07, 3.0154526029946283e-05, 1.8863744116970338e-05, 4.151238499616738e-06, 5.031317414250225e-06, 6.069065875635715e-06, 0.9929414987564087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012448659399524331, 0.00017617024423088878, 2.4151706384145655e-05, 1.2456669537641574e-05, 5.2113035053480417e-05, 2.3546019292552955e-05, 5.673440682585351e-05, 0.00045827668509446084, 2.498383537385962e-06, 0.0001134940903284587, 4.92024228151422e-05, 1.3444526302919257e-05, 7.735934195807204e-05, 1.343708390777465e-06, 6.0608936109929346e-06, 0.00010331763769499958, 8.745474588067736e-06, 1.0811555512191262e-05, 0.00015856359095778316, 1.9056049040955259e-06, 5.418784780886199e-07, 1.23213567349012e-06, 6.472226232290268e-05, 3.58905344910454e-06, 8.650893505546264e-06, 2.9628010906890268e-06, 1.3278948244987987e-05, 0.9973099231719971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001973336096853018, 0.000975057715550065, 7.218521204777062e-05, 9.848424087977037e-05, 4.960866863257252e-05, 5.434062040876597e-05, 0.00037972061545588076, 6.1846380958741065e-06, 1.0831167855940294e-06, 4.491214440349722e-06, 0.0004798358422704041, 9.928667168424e-07, 1.3564583241532091e-05, 6.477196734522295e-07, 1.0186131476075388e-05, 5.581331606663298e-06, 7.113490596566407e-07, 5.998076062496693e-07, 3.2010875656851567e-06, 2.2882857138029067e-06, 1.513085550186588e-07, 7.13077315595001e-06, 1.7937989014171762e-06, 2.4025746824918315e-05, 2.833120333889383e-07, 1.2269149920030031e-05, 0.00023325506481342018, 0.00031319662230089307, 0.9952757358551025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03009931929409504, 0.09027381241321564, 0.028149735182523727, 0.15763863921165466, 0.02647356316447258, 0.003006009152159095, 0.01721954345703125, 0.002244672505185008, 0.0312004704028368, 0.011351735331118107, 0.0013561322120949626, 0.029119184240698814, 0.016773544251918793, 0.023998118937015533, 0.009450536221265793, 0.006288206670433283, 0.023923054337501526, 0.05829622969031334, 0.009904226288199425, 0.00037797351251356304, 0.02459513582289219, 0.04042007029056549, 0.02788674458861351, 0.009823571890592575, 0.04994712397456169, 0.0010651156771928072, 0.014632536098361015, 0.011246390640735626, 0.0020601563155651093, 0.2411784827709198, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004169422201812267, 0.0006143286009319127, 0.0005938469548709691, 0.00011036222713300958, 9.005509491544217e-05, 1.3705158380616922e-05, 0.0005903488490730524, 2.6892357709584758e-06, 8.671501745993737e-06, 4.6116343582980335e-05, 1.005678677756805e-05, 5.362908268580213e-06, 5.1998453272972256e-05, 4.802413968718611e-06, 2.1195246517891064e-05, 2.478504757164046e-05, 3.4400409276713617e-06, 1.8410850316286087e-05, 7.055151218082756e-05, 5.603974386758637e-07, 5.060179319116287e-06, 2.2592128516407683e-05, 6.252538150874898e-05, 1.861934651969932e-05, 0.00014118559192866087, 2.6331084882258438e-05, 1.261043394151784e-06, 1.0759850965769147e-06, 3.093194322900672e-07, 5.7930542425310705e-06, 0.9932644367218018, 0.0, 0.0, 0.0, 0.0], [0.010566665790975094, 0.0013905882369726896, 0.0004313627432566136, 0.00102959293872118, 0.003916396759450436, 0.00015029506175778806, 0.0019935970194637775, 0.00030443735886365175, 2.984509410453029e-05, 0.0006592923309653997, 1.2659825188165996e-05, 7.52750929677859e-05, 0.0003976769803557545, 1.7276539438171312e-05, 0.00038583489367738366, 2.1061901861685328e-05, 5.340313873603009e-05, 6.33502786513418e-05, 0.00012688428978435695, 6.783195203752257e-06, 2.7170561224920675e-05, 0.0001300896255997941, 3.859863136312924e-05, 4.366646317066625e-05, 8.064098437898792e-06, 0.0007468670373782516, 8.195245754905045e-06, 9.368611063109711e-05, 6.252459570532665e-06, 4.44724500994198e-05, 0.00020698650041595101, 0.9770136475563049, 0.0, 0.0, 0.0], [0.017131494358181953, 0.10981207340955734, 0.04528498649597168, 0.16663989424705505, 0.046834930777549744, 0.012714344076812267, 0.0249418206512928, 0.0024605076760053635, 0.016514169052243233, 0.014018183574080467, 0.002804650692269206, 0.017261289060115814, 0.05619140341877937, 0.011843182146549225, 0.024518407881259918, 0.008004877716302872, 0.013582986779510975, 0.027696531265974045, 0.007881486788392067, 0.00137596414424479, 0.009033635258674622, 0.037480004131793976, 0.01436882559210062, 0.016579674556851387, 0.031486254185438156, 0.0022351096849888563, 0.00703256344422698, 0.020338818430900574, 0.0021573668345808983, 0.015735741704702377, 0.03529254347085953, 0.017795007675886154, 0.16295132040977478, 0.0, 0.0], [0.002736238529905677, 0.003270441899076104, 0.00024938516435213387, 2.9521106625907123e-05, 0.00271907658316195, 1.5680814613006078e-05, 0.0011440073139965534, 3.528553861542605e-05, 1.9352071831235662e-05, 3.620963980210945e-05, 1.2202231118862983e-05, 0.00012145649816375226, 4.9556045269127935e-05, 1.1851500858028885e-05, 8.826622070046142e-05, 3.184522211086005e-05, 8.618923311587423e-05, 0.00013057797332294285, 9.267545829061419e-05, 1.8444527086103335e-05, 4.454882855497999e-06, 1.4211034795152955e-05, 0.0002081980783259496, 6.224932440090925e-05, 2.7289963327348232e-05, 8.527088539267424e-06, 0.0010931706055998802, 0.001025898614898324, 1.8266431652591564e-05, 9.8163227448822e-06, 7.599958848913957e-07, 4.151809662289452e-06, 8.365892426809296e-06, 0.9866164922714233, 0.0], [0.01330177579075098, 0.0020241800229996443, 0.0009810654446482658, 0.00027103975298814476, 0.026242606341838837, 6.968415254959837e-05, 0.0001882462966023013, 0.00033232770510949194, 0.00020717503502964973, 0.0003558363241609186, 1.868877916422207e-05, 0.00031016356660984457, 0.00028844247572124004, 0.00014157580153550953, 0.0002101896534441039, 0.0001373013947159052, 0.0002454255591146648, 0.0005858636577613652, 0.0008409089641645551, 0.00037898452137596905, 0.00011255513527430594, 0.0009485286427661777, 0.0002581722801551223, 0.0005371636361815035, 0.0002370645379414782, 9.896155825117603e-05, 1.4541836208081804e-05, 7.514374010497704e-05, 1.014245117403334e-05, 7.690775237279013e-05, 6.643286906182766e-05, 5.4460040701087564e-05, 0.00010782018944155425, 0.002189124934375286, 0.9480814933776855]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9360752105712891, 0.06392484903335571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8446659445762634, 0.06946852803230286, 0.0858655497431755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6426600813865662, 0.1298869252204895, 0.1711716651916504, 0.056281283497810364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5074959993362427, 0.0778627097606659, 0.0726853534579277, 0.10711849480867386, 0.23483744263648987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4970756471157074, 0.06315259635448456, 0.11559104174375534, 0.08851397037506104, 0.1019636020064354, 0.13370312750339508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3081282079219818, 0.06775975227355957, 0.13057535886764526, 0.05440935492515564, 0.040503185242414474, 0.36059141159057617, 0.03803273290395737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32434970140457153, 0.06349694728851318, 0.07783651351928711, 0.07798176258802414, 0.07410477846860886, 0.13590554893016815, 0.07038860768079758, 0.1759362369775772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16412915289402008, 0.03469284996390343, 0.05131255462765694, 0.013317004777491093, 0.17712706327438354, 0.15951897203922272, 0.09812309592962265, 0.2969047427177429, 0.0048745498061180115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18775461614131927, 0.05488045886158943, 0.10758274793624878, 0.043910037726163864, 0.1406543254852295, 0.1169673353433609, 0.052460040897130966, 0.1536639779806137, 0.04935268685221672, 0.09277379512786865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2051711529493332, 0.04006878286600113, 0.0833921805024147, 0.04565277695655823, 0.05697013437747955, 0.13319888710975647, 0.026416387408971786, 0.09950856864452362, 0.05013459175825119, 0.21417362987995148, 0.04531294107437134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10754457861185074, 0.020955437794327736, 0.052468445152044296, 0.008330851793289185, 0.179975226521492, 0.10652031749486923, 0.07210806012153625, 0.20191140472888947, 0.003346041776239872, 0.14021334052085876, 0.10356738418340683, 0.003058961359784007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09423349797725677, 0.022835399955511093, 0.055588554590940475, 0.026967836543917656, 0.12799426913261414, 0.07631109654903412, 0.07361152023077011, 0.16634684801101685, 0.030196361243724823, 0.11622445285320282, 0.13079150021076202, 0.022433562204241753, 0.056465137749910355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11027710139751434, 0.019917329773306847, 0.03387210890650749, 0.008012221194803715, 0.12686960399150848, 0.12052717059850693, 0.06604591012001038, 0.2115958034992218, 0.0029103788547217846, 0.13361383974552155, 0.07830416411161423, 0.005965670570731163, 0.07863972336053848, 0.0034490155521780252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16007709503173828, 0.05452117323875427, 0.059736259281635284, 0.02020750753581524, 0.05266043543815613, 0.10011067986488342, 0.1172926053404808, 0.14998744428157806, 0.017248356714844704, 0.05625280365347862, 0.09442038089036942, 0.01204691082239151, 0.020297693088650703, 0.01824457198381424, 0.06689620018005371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17850056290626526, 0.04271138459444046, 0.05876289680600166, 0.025501543655991554, 0.02821972221136093, 0.0939594954252243, 0.035697728395462036, 0.03853301703929901, 0.027574097737669945, 0.124172143638134, 0.0990019217133522, 0.02991955727338791, 0.04168912395834923, 0.030038557946681976, 0.08029220253229141, 0.06542609632015228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08262613415718079, 0.01422164961695671, 0.03910333290696144, 0.005809779744595289, 0.14161063730716705, 0.08671101182699203, 0.05503493919968605, 0.1562698781490326, 0.002328178845345974, 0.116793192923069, 0.08067946881055832, 0.0021917957346886396, 0.09792859852313995, 0.002736868103966117, 0.03297452628612518, 0.08037843555212021, 0.002601497806608677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09858329594135284, 0.028320662677288055, 0.05263178050518036, 0.017858650535345078, 0.06163658946752548, 0.08070764690637589, 0.07397957891225815, 0.09560469537973404, 0.009335814975202084, 0.08467230945825577, 0.11269160360097885, 0.018467867746949196, 0.03856263309717178, 0.01105150580406189, 0.06964194774627686, 0.09237801283597946, 0.022560443729162216, 0.03131493553519249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1495792120695114, 0.01304806862026453, 0.033948518335819244, 0.015061767771840096, 0.04509885236620903, 0.08479965478181839, 0.027256974950432777, 0.17206282913684845, 0.01685032621026039, 0.10883237421512604, 0.11793845146894455, 0.00832325965166092, 0.01613432541489601, 0.017726469784975052, 0.0261734277009964, 0.05189085379242897, 0.00897608045488596, 0.010605713352560997, 0.0756927952170372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2303972691297531, 0.024296822026371956, 0.02655998058617115, 0.03924617916345596, 0.04230226203799248, 0.04924338683485985, 0.007979441434144974, 0.0732208788394928, 0.03455185517668724, 0.066019207239151, 0.038301702588796616, 0.03672322630882263, 0.024140117689967155, 0.0371052585542202, 0.028557147830724716, 0.054463934153318405, 0.03901507332921028, 0.015944402664899826, 0.04610009118914604, 0.0858316496014595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05691659078001976, 0.006225025746971369, 0.011754424311220646, 0.003549681045114994, 0.07110726088285446, 0.08006573468446732, 0.02216234989464283, 0.11016800999641418, 0.001048491452820599, 0.08122199028730392, 0.026672057807445526, 0.002196080284193158, 0.030598552897572517, 0.0012014044914394617, 0.014937776140868664, 0.14736883342266083, 0.0026267541106790304, 0.03338916227221489, 0.11049015820026398, 0.18504451215267181, 0.001255226437933743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09241706877946854, 0.02605961263179779, 0.024830594658851624, 0.01475398801267147, 0.07309960573911667, 0.04160081222653389, 0.02818295545876026, 0.10522367805242538, 0.01020055916160345, 0.02671685628592968, 0.03863626345992088, 0.008342117071151733, 0.034165363758802414, 0.011011882685124874, 0.02702196314930916, 0.10600946843624115, 0.009498462080955505, 0.0161230880767107, 0.06257017701864243, 0.19003154337406158, 0.010448906570672989, 0.04305500164628029, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.061736516654491425, 0.007029621861875057, 0.01948661170899868, 0.010366822592914104, 0.046012863516807556, 0.07236862182617188, 0.02275238372385502, 0.08978495746850967, 0.005041901022195816, 0.07019016891717911, 0.07947878539562225, 0.006475386209785938, 0.03835069015622139, 0.005680922418832779, 0.015840988606214523, 0.053441066294908524, 0.00752498023211956, 0.018862146884202957, 0.09784611314535141, 0.19087882339954376, 0.006985302083194256, 0.027727801352739334, 0.04613658785820007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.043498445302248, 0.006029140669852495, 0.016271812841296196, 0.0049628885462880135, 0.0923277959227562, 0.05643606558442116, 0.024273188784718513, 0.10004424303770065, 0.0013475836021825671, 0.04695264995098114, 0.04337000846862793, 0.002612092299386859, 0.025980042293667793, 0.0015367756132036448, 0.013811733573675156, 0.12162507325410843, 0.0030840584076941013, 0.014781144447624683, 0.08252862840890884, 0.20843428373336792, 0.00210581230930984, 0.033566392958164215, 0.04992128536105156, 0.00449881749227643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05493931844830513, 0.005164694972336292, 0.013282540254294872, 0.006816815119236708, 0.08581957966089249, 0.04258367791771889, 0.010111798532307148, 0.10901319235563278, 0.0030670405831187963, 0.04195145517587662, 0.03668754920363426, 0.003877607174217701, 0.036396291106939316, 0.003642829367890954, 0.015713095664978027, 0.04514279216527939, 0.004770637024194002, 0.010733411647379398, 0.12949080765247345, 0.18343371152877808, 0.005763917230069637, 0.06008811667561531, 0.064203642308712, 0.008479914627969265, 0.01882552169263363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1161927878856659, 0.024008184671401978, 0.0175008662045002, 0.022795306518673897, 0.05027655512094498, 0.032025471329689026, 0.020647751167416573, 0.039747435599565506, 0.023735977709293365, 0.026677902787923813, 0.018856432288885117, 0.02817135490477085, 0.034608811140060425, 0.02664371207356453, 0.022768095135688782, 0.023577352985739708, 0.031199194490909576, 0.022620437666773796, 0.09706811606884003, 0.06436188519001007, 0.03251432627439499, 0.04557201638817787, 0.04268260300159454, 0.028252843767404556, 0.025809554383158684, 0.08168511837720871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11220825463533401, 0.00527593120932579, 0.01370137371122837, 0.006475640926510096, 0.05825747549533844, 0.0559183694422245, 0.01302725076675415, 0.10451260209083557, 0.00401367386803031, 0.040113665163517, 0.03787229582667351, 0.0031745261512696743, 0.012129995971918106, 0.004096257966011763, 0.007334528956562281, 0.017732810229063034, 0.003475234843790531, 0.0030595515854656696, 0.09483390301465988, 0.2000264972448349, 0.005673970095813274, 0.01637454330921173, 0.017230207100510597, 0.004368433263152838, 0.009308066219091415, 0.09713462740182877, 0.052670352160930634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06115267053246498, 0.004939327482134104, 0.009762823581695557, 0.005227167624980211, 0.036462754011154175, 0.03137053921818733, 0.008218889124691486, 0.11535759270191193, 0.0032728654332458973, 0.0382491871714592, 0.033371757715940475, 0.002179377246648073, 0.007692963350564241, 0.003454807912930846, 0.00908544659614563, 0.027900516986846924, 0.002366592874750495, 0.0039482396095991135, 0.0407714881002903, 0.2757468521595001, 0.003546664956957102, 0.012455109506845474, 0.03261313587427139, 0.003209816524758935, 0.0036030937917530537, 0.1000962108373642, 0.08892866224050522, 0.03501545637845993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11957036703824997, 0.008050519041717052, 0.013377297669649124, 0.0070892684161663055, 0.025275396183133125, 0.05149080976843834, 0.006585441064089537, 0.061659809201955795, 0.005620481446385384, 0.055614862591028214, 0.027291810140013695, 0.004286487121134996, 0.00769842928275466, 0.005996248684823513, 0.00794201996177435, 0.02879050374031067, 0.00487096793949604, 0.004313753917813301, 0.02622806839644909, 0.15385550260543823, 0.010709965601563454, 0.009564646519720554, 0.029178379103541374, 0.005329276900738478, 0.008051513694226742, 0.07812704890966415, 0.10984012484550476, 0.0295210313051939, 0.0940699353814125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02588074654340744, 0.003286874620243907, 0.009190612472593784, 0.002271318808197975, 0.04206257686018944, 0.0403556153178215, 0.01510707288980484, 0.04801337048411369, 0.0008096095989458263, 0.0390641987323761, 0.026566801592707634, 0.0015204494120553136, 0.02122018113732338, 0.0009539546445012093, 0.007810375653207302, 0.03313515707850456, 0.00187924993224442, 0.010119674727320671, 0.06751003116369247, 0.12262912094593048, 0.0015832221833989024, 0.022168036550283432, 0.0307852104306221, 0.004318807739764452, 0.01872900314629078, 0.1447751820087433, 0.06957430392503738, 0.1138874888420105, 0.07182329893112183, 0.002968475455418229, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04612509533762932, 0.004929370246827602, 0.011905019171535969, 0.0059399111196398735, 0.050862327218055725, 0.03915584832429886, 0.011702246963977814, 0.07777240127325058, 0.0027224929071962833, 0.029330715537071228, 0.035436611622571945, 0.0025086570531129837, 0.011883251368999481, 0.002963855629786849, 0.008878662250936031, 0.018936671316623688, 0.002804588759317994, 0.004066924564540386, 0.06637166440486908, 0.16173599660396576, 0.004074744414538145, 0.017417894676327705, 0.048458121716976166, 0.005489852279424667, 0.014467369765043259, 0.0888427346944809, 0.05744141340255737, 0.048157572746276855, 0.09182099252939224, 0.0047510224394500256, 0.023045990616083145, 0.0, 0.0, 0.0, 0.0], [0.0286165252327919, 0.003539714263752103, 0.012825751677155495, 0.003731105476617813, 0.022132832556962967, 0.026339074596762657, 0.015483633615076542, 0.046924490481615067, 0.001677015912719071, 0.05343088135123253, 0.038187284022569656, 0.00252948934212327, 0.02768225222826004, 0.0019447177182883024, 0.010427966713905334, 0.02030639350414276, 0.003083116840571165, 0.008337556384503841, 0.06147442385554314, 0.056954674422740936, 0.0030909229535609484, 0.01978730410337448, 0.037704236805438995, 0.004031910095363855, 0.02077089436352253, 0.12126167118549347, 0.08733708411455154, 0.07036233693361282, 0.09933116286993027, 0.005798673722893, 0.06381495296955109, 0.021079953759908676, 0.0, 0.0, 0.0], [0.022769229486584663, 0.0023638124112039804, 0.006953613366931677, 0.0009745152783580124, 0.03343130648136139, 0.0309631135314703, 0.012881077826023102, 0.0763968825340271, 0.00026210371288470924, 0.030449921265244484, 0.03674255311489105, 0.000567060720641166, 0.014569047838449478, 0.0003055332927033305, 0.005948364734649658, 0.022492554038763046, 0.0007025580271147192, 0.0048664468340575695, 0.060261812061071396, 0.1558590531349182, 0.000500177382491529, 0.019988082349300385, 0.03086847811937332, 0.0031281488481909037, 0.012151171453297138, 0.11994658410549164, 0.07597392052412033, 0.09628817439079285, 0.07584258168935776, 0.0010643766727298498, 0.03271332010626793, 0.01111111044883728, 0.0006632998120039701, 0.0, 0.0], [0.06755813211202621, 0.0033527954947203398, 0.008972212672233582, 0.003402541158720851, 0.056073080748319626, 0.030404701828956604, 0.013628306798636913, 0.07952424883842468, 0.0025889384560287, 0.03472939133644104, 0.01531597413122654, 0.002527100732550025, 0.00768547086045146, 0.0026928249280899763, 0.007113001774996519, 0.02612846903502941, 0.002773371059447527, 0.007069498300552368, 0.05076207220554352, 0.17593896389007568, 0.003935441840440035, 0.010542858392000198, 0.012697337195277214, 0.002831442980095744, 0.00498349079862237, 0.05610370263457298, 0.1027865782380104, 0.07864399999380112, 0.06361376494169235, 0.004290642682462931, 0.01244904100894928, 0.007846906781196594, 0.0035741617903113365, 0.037459541112184525, 0.0], [0.058894261717796326, 0.004834294319152832, 0.008816243149340153, 0.004917600657790899, 0.05724450200796127, 0.04719964414834976, 0.010384353809058666, 0.04373682290315628, 0.003253214992582798, 0.027000511065125465, 0.015386003069579601, 0.005444497801363468, 0.018304413184523582, 0.003610058454796672, 0.011856132186949253, 0.07255370169878006, 0.0060180784203112125, 0.006411904469132423, 0.05586158484220505, 0.08374674618244171, 0.003973668906837702, 0.01859060488641262, 0.019445111975073814, 0.0038806768134236336, 0.008932654745876789, 0.12242709845304489, 0.040986306965351105, 0.07429765164852142, 0.05774557590484619, 0.0063186343759298325, 0.013084126636385918, 0.023065797984600067, 0.005796521902084351, 0.04094136878848076, 0.015039587393403053]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9780336022377014, 0.02196633629500866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5068987607955933, 0.42791464924812317, 0.06518664956092834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34595051407814026, 0.23385089635849, 0.1913881152868271, 0.22881050407886505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.27859705686569214, 0.17525731027126312, 0.11037100106477737, 0.2518094778060913, 0.18396514654159546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20804190635681152, 0.0882713571190834, 0.061608146876096725, 0.25848427414894104, 0.27056995034217834, 0.11302442848682404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1632562130689621, 0.12141187489032745, 0.11990706622600555, 0.16166450083255768, 0.10774080455303192, 0.29750359058380127, 0.02851596660912037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1228092834353447, 0.0397898368537426, 0.045145437121391296, 0.13578511774539948, 0.09269556403160095, 0.11808718740940094, 0.3369846045970917, 0.10870295763015747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07854471355676651, 0.035703860223293304, 0.02910536900162697, 0.05200909078121185, 0.10322193801403046, 0.062225185334682465, 0.06801242381334305, 0.1702916920185089, 0.40088576078414917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08555343002080917, 0.04508211836218834, 0.020755302160978317, 0.05748790502548218, 0.05853370949625969, 0.038125380873680115, 0.031640272587537766, 0.14470809698104858, 0.39396733045578003, 0.12414634227752686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03400759771466255, 0.005801306571811438, 0.004264358896762133, 0.014554589055478573, 0.002058125799521804, 0.010052242316305637, 0.015462438575923443, 0.014919949695467949, 0.07456015050411224, 0.8029414415359497, 0.02137780375778675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.036581333726644516, 0.008552639745175838, 0.009085922501981258, 0.01071860920637846, 0.031510576605796814, 0.07786071300506592, 0.02809949964284897, 0.05203400179743767, 0.09175647795200348, 0.24980762600898743, 0.22384561598300934, 0.18014705181121826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03899509087204933, 0.013953062705695629, 0.027150364592671394, 0.015978632494807243, 0.006068874150514603, 0.015332898125052452, 0.0073584397323429585, 0.008143594488501549, 0.09236103296279907, 0.09582390636205673, 0.3970893919467926, 0.22508259117603302, 0.05666206404566765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02941764146089554, 0.006853987462818623, 0.005433529615402222, 0.008306891657412052, 0.015738293528556824, 0.008708913810551167, 0.008349095471203327, 0.023920103907585144, 0.046946827322244644, 0.04814496263861656, 0.0930999144911766, 0.15290866792201996, 0.1485418677330017, 0.4036293625831604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0371282659471035, 0.007584462407976389, 0.0035451471339911222, 0.008117970079183578, 0.018834207206964493, 0.005904970224946737, 0.009632603265345097, 0.011076663620769978, 0.04249943792819977, 0.015083963982760906, 0.01984347216784954, 0.11177285760641098, 0.12816858291625977, 0.33317869901657104, 0.24762879312038422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024791479110717773, 0.0022572369780391455, 0.0019112303853034973, 0.003149640979245305, 0.0017746681114658713, 0.003080856753513217, 0.019880713894963264, 0.006427106447517872, 0.015317467041313648, 0.003226602915674448, 0.020296048372983932, 0.05772729218006134, 0.02255523018538952, 0.08885949850082397, 0.714112401008606, 0.01463242806494236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019352810457348824, 0.002735717687755823, 0.002700645010918379, 0.0028163986280560493, 0.007300620432943106, 0.016268717125058174, 0.0051347059197723866, 0.010258648544549942, 0.01379147358238697, 0.03380442410707474, 0.033944789320230484, 0.024110401049256325, 0.053474944084882736, 0.09690996259450912, 0.2761882543563843, 0.2219037562608719, 0.17930372059345245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016778266057372093, 0.0013836651341989636, 0.0012504421174526215, 0.0019532653968781233, 0.001228307606652379, 0.003427051240578294, 0.001771017094142735, 0.002587685827165842, 0.009956514462828636, 0.007537410128861666, 0.004963121376931667, 0.023668866604566574, 0.017456673085689545, 0.06967746466398239, 0.2612769901752472, 0.24082402884960175, 0.17677928507328033, 0.15747997164726257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05475038290023804, 0.009201948530972004, 0.003783299820497632, 0.006891878787428141, 0.007006865926086903, 0.005267786327749491, 0.0019135883776471019, 0.006649003829807043, 0.0224907249212265, 0.007203699089586735, 0.039859868586063385, 0.026306964457035065, 0.03598390519618988, 0.10654615610837936, 0.14742803573608398, 0.029531899839639664, 0.14834171533584595, 0.23425260186195374, 0.1065896525979042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08004871755838394, 0.00356274307705462, 0.0033941506408154964, 0.011285580694675446, 0.012208586558699608, 0.0019434967543929815, 0.003920826595276594, 0.024116624146699905, 0.02334999106824398, 0.008975883945822716, 0.005343946162611246, 0.025336073711514473, 0.013870186172425747, 0.10103640705347061, 0.03973820060491562, 0.08061374723911285, 0.12086467444896698, 0.1229468509554863, 0.1413252353668213, 0.1761181354522705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013053345493972301, 0.0019795631524175406, 0.0016182123217731714, 0.0014078525127843022, 0.0014868241269141436, 0.0013099159114062786, 0.0016642939299345016, 0.0025665161665529013, 0.003062670351937413, 0.010340572334825993, 0.007755252066999674, 0.00892942026257515, 0.00886954739689827, 0.01716512441635132, 0.07265801727771759, 0.08664456754922867, 0.06223953887820244, 0.16528475284576416, 0.07255075871944427, 0.09155549108982086, 0.36785778403282166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012316005304455757, 0.0011592352529987693, 0.0007622393313795328, 0.0019507510587573051, 0.0012718499638140202, 0.0006892282981425524, 0.0005458982777781785, 0.00260300375521183, 0.003917665220797062, 0.0005409365985542536, 0.0012741906102746725, 0.006503158248960972, 0.005551592446863651, 0.017973441630601883, 0.013353326357901096, 0.038051243871450424, 0.043033964931964874, 0.03958652913570404, 0.02230064943432808, 0.03898366913199425, 0.5949543118476868, 0.1526770442724228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013724959455430508, 0.001612572930753231, 0.0003289871383458376, 0.0010084330569952726, 0.0011758027831092477, 0.0007259281119331717, 0.0005918759270571172, 0.000961559999268502, 0.0031186218839138746, 0.005970012862235308, 0.0030334636103361845, 0.003344496013596654, 0.008407552726566792, 0.013658510521054268, 0.005607037339359522, 0.005321719218045473, 0.019289923831820488, 0.02910967357456684, 0.013599644415080547, 0.03133779391646385, 0.25137242674827576, 0.5305220484733582, 0.056176941841840744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016002366319298744, 0.0009560448816046119, 0.0005680455942638218, 0.0015549738891422749, 0.0015755707863718271, 0.0006219720817171037, 0.0011257637524977326, 0.0014368736883625388, 0.0023100459948182106, 0.0009028321946971118, 0.0013921464560553432, 0.0036725918762385845, 0.003632282605394721, 0.009217401966452599, 0.008623878471553326, 0.027025727555155754, 0.021376436576247215, 0.03330108895897865, 0.038854021579027176, 0.03905842825770378, 0.2659664750099182, 0.19372612237930298, 0.09792876243591309, 0.22917026281356812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009987279772758484, 0.0009651743457652628, 0.0006041582673788071, 0.0009222141234204173, 0.0008805796969681978, 0.0005974340601824224, 0.00021149194799363613, 0.0006455681868828833, 0.0012417667312547565, 0.0006859695422463119, 0.0007031502318568528, 0.0014577421825379133, 0.0018487719353288412, 0.005077196750789881, 0.0019275662489235401, 0.012413403019309044, 0.008568298071622849, 0.012073671445250511, 0.02193666435778141, 0.0291941799223423, 0.14272768795490265, 0.09834033995866776, 0.11847668141126633, 0.3163197338581085, 0.21219336986541748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01686086691915989, 0.0019703253637999296, 0.0008858375367708504, 0.001765639171935618, 0.002392833586782217, 0.0005271151894703507, 0.0003617889597080648, 0.0006361057749018073, 0.00224113161675632, 0.0008515844820067286, 0.00038157758535817266, 0.002274829428642988, 0.0018798474920913577, 0.0072922417894005775, 0.002146675018593669, 0.0025263046845793724, 0.010355675593018532, 0.011969316750764847, 0.006590907461941242, 0.012827474623918533, 0.12130498141050339, 0.06624650955200195, 0.14612388610839844, 0.28280729055404663, 0.24703305959701538, 0.049746185541152954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.026405010372400284, 0.0014231009408831596, 0.0016234476352110505, 0.002576404018327594, 0.002689703833311796, 0.001225753454491496, 0.0010898751206696033, 0.0009538460872136056, 0.0019223564304411411, 0.0024115294218063354, 0.0024579435121268034, 0.0014354214072227478, 0.005378495901823044, 0.0047323452308773994, 0.0019391176756471395, 0.007957505993545055, 0.00608688872307539, 0.012657439336180687, 0.011602526530623436, 0.029096635058522224, 0.08598874509334564, 0.0766589343547821, 0.03624012693762779, 0.131333589553833, 0.19490279257297516, 0.21766333281993866, 0.131547212600708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.023896077647805214, 0.0020674974657595158, 0.0025093802250921726, 0.0018511994276195765, 0.003160968190059066, 0.000900563201867044, 0.00026854267343878746, 0.0005213551339693367, 0.0017872147727757692, 0.001930898055434227, 0.001015822752378881, 0.001044267090037465, 0.001567705417983234, 0.0040601021610200405, 0.0008207396022044122, 0.003358299843966961, 0.004117123316973448, 0.007223031017929316, 0.014547302387654781, 0.04635155200958252, 0.05601867288351059, 0.03840016946196556, 0.041609954088926315, 0.10494539886713028, 0.1578821837902069, 0.12118801474571228, 0.1909026801586151, 0.16605331003665924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04075776785612106, 0.0039583598263561726, 0.005698095075786114, 0.003957982175052166, 0.0014047796139493585, 0.0003276943461969495, 0.0006401922437362373, 0.0012045823968946934, 0.0022385590709745884, 0.0007448496762663126, 0.0038365793880075216, 0.0016206831205636263, 0.0010148307774215937, 0.00426118727773428, 0.0009652962326072156, 0.00039543205639347434, 0.00540107162669301, 0.007263401057571173, 0.00576681038364768, 0.029991835355758667, 0.04173656553030014, 0.017527665942907333, 0.025155046954751015, 0.0756526067852974, 0.24542629718780518, 0.06668493896722794, 0.26483193039894104, 0.055024128407239914, 0.08651075512170792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011784794740378857, 0.0013947563711553812, 0.0009515657438896596, 0.000895321078132838, 0.0010372711112722754, 0.0004972644383087754, 0.00025283885770477355, 0.00043175695464015007, 0.0005345691461116076, 0.00028229248709976673, 0.00042747301631607115, 0.0005479558021761477, 0.0008038750966079533, 0.0011037482181563973, 0.0010882882634177804, 0.0026353762950748205, 0.0020033165346831083, 0.002939451951533556, 0.005114209372550249, 0.009162317961454391, 0.020236428827047348, 0.014397266320884228, 0.014386608265340328, 0.05287303775548935, 0.044258106499910355, 0.0717473104596138, 0.08077163249254227, 0.11779720336198807, 0.1448613852262497, 0.3947826325893402, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012992850504815578, 0.0016676135128363967, 0.0010021079797297716, 0.0011761257192119956, 0.0007638346287421882, 0.0004005827067885548, 0.00012849250924773514, 0.00010518684575799853, 0.0005606432096101344, 0.00014079366519581527, 0.00012207566760480404, 0.00039859922253526747, 0.00022988310956861824, 0.0011077818926423788, 0.0003631032013799995, 0.0008891792385838926, 0.0014402443775907159, 0.0014520194381475449, 0.002630571834743023, 0.0031673822086304426, 0.01722465269267559, 0.010722342878580093, 0.0050229961052536964, 0.045778512954711914, 0.04751962050795555, 0.027067044749855995, 0.05216856673359871, 0.055007923394441605, 0.11481013894081116, 0.44568830728530884, 0.14825090765953064, 0.0, 0.0, 0.0, 0.0], [0.011720003560185432, 0.0009638665360398591, 0.0016792761161923409, 0.0009598789620213211, 0.001183533575385809, 0.00035873393062502146, 0.0001312520180363208, 0.0002098587719956413, 0.00035185745218768716, 0.00011673840344883502, 0.00033267223625443876, 0.00020899836090393364, 0.0001630404294701293, 0.0005591597873717546, 0.00017877924256026745, 0.0005847528809681535, 0.0006520423339679837, 0.000810088706202805, 0.0008232013205997646, 0.006545142736285925, 0.007790668401867151, 0.006622510030865669, 0.005052968394011259, 0.014489847235381603, 0.02494208700954914, 0.01901032216846943, 0.02852548100054264, 0.036787740886211395, 0.14266954362392426, 0.23489893972873688, 0.3008542060852051, 0.14982274174690247, 0.0, 0.0, 0.0], [0.011463269591331482, 0.0009014818351715803, 0.0005477445083670318, 0.0005869870656169951, 0.0005616629496216774, 0.00023434772447217256, 0.00013944678357802331, 0.00019926785898860544, 0.0003140303597319871, 0.0001251463545486331, 0.00021479520364664495, 0.0002481348055880517, 0.0002290619013365358, 0.0005020766402594745, 0.00045190236414782703, 0.0006676735356450081, 0.0007638593669980764, 0.0009467154741287231, 0.001009436440654099, 0.0037195703480392694, 0.007444886025041342, 0.00450055580586195, 0.001834433525800705, 0.012973621487617493, 0.015522468835115433, 0.021838270127773285, 0.01622895523905754, 0.024697456508874893, 0.0380532369017601, 0.16302332282066345, 0.11826053261756897, 0.22884775698184967, 0.3229479193687439, 0.0, 0.0], [0.009539726190268993, 0.0014243277255445719, 0.00099445809610188, 0.000965558341704309, 0.0007854430587030947, 0.00030160610913299024, 0.00011159564746776596, 0.0008093689102679491, 0.00040054635610431433, 8.517073729308322e-05, 0.000630756898317486, 0.00020861541270278394, 0.0002525561139918864, 0.0005451844772323966, 0.00024275557370856404, 0.0005828303983435035, 0.0005503923748619854, 0.001054856344126165, 0.0010979125509038568, 0.004033542238175869, 0.005151547957211733, 0.00725124916061759, 0.003988179378211498, 0.012260395102202892, 0.013561543077230453, 0.03828657045960426, 0.06675273180007935, 0.013111520558595657, 0.10093282908201218, 0.13179117441177368, 0.05432303622364998, 0.15251490473747253, 0.3083244860172272, 0.06713256984949112, 0.0], [0.009234576486051083, 0.0018696906045079231, 0.0015434968518093228, 0.0012878915295004845, 0.0009349415195174515, 0.00028256099903956056, 0.00044942696695216, 0.0005595001857727766, 0.0003277683863416314, 7.203824497992173e-05, 0.00010657920938683674, 0.00026362462085671723, 0.0003654732136055827, 0.0003748312301468104, 0.0003117537416983396, 0.0008969141053967178, 0.0006347454618662596, 0.0008650016388855875, 0.0008020036621019244, 0.0006307897856459022, 0.003218781901523471, 0.0038458341732621193, 0.0030004349537193775, 0.007814166136085987, 0.01010721456259489, 0.016721554100513458, 0.007672085892409086, 0.010031219571828842, 0.005356388166546822, 0.07757057994604111, 0.03774448111653328, 0.13809102773666382, 0.19567598402500153, 0.030743561685085297, 0.4305931031703949]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8970723748207092, 0.10292764008045197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7731762528419495, 0.17108596861362457, 0.05573779717087746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21909849345684052, 0.0959283784031868, 0.15399755537509918, 0.5309755802154541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49329182505607605, 0.12421070784330368, 0.08378960937261581, 0.2104450762271881, 0.08826279640197754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4792534112930298, 0.1148393303155899, 0.05825285241007805, 0.12140917778015137, 0.19296903908252716, 0.033276282250881195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33760711550712585, 0.1303829401731491, 0.12365781515836716, 0.1684831827878952, 0.0394856296479702, 0.1552271544933319, 0.045156147330999374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31243136525154114, 0.10335514694452286, 0.07322125136852264, 0.13077445328235626, 0.08650774508714676, 0.20371733605861664, 0.04714134708046913, 0.042851291596889496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1071995422244072, 0.032564762979745865, 0.04615401849150658, 0.12522782385349274, 0.011105234734714031, 0.03433002531528473, 0.007858379743993282, 0.011366566643118858, 0.6241937279701233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3028891086578369, 0.07804971933364868, 0.05937647446990013, 0.09426911175251007, 0.17377148568630219, 0.03861626237630844, 0.04802529886364937, 0.039512552320957184, 0.13237623870372772, 0.03311377763748169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13027667999267578, 0.04213492572307587, 0.07258214056491852, 0.1092287003993988, 0.03630439564585686, 0.19112560153007507, 0.03369800001382828, 0.05715862289071083, 0.11187217384576797, 0.16414125263690948, 0.05147745832800865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09464417397975922, 0.02925342693924904, 0.03811942785978317, 0.1498957872390747, 0.020670875906944275, 0.07631716877222061, 0.008947468362748623, 0.02004508674144745, 0.30578556656837463, 0.0475209504365921, 0.010440836660563946, 0.19835928082466125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1444079577922821, 0.06329525262117386, 0.07617762684822083, 0.07194560021162033, 0.03394109010696411, 0.08442068099975586, 0.03594024106860161, 0.07685539871454239, 0.1158827692270279, 0.05951954796910286, 0.061835020780563354, 0.14841710031032562, 0.027361813932657242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0414787232875824, 0.011494407430291176, 0.017643535509705544, 0.045997269451618195, 0.0040850103832781315, 0.013701111078262329, 0.0028709012549370527, 0.00451077613979578, 0.24164839088916779, 0.009729515761137009, 0.002616736339405179, 0.2641771137714386, 0.008053780533373356, 0.3319928050041199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15155856311321259, 0.037725016474723816, 0.02733066864311695, 0.06052478030323982, 0.030143296346068382, 0.028034880757331848, 0.013341412879526615, 0.02250303141772747, 0.11653435230255127, 0.05189972370862961, 0.01055865827947855, 0.10229875147342682, 0.015167291276156902, 0.14137379825115204, 0.19100579619407654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2839045226573944, 0.0650240108370781, 0.032383374869823456, 0.02959110401570797, 0.0424320288002491, 0.028469771146774292, 0.041533127427101135, 0.08465301245450974, 0.0438549667596817, 0.02753039449453354, 0.09218151867389679, 0.03751113638281822, 0.04891907051205635, 0.04984966292977333, 0.07913841307163239, 0.0130238002166152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04885758459568024, 0.014007368125021458, 0.019542623311281204, 0.07337553054094315, 0.010089147835969925, 0.039725709706544876, 0.00431005097925663, 0.010590329766273499, 0.1530359983444214, 0.026499038562178612, 0.0054172552190721035, 0.09647627919912338, 0.0128067247569561, 0.20478658378124237, 0.14743395149707794, 0.009689189493656158, 0.12335669249296188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05943119525909424, 0.025951169431209564, 0.035473912954330444, 0.039079755544662476, 0.018049322068691254, 0.023087238892912865, 0.010503753088414669, 0.030069539323449135, 0.09918276965618134, 0.03614409640431404, 0.01841004006564617, 0.11741487681865692, 0.017167577520012856, 0.12769994139671326, 0.08459021896123886, 0.03790270909667015, 0.14577233791351318, 0.07406949996948242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2724890112876892, 0.045022718608379364, 0.04612240567803383, 0.042051974684000015, 0.03813564032316208, 0.05454425886273384, 0.025706542655825615, 0.01925414800643921, 0.04536456987261772, 0.05106879770755768, 0.021479347720742226, 0.05142940580844879, 0.03568309172987938, 0.05110248178243637, 0.04221019893884659, 0.038132812827825546, 0.057898253202438354, 0.023540087044239044, 0.03876426815986633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2398124784231186, 0.03723882883787155, 0.04641323164105415, 0.018074776977300644, 0.028609465807676315, 0.031563613563776016, 0.023263663053512573, 0.05314118415117264, 0.0367298349738121, 0.04436158016324043, 0.014090005308389664, 0.04079654812812805, 0.013384051620960236, 0.04018275439739227, 0.02512497827410698, 0.022283194586634636, 0.04457437992095947, 0.0263572558760643, 0.018502116203308105, 0.1954961121082306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03447255492210388, 0.007049778942018747, 0.008516236208379269, 0.019823292270302773, 0.0020061940886080265, 0.008738482370972633, 0.001380531000904739, 0.0025849840603768826, 0.1296386569738388, 0.004980518948286772, 0.001454297685995698, 0.09793511778116226, 0.00424265768378973, 0.1747492551803589, 0.02057535946369171, 0.0029217286501079798, 0.12519218027591705, 0.017666740342974663, 0.008172447793185711, 0.0064639742486178875, 0.32143494486808777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07532121986150742, 0.017385119572281837, 0.02649960294365883, 0.03820114582777023, 0.013464294373989105, 0.017004910856485367, 0.005682714749127626, 0.008161388337612152, 0.08791027218103409, 0.015652010217308998, 0.0046223788522183895, 0.06870011985301971, 0.017068399116396904, 0.11098408699035645, 0.08843358606100082, 0.015540479682385921, 0.08290654420852661, 0.03445707634091377, 0.034902893006801605, 0.022669030353426933, 0.1672758311033249, 0.04715689271688461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11039689928293228, 0.017618604004383087, 0.012073233723640442, 0.07903026789426804, 0.04707182198762894, 0.028393451124429703, 0.010853300802409649, 0.03898292034864426, 0.04254176840186119, 0.05313577130436897, 0.010616586543619633, 0.04066743701696396, 0.016578692942857742, 0.05044252425432205, 0.04148310795426369, 0.011694187298417091, 0.04894394055008888, 0.04587525129318237, 0.06803464144468307, 0.03145821765065193, 0.07373650372028351, 0.09332357347011566, 0.02704726718366146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05010591074824333, 0.011403633281588554, 0.018980011343955994, 0.04829110950231552, 0.005478166975080967, 0.027938108891248703, 0.0034753403160721064, 0.009667658247053623, 0.08883960545063019, 0.02145979180932045, 0.009184256196022034, 0.06738956272602081, 0.006293781567364931, 0.11730515956878662, 0.05559389665722847, 0.023259565234184265, 0.08538829535245895, 0.030172361060976982, 0.018553778529167175, 0.04972720891237259, 0.138699471950531, 0.03593090921640396, 0.029570572078227997, 0.04729196056723595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03365061804652214, 0.03973431885242462, 0.013943268917500973, 0.02215501107275486, 0.007374102249741554, 0.012534331530332565, 0.003937930800020695, 0.0055880313739180565, 0.052764154970645905, 0.01135347317904234, 0.0029761556070297956, 0.06122001260519028, 0.007114534731954336, 0.06609286367893219, 0.01845719665288925, 0.004707180894911289, 0.07780604809522629, 0.015934068709611893, 0.016269709914922714, 0.027332952246069908, 0.08945078402757645, 0.028283191844820976, 0.01342833787202835, 0.24125008285045624, 0.12664161622524261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10162996500730515, 0.0481734536588192, 0.02274153009057045, 0.017647162079811096, 0.01635766215622425, 0.014718171209096909, 0.02023891732096672, 0.03009829856455326, 0.038364384323358536, 0.02529747039079666, 0.039593473076820374, 0.04179808869957924, 0.01849495805799961, 0.043456628918647766, 0.023876946419477463, 0.013411915861070156, 0.04804754629731178, 0.021995287388563156, 0.03074478916823864, 0.05168474093079567, 0.05786484479904175, 0.04216013476252556, 0.050390034914016724, 0.08024894446134567, 0.07608184963464737, 0.024882826954126358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06603521853685379, 0.020660124719142914, 0.02168169990181923, 0.03408763185143471, 0.015279398299753666, 0.01844198815524578, 0.010789580643177032, 0.05595836043357849, 0.03565485402941704, 0.02173885516822338, 0.025664953514933586, 0.03946555405855179, 0.01909186877310276, 0.04260497912764549, 0.04514036700129509, 0.012913588434457779, 0.047355785965919495, 0.025561857968568802, 0.03524414449930191, 0.0974637046456337, 0.05611313134431839, 0.035938456654548645, 0.032566994428634644, 0.04301987215876579, 0.046976763755083084, 0.0324612595140934, 0.062089040875434875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10541093349456787, 0.01697310246527195, 0.020341018214821815, 0.03266652673482895, 0.021851157769560814, 0.03178992122411728, 0.005571207031607628, 0.0241945069283247, 0.0167404655367136, 0.016082551330327988, 0.013484911993145943, 0.02279035933315754, 0.020844904705882072, 0.019816400483250618, 0.007412003353238106, 0.013035072013735771, 0.026982463896274567, 0.010132258757948875, 0.01766769215464592, 0.2972625494003296, 0.023457160219550133, 0.03235583007335663, 0.032245323061943054, 0.01998010091483593, 0.05017198249697685, 0.04827893152832985, 0.03308818116784096, 0.01937238685786724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11478212475776672, 0.02845187857747078, 0.03015810437500477, 0.029890719801187515, 0.015577699989080429, 0.04523628205060959, 0.00815667025744915, 0.04677765816450119, 0.02057458460330963, 0.018089186400175095, 0.016638455912470818, 0.02435150370001793, 0.014281022362411022, 0.022870570421218872, 0.024558458477258682, 0.021522246301174164, 0.027740145102143288, 0.012263163924217224, 0.01678968220949173, 0.030601773411035538, 0.033104460686445236, 0.04230615124106407, 0.050134167075157166, 0.039895687252283096, 0.025471467524766922, 0.03835654631257057, 0.14836569130420685, 0.040621932595968246, 0.012431957758963108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010402965359389782, 0.003988310694694519, 0.00753655843436718, 0.023714076727628708, 0.0015746989520266652, 0.0045564970932900906, 0.0011461435351520777, 0.0020206542685627937, 0.08388333022594452, 0.0060935490764677525, 0.0012243662495166063, 0.08011975884437561, 0.003282929537817836, 0.1148514598608017, 0.02013854682445526, 0.00387402530759573, 0.1035565659403801, 0.01623990572988987, 0.006219523027539253, 0.011158788576722145, 0.12897227704524994, 0.016916092485189438, 0.008813062682747841, 0.028795938938856125, 0.060593489557504654, 0.0056185950525105, 0.016893547028303146, 0.008791644126176834, 0.017022375017404556, 0.20200031995773315, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05472033470869064, 0.015954433009028435, 0.012098275125026703, 0.022833751514554024, 0.018985217437148094, 0.028783902525901794, 0.008076783269643784, 0.008372064679861069, 0.039564043283462524, 0.012315313331782818, 0.009588331915438175, 0.023571277037262917, 0.010643109679222107, 0.046638429164886475, 0.0145158926025033, 0.012394603341817856, 0.027597365900874138, 0.02169143222272396, 0.020180562511086464, 0.018239211291074753, 0.05496654659509659, 0.03711783513426781, 0.02424500696361065, 0.03499608114361763, 0.1494767814874649, 0.02901950664818287, 0.043276481330394745, 0.015866439789533615, 0.0451154001057148, 0.11428382992744446, 0.02487177588045597, 0.0, 0.0, 0.0, 0.0], [0.028266336768865585, 0.008342590183019638, 0.009693165309727192, 0.024003315716981888, 0.01240698155015707, 0.009731604717671871, 0.0072547742165625095, 0.011378857307136059, 0.04525343328714371, 0.014661085791885853, 0.004759799689054489, 0.032793063670396805, 0.009599774144589901, 0.05662675201892853, 0.023795723915100098, 0.004614101257175207, 0.039821475744247437, 0.021238990128040314, 0.025286555290222168, 0.10159800946712494, 0.09278310090303421, 0.026123860850930214, 0.015091420151293278, 0.03458565101027489, 0.06182192638516426, 0.013406998477876186, 0.016889771446585655, 0.030893532559275627, 0.028194863349199295, 0.1103137880563736, 0.04056955873966217, 0.03819922357797623, 0.0, 0.0, 0.0], [0.005920095834881067, 0.002644824329763651, 0.005754891317337751, 0.021997179836034775, 0.0013081278884783387, 0.005726536735892296, 0.0008704044157639146, 0.0018940422451123595, 0.052954982966184616, 0.00472501153126359, 0.0009999445173889399, 0.04342709854245186, 0.002174984198063612, 0.0736372247338295, 0.01701577752828598, 0.003086993470788002, 0.057790882885456085, 0.010734478943049908, 0.0034258230589330196, 0.01033270638436079, 0.08509064465761185, 0.012429158203303814, 0.0062302350997924805, 0.022221006453037262, 0.06411111354827881, 0.0050534834153950214, 0.018152374774217606, 0.007594150025397539, 0.0067864395678043365, 0.16716453433036804, 0.013871795497834682, 0.014755620621144772, 0.2501174509525299, 0.0, 0.0], [0.059587135910987854, 0.014287109486758709, 0.00968867726624012, 0.028474608436226845, 0.028604796156287193, 0.026259329169988632, 0.0088196424767375, 0.022136058658361435, 0.01791020855307579, 0.026397546753287315, 0.01724359393119812, 0.02598380856215954, 0.006316181272268295, 0.020043157041072845, 0.015440626069903374, 0.02594027668237686, 0.0301030445843935, 0.01836533658206463, 0.023130422458052635, 0.02621460147202015, 0.031157266348600388, 0.028986169025301933, 0.028961259871721268, 0.016435226425528526, 0.03480091691017151, 0.03794368356466293, 0.0738067477941513, 0.03077242523431778, 0.028517240658402443, 0.07387102395296097, 0.02458771876990795, 0.035234082490205765, 0.08090808987617493, 0.023072006180882454, 0.0], [0.052589885890483856, 0.0082823745906353, 0.0046865916810929775, 0.011556110344827175, 0.00212435913272202, 0.007376655004918575, 0.0025699108373373747, 0.005167303141206503, 0.06430476158857346, 0.008688678964972496, 0.004349819850176573, 0.054052047431468964, 0.003567329840734601, 0.08101722598075867, 0.021457038819789886, 0.004144071601331234, 0.0662156268954277, 0.01871691830456257, 0.009488231502473354, 0.0060385484248399734, 0.10274301469326019, 0.014565224759280682, 0.009106291458010674, 0.021657677367329597, 0.03524801880121231, 0.004852634854614735, 0.008422155864536762, 0.019589491188526154, 0.011885890737175941, 0.14464665949344635, 0.016607560217380524, 0.02283478155732155, 0.08476626873016357, 0.015126866288483143, 0.05155404657125473]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8803902864456177, 0.11960969120264053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8001627922058105, 0.1442255973815918, 0.05561167001724243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6471942067146301, 0.1470176875591278, 0.07931006699800491, 0.1264779418706894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6291002035140991, 0.13269931077957153, 0.0830739215016365, 0.10306606441736221, 0.052060455083847046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5631014108657837, 0.12375932186841965, 0.11159726977348328, 0.10842740535736084, 0.08343346416950226, 0.009681181982159615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49733906984329224, 0.11400073021650314, 0.07851863652467728, 0.10408833622932434, 0.08229987323284149, 0.08720175176858902, 0.03655163571238518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.46186619997024536, 0.10720600932836533, 0.07680266350507736, 0.09525886178016663, 0.11179571598768234, 0.04683655872941017, 0.0632898136973381, 0.03694411367177963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.408801794052124, 0.11223537474870682, 0.06194954738020897, 0.08138207346200943, 0.06888709217309952, 0.04759938269853592, 0.05779566988348961, 0.06300586462020874, 0.09834322333335876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33778560161590576, 0.07768949121236801, 0.06164025515317917, 0.08030420541763306, 0.09243479371070862, 0.12569791078567505, 0.043102771043777466, 0.08006508648395538, 0.08753130584955215, 0.013748622499406338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4084458351135254, 0.07972611486911774, 0.05943279713392258, 0.07098966836929321, 0.06258385628461838, 0.0729871317744255, 0.05290912836790085, 0.06663116067647934, 0.08486582338809967, 0.030785243958234787, 0.01064338069409132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3284088671207428, 0.08126053214073181, 0.05222120136022568, 0.0667019784450531, 0.06221221014857292, 0.04688326269388199, 0.047482267022132874, 0.04943711683154106, 0.0864436998963356, 0.05108509585261345, 0.04660412669181824, 0.08125964552164078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28456372022628784, 0.0733422115445137, 0.059566278010606766, 0.05995685234665871, 0.0626126304268837, 0.04492250457406044, 0.053548913449048996, 0.055395208299160004, 0.0760505199432373, 0.0543915219604969, 0.05521012842655182, 0.08481413871049881, 0.03562536835670471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2986925542354584, 0.08053489029407501, 0.04630003869533539, 0.05841612070798874, 0.05245252326130867, 0.03589674457907677, 0.043130062520504, 0.04816412553191185, 0.07179585844278336, 0.03588228300213814, 0.03498636558651924, 0.06638612598180771, 0.04749887436628342, 0.0798635482788086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26184865832328796, 0.06895221769809723, 0.04662094637751579, 0.05860459432005882, 0.04692878574132919, 0.05568011850118637, 0.04915207624435425, 0.04117779806256294, 0.074907585978508, 0.03198425844311714, 0.03257225826382637, 0.07257071882486343, 0.03739878535270691, 0.08542973548173904, 0.036171406507492065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2941746413707733, 0.05360913649201393, 0.038608793169260025, 0.04952675849199295, 0.04060918465256691, 0.0414932444691658, 0.029716243967413902, 0.04536984860897064, 0.06024932861328125, 0.04159966856241226, 0.06637393683195114, 0.05982467904686928, 0.04050290957093239, 0.06734268367290497, 0.060957394540309906, 0.010041479952633381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24078045785427094, 0.057315003126859665, 0.03812981769442558, 0.047623757272958755, 0.04672614857554436, 0.03515474870800972, 0.034621816128492355, 0.0374724380671978, 0.062347810715436935, 0.0395454578101635, 0.035744328051805496, 0.05874497443437576, 0.03407842293381691, 0.07071566581726074, 0.054391175508499146, 0.039451491087675095, 0.06715650856494904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19008122384548187, 0.055469125509262085, 0.03824989125132561, 0.04468472674489021, 0.0434919036924839, 0.03729136288166046, 0.035000309348106384, 0.03413337841629982, 0.05614841356873512, 0.029018184170126915, 0.026478607207536697, 0.06265047192573547, 0.03502201288938522, 0.06568854302167892, 0.0571419820189476, 0.04781633988022804, 0.07356446981430054, 0.06806915998458862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23406480252742767, 0.04765676334500313, 0.03626639395952225, 0.043501537293195724, 0.044823311269283295, 0.030926158651709557, 0.024145537987351418, 0.03047104738652706, 0.051002658903598785, 0.03852143883705139, 0.04128360003232956, 0.05289097875356674, 0.027892805635929108, 0.057388786226511, 0.06067002937197685, 0.04387103021144867, 0.059330206364393234, 0.05117018148303032, 0.024122724309563637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3121168911457062, 0.04305696487426758, 0.030739204958081245, 0.0399012416601181, 0.04073915258049965, 0.033973559737205505, 0.013991210609674454, 0.0325016975402832, 0.04214293509721756, 0.03136739134788513, 0.05722324550151825, 0.0420997329056263, 0.032853297889232635, 0.04662720113992691, 0.048747774213552475, 0.02173059806227684, 0.047223784029483795, 0.029857579618692398, 0.04530390352010727, 0.007802661508321762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1958305388689041, 0.05227471888065338, 0.03251207619905472, 0.03705889731645584, 0.04335429146885872, 0.02764130011200905, 0.02745206654071808, 0.033081553876399994, 0.04532438889145851, 0.02540675923228264, 0.02478163130581379, 0.03888050094246864, 0.03024730272591114, 0.050895120948553085, 0.04128778353333473, 0.03749212250113487, 0.04425322636961937, 0.04428720474243164, 0.04519396275281906, 0.05072396248579025, 0.07202054560184479, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16079998016357422, 0.048410702496767044, 0.0330209955573082, 0.0344170480966568, 0.03531977906823158, 0.023897025734186172, 0.026063477620482445, 0.02863973192870617, 0.04453875869512558, 0.02494947984814644, 0.02971617318689823, 0.04013000801205635, 0.02485905960202217, 0.05134394019842148, 0.0537353977560997, 0.04527629166841507, 0.04680595546960831, 0.0346059687435627, 0.04245501384139061, 0.05485451593995094, 0.06976334005594254, 0.046397317200899124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18932504951953888, 0.03910360485315323, 0.024852028116583824, 0.03345050662755966, 0.0386015847325325, 0.024109292775392532, 0.020502105355262756, 0.024301744997501373, 0.03976471722126007, 0.03418167307972908, 0.03484787046909332, 0.036197811365127563, 0.023668942973017693, 0.0450248122215271, 0.03498944267630577, 0.026825517416000366, 0.04153793305158615, 0.037366610020399094, 0.042022790759801865, 0.05591040849685669, 0.06404420733451843, 0.056186333298683167, 0.03318498656153679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16596607863903046, 0.03388110175728798, 0.02065752074122429, 0.03212727978825569, 0.03747253492474556, 0.026519475504755974, 0.01988290250301361, 0.025609642267227173, 0.04091744124889374, 0.02261033095419407, 0.019720884039998055, 0.03376534581184387, 0.023503810167312622, 0.046445246785879135, 0.035414308309555054, 0.02736842632293701, 0.03876943141222, 0.031460732221603394, 0.04639927297830582, 0.04867471009492874, 0.06382153183221817, 0.06529751420021057, 0.046299051493406296, 0.047415394335985184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15514099597930908, 0.036314792931079865, 0.022236905992031097, 0.028097422793507576, 0.04015664383769035, 0.024055976420640945, 0.01740090921521187, 0.021498557180166245, 0.03675065562129021, 0.017986752092838287, 0.019703922793269157, 0.02832779660820961, 0.02260461077094078, 0.04168051481246948, 0.030497953295707703, 0.025585582479834557, 0.03248761221766472, 0.027014948427677155, 0.04112284258008003, 0.04738448187708855, 0.0638233870267868, 0.056550100445747375, 0.041199978440999985, 0.06263260543346405, 0.059744078665971756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12975940108299255, 0.027339685708284378, 0.02995753102004528, 0.02270284853875637, 0.037815336138010025, 0.031446345150470734, 0.017136769369244576, 0.04656492918729782, 0.03061830997467041, 0.018781673163175583, 0.025273209437727928, 0.028721973299980164, 0.019090931862592697, 0.03481000289320946, 0.02617022767663002, 0.02681772969663143, 0.03296039626002312, 0.024960240349173546, 0.05474759638309479, 0.0578010119497776, 0.056176237761974335, 0.03305983543395996, 0.05767423287034035, 0.046674203127622604, 0.06228698045015335, 0.02065236121416092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18126995861530304, 0.027924932539463043, 0.028055919334292412, 0.029457418248057365, 0.028532754629850388, 0.020307764410972595, 0.019550152122974396, 0.03153108060359955, 0.029232840985059738, 0.021110545843839645, 0.014580844901502132, 0.022505322471261024, 0.016256749629974365, 0.031508851796388626, 0.024519700556993484, 0.03659053519368172, 0.025034507736563683, 0.020030660554766655, 0.04726614058017731, 0.12142346054315567, 0.0418962687253952, 0.03646092116832733, 0.03734692931175232, 0.03705747798085213, 0.035210929811000824, 0.024784492328763008, 0.010552847757935524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1419323980808258, 0.026873400434851646, 0.023394420742988586, 0.024198895320296288, 0.03441091999411583, 0.031768206506967545, 0.014282823540270329, 0.027884989976882935, 0.027823274955153465, 0.02026795595884323, 0.020075349137187004, 0.026035411283373833, 0.015271048992872238, 0.031183555722236633, 0.02134445309638977, 0.030780872330069542, 0.029686488211154938, 0.024966169148683548, 0.03290623426437378, 0.0812656506896019, 0.04738020896911621, 0.0395050123333931, 0.03810605779290199, 0.03920024633407593, 0.047230418771505356, 0.032237764447927475, 0.04768495261669159, 0.02230280078947544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1936107724905014, 0.028910452499985695, 0.01741074211895466, 0.024991966784000397, 0.02041228860616684, 0.03692351281642914, 0.018564047291874886, 0.02249111421406269, 0.026469897478818893, 0.01985173299908638, 0.016706908121705055, 0.020129598677158356, 0.01730293408036232, 0.02887752279639244, 0.019370291382074356, 0.02151290699839592, 0.02260466292500496, 0.019465506076812744, 0.03218546509742737, 0.09415601193904877, 0.03964084014296532, 0.046928733587265015, 0.03296547383069992, 0.034327469766139984, 0.035498879849910736, 0.04152423143386841, 0.03800845891237259, 0.024193771183490753, 0.00496391486376524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13062261044979095, 0.029238125309348106, 0.020562490448355675, 0.024924928322434425, 0.026433376595377922, 0.020880043506622314, 0.01689508929848671, 0.020366210490465164, 0.030794672667980194, 0.016811517998576164, 0.014352652244269848, 0.026399681344628334, 0.01796814426779747, 0.03419142961502075, 0.025793632492423058, 0.02088005840778351, 0.029983339831233025, 0.0225768331438303, 0.031984005123376846, 0.0387752465903759, 0.04729927331209183, 0.039518099278211594, 0.035695526748895645, 0.04647781699895859, 0.045603714883327484, 0.027694009244441986, 0.0283762626349926, 0.029506973922252655, 0.033888138830661774, 0.06550601869821548, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10399015247821808, 0.02196613699197769, 0.016451170668005943, 0.022787991911172867, 0.02435714565217495, 0.01997542381286621, 0.013678604736924171, 0.020524611696600914, 0.02641664445400238, 0.01582498662173748, 0.018124759197235107, 0.022938068956136703, 0.015249828808009624, 0.02995176613330841, 0.019568651914596558, 0.017790067940950394, 0.026331381872296333, 0.020062360912561417, 0.03040565736591816, 0.05837803706526756, 0.04746948182582855, 0.03560006991028786, 0.033618565648794174, 0.039051614701747894, 0.046234603971242905, 0.03415835276246071, 0.05063628777861595, 0.03304954245686531, 0.04132761061191559, 0.06007474660873413, 0.034005604684352875, 0.0, 0.0, 0.0, 0.0], [0.10689456015825272, 0.023425208404660225, 0.01831112429499626, 0.02227621152997017, 0.019986260682344437, 0.018345672637224197, 0.01589350774884224, 0.0198027566075325, 0.025829363614320755, 0.0160794910043478, 0.016656849533319473, 0.02581821382045746, 0.012892837636172771, 0.029111457988619804, 0.020739195868372917, 0.017621513456106186, 0.029654454439878464, 0.024281147867441177, 0.028045887127518654, 0.05205394700169563, 0.04263105243444443, 0.03251812234520912, 0.037380319088697433, 0.038434360176324844, 0.03982122242450714, 0.02629011683166027, 0.0352063849568367, 0.031386297196149826, 0.03282343968749046, 0.061947036534547806, 0.03762543946504593, 0.04021657630801201, 0.0, 0.0, 0.0], [0.1222902461886406, 0.02516898512840271, 0.01671406999230385, 0.022033262997865677, 0.023000743240118027, 0.015408718958497047, 0.014958010986447334, 0.018676770851016045, 0.026191165670752525, 0.012370303273200989, 0.01071577612310648, 0.021631909534335136, 0.013984632678329945, 0.02889922820031643, 0.023200996220111847, 0.01821659691631794, 0.02428124099969864, 0.018235312774777412, 0.021653978154063225, 0.03633743152022362, 0.03855650871992111, 0.03691945970058441, 0.033792268484830856, 0.042588260024785995, 0.03839157149195671, 0.02329576015472412, 0.030805250629782677, 0.024493306875228882, 0.03010578453540802, 0.05652609467506409, 0.03756684437394142, 0.04159916564822197, 0.051390375941991806, 0.0, 0.0], [0.13871711492538452, 0.02196723036468029, 0.01668298803269863, 0.021551381796598434, 0.026049228385090828, 0.015379131771624088, 0.012522310018539429, 0.02002521976828575, 0.021879851818084717, 0.014553075656294823, 0.015628254041075706, 0.018288591876626015, 0.0124217439442873, 0.023633427917957306, 0.017220688983798027, 0.020091669633984566, 0.02015187218785286, 0.018530184403061867, 0.02421250194311142, 0.07234078645706177, 0.03423938527703285, 0.030147042125463486, 0.031458817422389984, 0.030202969908714294, 0.030948735773563385, 0.024833209812641144, 0.030743272975087166, 0.022636571899056435, 0.04456690326333046, 0.04173138737678528, 0.028924651443958282, 0.029865309596061707, 0.04288145527243614, 0.024973047897219658, 0.0], [0.12327976524829865, 0.026707442477345467, 0.01483471505343914, 0.018021516501903534, 0.017764994874596596, 0.013351651839911938, 0.014073795638978481, 0.01872303895652294, 0.023980092257261276, 0.021256309002637863, 0.017004823312163353, 0.020616674795746803, 0.012905529700219631, 0.02609744854271412, 0.02155427262187004, 0.015845773741602898, 0.02278093993663788, 0.023595383390784264, 0.019861752167344093, 0.021922387182712555, 0.03597114235162735, 0.03369682654738426, 0.02117166854441166, 0.035360533744096756, 0.03450926020741463, 0.021897651255130768, 0.03512424975633621, 0.02411290444433689, 0.03299051895737648, 0.046776361763477325, 0.030424457043409348, 0.03270316496491432, 0.03790726885199547, 0.042624954134225845, 0.040550798177719116]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6533872485160828, 0.3466127812862396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4451116919517517, 0.3337683379650116, 0.2211199402809143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5459807515144348, 0.15291084349155426, 0.07645456492900848, 0.22465379536151886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.42720288038253784, 0.1412525624036789, 0.06143972650170326, 0.11979992687702179, 0.2503049373626709, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4097929298877716, 0.11732906848192215, 0.06548823416233063, 0.12367463111877441, 0.04222371056675911, 0.24149145185947418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.36435145139694214, 0.15547122061252594, 0.08527877181768417, 0.08832608163356781, 0.04993733763694763, 0.03409624099731445, 0.22253885865211487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.35626861453056335, 0.09063341468572617, 0.05006815120577812, 0.10755757242441177, 0.06895481050014496, 0.04669608548283577, 0.04097529500722885, 0.2388460487127304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3461388945579529, 0.14562258124351501, 0.09470635652542114, 0.1049964502453804, 0.06400175392627716, 0.04047239571809769, 0.03757920861244202, 0.044482164084911346, 0.12200023978948593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20510224997997284, 0.04824315756559372, 0.05157081410288811, 0.09953966736793518, 0.06673121452331543, 0.04558688774704933, 0.03648391366004944, 0.08169859647750854, 0.08583586663007736, 0.27920761704444885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23016957938671112, 0.07576318085193634, 0.062430281192064285, 0.061968352645635605, 0.05024825036525726, 0.037962619215250015, 0.057705141603946686, 0.05617324262857437, 0.06585753709077835, 0.041665591299533844, 0.26005616784095764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2668822705745697, 0.09969270974397659, 0.06880498677492142, 0.10110108554363251, 0.036257702857255936, 0.04876029118895531, 0.0317954383790493, 0.03426745906472206, 0.09192278981208801, 0.044060155749320984, 0.024279996752738953, 0.152175173163414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24808602035045624, 0.05943755805492401, 0.03645307943224907, 0.09643884003162384, 0.04665256291627884, 0.043580614030361176, 0.026409663259983063, 0.038718484342098236, 0.06937100738286972, 0.035532157868146896, 0.02358422242105007, 0.05824919790029526, 0.21748659014701843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22227588295936584, 0.08784299343824387, 0.06428328156471252, 0.07245951145887375, 0.05153009295463562, 0.03354167565703392, 0.03151150792837143, 0.043959807604551315, 0.10531804710626602, 0.03629286214709282, 0.03349636122584343, 0.07923727482557297, 0.03496609628200531, 0.10328467935323715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26255419850349426, 0.07451014220714569, 0.04962189495563507, 0.0651395171880722, 0.02218240685760975, 0.03923412412405014, 0.02143390290439129, 0.02829248458147049, 0.06496230512857437, 0.022169629111886024, 0.018070973455905914, 0.05796553194522858, 0.018188010901212692, 0.06176503747701645, 0.19390982389450073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21454617381095886, 0.05207953229546547, 0.04338602349162102, 0.05108674243092537, 0.023057056590914726, 0.03987297788262367, 0.021457543596625328, 0.043103158473968506, 0.057124003767967224, 0.047324102371931076, 0.02007635310292244, 0.04863850027322769, 0.03173767402768135, 0.05389070510864258, 0.03922811895608902, 0.21339136362075806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.169346421957016, 0.0575847402215004, 0.04318231716752052, 0.06501621007919312, 0.025769712403416634, 0.035840604454278946, 0.023403938859701157, 0.028633087873458862, 0.06884393095970154, 0.03735613077878952, 0.021079331636428833, 0.12265525758266449, 0.02518490143120289, 0.07096559554338455, 0.049235545098781586, 0.028457917273044586, 0.12744443118572235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1294490247964859, 0.043515175580978394, 0.02870734967291355, 0.045572541654109955, 0.021282192319631577, 0.019885342568159103, 0.028857694938778877, 0.034781113266944885, 0.055325932800769806, 0.030885059386491776, 0.02108755148947239, 0.06504065543413162, 0.04043160006403923, 0.057976022362709045, 0.041369806975126266, 0.02854405716061592, 0.06784921884536743, 0.23943962156772614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14163608849048615, 0.03578965365886688, 0.028365228325128555, 0.04538756608963013, 0.04637839272618294, 0.03978871926665306, 0.014343786984682083, 0.049597978591918945, 0.04732619971036911, 0.030782440677285194, 0.018412159755825996, 0.04871036857366562, 0.02340163290500641, 0.047455623745918274, 0.03751208633184433, 0.023782698437571526, 0.04894063621759415, 0.033790670335292816, 0.23859809339046478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1335032433271408, 0.03222054988145828, 0.02058890275657177, 0.03780217468738556, 0.04108010604977608, 0.03671093285083771, 0.02595440484583378, 0.04136637970805168, 0.043265700340270996, 0.030096469447016716, 0.026812905445694923, 0.04010694473981857, 0.024385906755924225, 0.04430920630693436, 0.0337374247610569, 0.02071092277765274, 0.04079744592308998, 0.032650161534547806, 0.03506242111325264, 0.2588377892971039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11974352598190308, 0.03914882242679596, 0.028956562280654907, 0.03342708572745323, 0.037695933133363724, 0.0205439031124115, 0.01755896955728531, 0.032658424228429794, 0.06372418999671936, 0.03310192748904228, 0.02986794151365757, 0.053869184106588364, 0.022512977942824364, 0.07236675173044205, 0.041434261947870255, 0.03790142759680748, 0.06002624332904816, 0.04586021229624748, 0.05091096833348274, 0.031955886632204056, 0.1267348974943161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11878620088100433, 0.03957203030586243, 0.02322298102080822, 0.053640808910131454, 0.03261677548289299, 0.01737094298005104, 0.011663909070193768, 0.016273824498057365, 0.05014302581548691, 0.013260260224342346, 0.0104869045317173, 0.03813209384679794, 0.04193669185042381, 0.05336223170161247, 0.030979983508586884, 0.019617725163698196, 0.040241554379463196, 0.03244159370660782, 0.020540127530694008, 0.026845507323741913, 0.05771108716726303, 0.2511536478996277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10596504807472229, 0.03639821708202362, 0.02373066358268261, 0.02770346589386463, 0.029520327225327492, 0.016958514228463173, 0.009277226403355598, 0.019281184300780296, 0.043534498661756516, 0.02543571963906288, 0.01544105727225542, 0.0416172631084919, 0.018472323194146156, 0.04617342725396156, 0.026975227519869804, 0.016877293586730957, 0.0436592735350132, 0.020190222188830376, 0.01864578202366829, 0.01635969616472721, 0.05703481659293175, 0.06433956325054169, 0.27640920877456665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08669393509626389, 0.1400514841079712, 0.05404340475797653, 0.026910439133644104, 0.02693350799381733, 0.01693662256002426, 0.017527246847748756, 0.011132634244859219, 0.033167172223329544, 0.009116585366427898, 0.014021700248122215, 0.02812526933848858, 0.012107604183256626, 0.03627436235547066, 0.03099164552986622, 0.015099077485501766, 0.03022146411240101, 0.020815474912524223, 0.018955033272504807, 0.021182596683502197, 0.04364987835288048, 0.04377347603440285, 0.025040630251169205, 0.23722875118255615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10505463182926178, 0.024722838774323463, 0.02343858778476715, 0.02425646223127842, 0.021477699279785156, 0.014111106283962727, 0.012018012814223766, 0.015707308426499367, 0.042195845395326614, 0.016803370788693428, 0.011159364134073257, 0.03127181529998779, 0.020320698618888855, 0.04702334851026535, 0.039886802434921265, 0.02585337497293949, 0.034509602934122086, 0.02452259697020054, 0.017594218254089355, 0.021597163751721382, 0.06303168833255768, 0.05036986619234085, 0.02654913067817688, 0.040915295481681824, 0.24560922384262085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07146886736154556, 0.015683092176914215, 0.019199566915631294, 0.02765510231256485, 0.025888733565807343, 0.011495732702314854, 0.013834545388817787, 0.0250062458217144, 0.032857514917850494, 0.04069042578339577, 0.019407067447900772, 0.036282770335674286, 0.02667134441435337, 0.03698843717575073, 0.0253913477063179, 0.012203282676637173, 0.04081625118851662, 0.022441420704126358, 0.018680062144994736, 0.03714069724082947, 0.05291350930929184, 0.03374897688627243, 0.03600706160068512, 0.027396058663725853, 0.04157791659235954, 0.24855394661426544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09520066529512405, 0.02339908853173256, 0.01624995656311512, 0.03728703409433365, 0.027069473639130592, 0.02442619949579239, 0.016916710883378983, 0.02051924541592598, 0.03561447188258171, 0.01724678836762905, 0.01696517877280712, 0.03067062981426716, 0.014761793427169323, 0.03783896565437317, 0.025590213015675545, 0.013281542807817459, 0.03275728225708008, 0.01698147878050804, 0.012912829406559467, 0.04096675664186478, 0.04452374204993248, 0.032888539135456085, 0.021862000226974487, 0.028905071318149567, 0.025222204625606537, 0.015681948512792587, 0.2742602825164795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07106206566095352, 0.022234488278627396, 0.015442520380020142, 0.02880682982504368, 0.02491171285510063, 0.01409667544066906, 0.010925302281975746, 0.022356446832418442, 0.02825102210044861, 0.025925250723958015, 0.012314545921981335, 0.03621361032128334, 0.017662763595581055, 0.03140704706311226, 0.018595034256577492, 0.0181714054197073, 0.040066659450531006, 0.02272828295826912, 0.025000527501106262, 0.04014963284134865, 0.04249803349375725, 0.02628159709274769, 0.02363489754498005, 0.03034823015332222, 0.028446590527892113, 0.04931708052754402, 0.045332688838243484, 0.22781896591186523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1199868768453598, 0.03201312944293022, 0.020363762974739075, 0.03192231431603432, 0.020111484453082085, 0.017741892486810684, 0.014963152818381786, 0.014099689200520515, 0.0323602668941021, 0.012826556339859962, 0.01920422539114952, 0.024741895496845245, 0.014775943011045456, 0.03365084156394005, 0.03285076841711998, 0.01563302055001259, 0.02633098140358925, 0.009946919046342373, 0.010015268810093403, 0.023254677653312683, 0.03898428753018379, 0.034919414669275284, 0.011989147402346134, 0.03053087368607521, 0.02381373755633831, 0.018979014828801155, 0.06846079975366592, 0.019141538068652153, 0.22638750076293945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07111397385597229, 0.023045005276799202, 0.017407836392521858, 0.025577737018465996, 0.018817279487848282, 0.01440666988492012, 0.011364503763616085, 0.019742922857403755, 0.037803784012794495, 0.017498362809419632, 0.0122145377099514, 0.034711796790361404, 0.01624511182308197, 0.04494825378060341, 0.031461045145988464, 0.017976269125938416, 0.04077500104904175, 0.02623201161623001, 0.02910454012453556, 0.032863155007362366, 0.06312327086925507, 0.039967380464076996, 0.03193744271993637, 0.05005760118365288, 0.050039857625961304, 0.02629847079515457, 0.040675751864910126, 0.03425349295139313, 0.03361441567540169, 0.0867224931716919, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06342679262161255, 0.018928566947579384, 0.015915194526314735, 0.02297447994351387, 0.01581357792019844, 0.011996154673397541, 0.006959729827940464, 0.010440587997436523, 0.027604447677731514, 0.014203780330717564, 0.011755011044442654, 0.02697419933974743, 0.015696225687861443, 0.03244095295667648, 0.021464010700583458, 0.016300220042467117, 0.0315910242497921, 0.018295636400580406, 0.02407490275800228, 0.018299637362360954, 0.04905860871076584, 0.03294462338089943, 0.031695034354925156, 0.04070066288113594, 0.05526788532733917, 0.03228399530053139, 0.01833721622824669, 0.020621933043003082, 0.020615674555301666, 0.061421554535627365, 0.21189774572849274, 0.0, 0.0, 0.0, 0.0], [0.05903123319149017, 0.01165033970028162, 0.01190632302314043, 0.02030511572957039, 0.01582455448806286, 0.011342634446918964, 0.012165093794465065, 0.02051454968750477, 0.02463514916598797, 0.01787753961980343, 0.008976958692073822, 0.027097539976239204, 0.010151369497179985, 0.029500102624297142, 0.022961728274822235, 0.01152712944895029, 0.032491885125637054, 0.020219076424837112, 0.02027125470340252, 0.0276049617677927, 0.042306944727897644, 0.022920362651348114, 0.02739839442074299, 0.024839358404278755, 0.028419984504580498, 0.04172161594033241, 0.0314212292432785, 0.035203300416469574, 0.03063124045729637, 0.06006475165486336, 0.04537738487124443, 0.19364091753959656, 0.0, 0.0, 0.0], [0.08590575307607651, 0.014704098924994469, 0.01051056943833828, 0.028699854388833046, 0.016654491424560547, 0.012795393355190754, 0.009235279634594917, 0.014819215051829815, 0.028232725337147713, 0.011867673136293888, 0.009268179535865784, 0.02304435521364212, 0.017553264275193214, 0.03295403718948364, 0.025013741105794907, 0.012247494421899319, 0.02679956704378128, 0.013326534070074558, 0.016479840502142906, 0.03472822159528732, 0.0398079976439476, 0.05067337676882744, 0.03086116537451744, 0.027551837265491486, 0.036164239048957825, 0.01740610972046852, 0.04716058447957039, 0.025891847908496857, 0.028397276997566223, 0.06047138199210167, 0.03584858402609825, 0.03886667266488075, 0.11605862528085709, 0.0, 0.0], [0.056707728654146194, 0.015243271365761757, 0.009892581030726433, 0.017495427280664444, 0.035292427986860275, 0.015370236709713936, 0.010747743770480156, 0.017091592773795128, 0.021245012059807777, 0.013064504601061344, 0.006394114810973406, 0.02176818437874317, 0.011015367694199085, 0.023290835320949554, 0.0209710244089365, 0.012346651405096054, 0.02411966770887375, 0.013815036043524742, 0.016820499673485756, 0.034515149891376495, 0.030974799767136574, 0.03217756003141403, 0.03227026015520096, 0.02327035926282406, 0.027259428054094315, 0.01785033568739891, 0.05776430293917656, 0.024271581321954727, 0.02524302341043949, 0.03774581849575043, 0.015895815566182137, 0.02659659832715988, 0.04215160012245178, 0.20932142436504364, 0.0], [0.047369711101055145, 0.013491545803844929, 0.008601201698184013, 0.011534379795193672, 0.03260952979326248, 0.008750012144446373, 0.01049541961401701, 0.015973461791872978, 0.024224920198321342, 0.013959748670458794, 0.011584172025322914, 0.02090699039399624, 0.01231019850820303, 0.028499366715550423, 0.014403226785361767, 0.011428194120526314, 0.024424536153674126, 0.02128405123949051, 0.0275762677192688, 0.025762220844626427, 0.0491495318710804, 0.021549450233578682, 0.020725879818201065, 0.030232438817620277, 0.046837322413921356, 0.02172248438000679, 0.020257199183106422, 0.01914953999221325, 0.010533900000154972, 0.050025906413793564, 0.030405575409531593, 0.022812236100435257, 0.029462473466992378, 0.039963193237781525, 0.20198363065719604]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8253123164176941, 0.1746876984834671, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7580503821372986, 0.1302967369556427, 0.11165298521518707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7232239842414856, 0.08274427056312561, 0.07870832085609436, 0.11532341688871384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.559454083442688, 0.08694437891244888, 0.0911555141210556, 0.09393446892499924, 0.1685115247964859, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5031396150588989, 0.08192654699087143, 0.05872316658496857, 0.10480906069278717, 0.15214209258556366, 0.09925957024097443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.527961015701294, 0.058259785175323486, 0.06836593896150589, 0.11652137339115143, 0.11039452999830246, 0.06918036937713623, 0.04931706190109253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30010074377059937, 0.08825996518135071, 0.05834933742880821, 0.109842449426651, 0.1686263084411621, 0.1289689838886261, 0.02322760969400406, 0.12262459099292755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3934403955936432, 0.04758618026971817, 0.05194966122508049, 0.07471581548452377, 0.11950992792844772, 0.059380389750003815, 0.023368598893284798, 0.102664053440094, 0.1273849904537201, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3446025252342224, 0.05032898858189583, 0.05991332232952118, 0.044831324368715286, 0.1573815643787384, 0.06782463192939758, 0.032290101051330566, 0.07052529603242874, 0.0895390585064888, 0.08276327699422836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3350846767425537, 0.0462699718773365, 0.047857675701379776, 0.10917433351278305, 0.04435236006975174, 0.04490724951028824, 0.02844385989010334, 0.07920622080564499, 0.10731325298547745, 0.06832481175661087, 0.08906549960374832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31157219409942627, 0.03927760571241379, 0.03521275147795677, 0.07551001012325287, 0.08078573644161224, 0.04503689706325531, 0.028806490823626518, 0.10218672454357147, 0.08797681331634521, 0.05585261434316635, 0.0857192724943161, 0.052063003182411194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3614695072174072, 0.06311221420764923, 0.026989934965968132, 0.07095800340175629, 0.039851732552051544, 0.029446519911289215, 0.022796373814344406, 0.07072699815034866, 0.1130439043045044, 0.033355165272951126, 0.03714419901371002, 0.04763943701982498, 0.08346598595380783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26885920763015747, 0.03265075013041496, 0.039381880313158035, 0.05081149563193321, 0.08684229850769043, 0.04310198128223419, 0.017922354862093925, 0.06655362248420715, 0.07785408198833466, 0.04528899863362312, 0.06586873531341553, 0.04606606438755989, 0.07721769064664841, 0.08158090710639954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20790521800518036, 0.030814683064818382, 0.02946298010647297, 0.050674259662628174, 0.08743470907211304, 0.047705817967653275, 0.02733318693935871, 0.09152112156152725, 0.05214140564203262, 0.04708244651556015, 0.0808199942111969, 0.05453276261687279, 0.12074841558933258, 0.055161673575639725, 0.01666121557354927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19932866096496582, 0.04206705093383789, 0.05715769901871681, 0.071933314204216, 0.05065879225730896, 0.031524572521448135, 0.027136797085404396, 0.04140904173254967, 0.0932227075099945, 0.052022065967321396, 0.025422828271985054, 0.05927914381027222, 0.06613776087760925, 0.0958227664232254, 0.031632158905267715, 0.05524462088942528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2371978461742401, 0.03067580983042717, 0.029208501800894737, 0.05821242555975914, 0.06082989647984505, 0.03495607152581215, 0.02444053255021572, 0.07084919512271881, 0.05983855947852135, 0.03970347344875336, 0.05932589992880821, 0.0367523618042469, 0.07694029808044434, 0.06171641871333122, 0.014049740508198738, 0.06745626777410507, 0.0378466434776783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2499532252550125, 0.0266294926404953, 0.03931761160492897, 0.044632140547037125, 0.07087578624486923, 0.034094225615262985, 0.02126503176987171, 0.05726417899131775, 0.05179663375020027, 0.03503984585404396, 0.043922778218984604, 0.039228759706020355, 0.061559129506349564, 0.0512242466211319, 0.015611974522471428, 0.08278115093708038, 0.03891744837164879, 0.035886332392692566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.222697913646698, 0.02651810832321644, 0.039789535105228424, 0.027604004368185997, 0.08196067810058594, 0.03582964092493057, 0.015378952957689762, 0.06874662637710571, 0.05343088135123253, 0.05469820648431778, 0.05721571668982506, 0.03161528334021568, 0.03717072680592537, 0.05228295549750328, 0.011851192452013493, 0.0720609650015831, 0.03087829053401947, 0.024411147460341454, 0.055859170854091644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07419286668300629, 0.050926972180604935, 0.028230978175997734, 0.034200072288513184, 0.03361427038908005, 0.051822178065776825, 0.009658369235694408, 0.04940613731741905, 0.09883324801921844, 0.05356481298804283, 0.02458188124001026, 0.05879184231162071, 0.01302679255604744, 0.10889022052288055, 0.01567712612450123, 0.04766634479165077, 0.06507280468940735, 0.03886165842413902, 0.03984261676669121, 0.10313884913921356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22614887356758118, 0.02576986886560917, 0.03336169198155403, 0.04034488648176193, 0.06116843968629837, 0.03166025131940842, 0.023036977276206017, 0.04815823212265968, 0.04964131489396095, 0.02570328675210476, 0.05132424086332321, 0.029225800186395645, 0.0462723933160305, 0.04679546132683754, 0.01047150045633316, 0.043467387557029724, 0.027977772057056427, 0.033561065793037415, 0.03209926560521126, 0.05562404915690422, 0.05818726867437363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19442987442016602, 0.020005781203508377, 0.02566998079419136, 0.02761007659137249, 0.07351990044116974, 0.02511858567595482, 0.016428444534540176, 0.0544336661696434, 0.044502679258584976, 0.0222728680819273, 0.029331281781196594, 0.03064262866973877, 0.06286599487066269, 0.0433916412293911, 0.01021601166576147, 0.09763479232788086, 0.029601430520415306, 0.028080439195036888, 0.03757164254784584, 0.05037400871515274, 0.06089738756418228, 0.01540080551058054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19766588509082794, 0.041157495230436325, 0.03360121697187424, 0.023870186880230904, 0.06633447110652924, 0.02801697887480259, 0.019582942128181458, 0.05178564041852951, 0.03159146383404732, 0.026536140590906143, 0.0416431650519371, 0.025757968425750732, 0.0432840920984745, 0.029939454048871994, 0.012750321999192238, 0.056069161742925644, 0.024677351117134094, 0.02150590345263481, 0.045592937618494034, 0.07480885088443756, 0.044334057718515396, 0.021997367963194847, 0.037497010082006454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1804356724023819, 0.02334981970489025, 0.023929765447974205, 0.044541697949171066, 0.040705956518650055, 0.03654098138213158, 0.016616584733128548, 0.05323561280965805, 0.050283923745155334, 0.02584689110517502, 0.04605168476700783, 0.024920543655753136, 0.03976094350218773, 0.04893423989415169, 0.012390019372105598, 0.06191657483577728, 0.023965347558259964, 0.02875448204576969, 0.02509540505707264, 0.06865917891263962, 0.0735766589641571, 0.018046913668513298, 0.022800743579864502, 0.009640375152230263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2424635887145996, 0.02469644322991371, 0.03868826478719711, 0.033572323620319366, 0.05476619303226471, 0.03380467742681503, 0.02072160132229328, 0.03275461494922638, 0.04349980503320694, 0.01856265589594841, 0.03646847978234291, 0.031002484261989594, 0.03862546384334564, 0.039931803941726685, 0.010727171786129475, 0.03831766918301582, 0.029280317947268486, 0.024678120389580727, 0.027889322489500046, 0.045021556317806244, 0.043075986206531525, 0.016905829310417175, 0.023586291819810867, 0.007298625539988279, 0.04366059601306915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11111283302307129, 0.029458744451403618, 0.024559468030929565, 0.030902530997991562, 0.033864837139844894, 0.033630646765232086, 0.012831437401473522, 0.03066926635801792, 0.06390535831451416, 0.02348153106868267, 0.025704611092805862, 0.03766981139779091, 0.016167866066098213, 0.06660737842321396, 0.017231760546565056, 0.030658654868602753, 0.039240483194589615, 0.024295225739479065, 0.026388786733150482, 0.058640263974666595, 0.10666146129369736, 0.017623895779252052, 0.02424543909728527, 0.01827959716320038, 0.036750197410583496, 0.059418004006147385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17855210602283478, 0.04373869672417641, 0.02777230180799961, 0.03288250043988228, 0.08083150535821915, 0.036148551851511, 0.01943815127015114, 0.03604714199900627, 0.0315406434237957, 0.02228383533656597, 0.026742074638605118, 0.020272962749004364, 0.04929490014910698, 0.028057057410478592, 0.010035556741058826, 0.028219016268849373, 0.018526636064052582, 0.025377927348017693, 0.03921228647232056, 0.05273989215493202, 0.024735094979405403, 0.028674766421318054, 0.029405983164906502, 0.013893154449760914, 0.0176064595580101, 0.05648734048008919, 0.021483466029167175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15546514093875885, 0.04916936531662941, 0.024515938013792038, 0.025700539350509644, 0.05483130365610123, 0.0420927032828331, 0.01164503674954176, 0.06493963301181793, 0.031219761818647385, 0.02656278759241104, 0.028326869010925293, 0.018289057537913322, 0.03490860015153885, 0.029660990461707115, 0.008558588102459908, 0.0466504730284214, 0.01766982488334179, 0.02372436411678791, 0.019038720056414604, 0.07715761661529541, 0.02730739489197731, 0.019747741520404816, 0.024364115670323372, 0.014429948292672634, 0.01892835833132267, 0.05850560590624809, 0.02436404675245285, 0.022225432097911835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19332920014858246, 0.026298340409994125, 0.03039250150322914, 0.02961190976202488, 0.04520163685083389, 0.03307906910777092, 0.02184077352285385, 0.026594150811433792, 0.04538282752037048, 0.03843945637345314, 0.02691539190709591, 0.024535097181797028, 0.015795720741152763, 0.040367621928453445, 0.010634277015924454, 0.026345491409301758, 0.022409791126847267, 0.019946036860346794, 0.04401850700378418, 0.06709348410367966, 0.033454738557338715, 0.01608494482934475, 0.025615878403186798, 0.01140951830893755, 0.013623220846056938, 0.04055489972233772, 0.016662972047924995, 0.03589887171983719, 0.018463704735040665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15965190529823303, 0.01864234358072281, 0.026677725836634636, 0.028047846630215645, 0.04907771572470665, 0.0260456595569849, 0.01780770905315876, 0.03679424151778221, 0.045969411730766296, 0.019110891968011856, 0.03796318545937538, 0.027620630338788033, 0.02834104560315609, 0.04296436160802841, 0.008847595192492008, 0.03253018483519554, 0.025659985840320587, 0.02448510006070137, 0.029966222122311592, 0.04054072126746178, 0.04233502596616745, 0.017694557085633278, 0.02121768519282341, 0.006380946841090918, 0.031033925712108612, 0.03557969629764557, 0.025066182017326355, 0.02660747617483139, 0.024308431893587112, 0.043031539767980576, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1966170370578766, 0.01979137398302555, 0.0330333448946476, 0.025687098503112793, 0.042206067591905594, 0.03137582167983055, 0.01624363474547863, 0.030698416754603386, 0.036294274032115936, 0.026839347556233406, 0.026712190359830856, 0.023046312853693962, 0.02195010334253311, 0.03344837203621864, 0.010305739939212799, 0.022743644192814827, 0.021480808034539223, 0.021094728261232376, 0.031490400433540344, 0.03692729026079178, 0.037232108414173126, 0.015421994961798191, 0.019252348691225052, 0.0073204925283789635, 0.024766920134425163, 0.04439167678356171, 0.0198507197201252, 0.02613365836441517, 0.018124466761946678, 0.042709074914455414, 0.03681057319045067, 0.0, 0.0, 0.0, 0.0], [0.16313208639621735, 0.022932477295398712, 0.029583686962723732, 0.028615498915314674, 0.037784643471241, 0.026518700644373894, 0.026229016482830048, 0.031034143641591072, 0.03483205661177635, 0.01897561363875866, 0.033202946186065674, 0.026435954496264458, 0.032307371497154236, 0.0313291996717453, 0.01172788068652153, 0.027169130742549896, 0.024106519296765327, 0.02262030355632305, 0.025755558162927628, 0.03801414743065834, 0.03207404538989067, 0.017354248091578484, 0.017987214028835297, 0.009293689392507076, 0.04247137904167175, 0.0312158465385437, 0.019006574526429176, 0.021523447707295418, 0.0175411868840456, 0.040145207196474075, 0.018160777166485786, 0.04091951251029968, 0.0, 0.0, 0.0], [0.15803851187229156, 0.016828803345561028, 0.020642392337322235, 0.045382533222436905, 0.046641744673252106, 0.027835223823785782, 0.020206494256854057, 0.04211510717868805, 0.037034474313259125, 0.01774459145963192, 0.030353328213095665, 0.024713626131415367, 0.034284885972738266, 0.03341372311115265, 0.009082169272005558, 0.035213764756917953, 0.022280126810073853, 0.020849989727139473, 0.027390217408537865, 0.03231459856033325, 0.0376492403447628, 0.014920791611075401, 0.016553670167922974, 0.006309077143669128, 0.02321873977780342, 0.02794986218214035, 0.02383224107325077, 0.015323556959629059, 0.017670489847660065, 0.02681528776884079, 0.022188853472471237, 0.028694558888673782, 0.03650737926363945, 0.0, 0.0], [0.17019402980804443, 0.032125912606716156, 0.02987012080848217, 0.01961558870971203, 0.05489380657672882, 0.03622056171298027, 0.01715220883488655, 0.032326590269804, 0.0315006859600544, 0.02962452918291092, 0.02909429371356964, 0.01662426069378853, 0.02998979575932026, 0.02761414647102356, 0.010949773713946342, 0.03436654806137085, 0.014830096624791622, 0.015176056884229183, 0.03050290234386921, 0.041597455739974976, 0.02064121887087822, 0.017041223123669624, 0.02617543190717697, 0.010538813658058643, 0.007441799156367779, 0.03439135104417801, 0.026077082380652428, 0.029615644365549088, 0.01369301974773407, 0.018074296414852142, 0.03374852240085602, 0.029002603143453598, 0.013117284514009953, 0.016172271221876144, 0.0], [0.11417391896247864, 0.016700677573680878, 0.023576240986585617, 0.03235284611582756, 0.05511363968253136, 0.029616648331284523, 0.017176376655697823, 0.05952787026762962, 0.038434237241744995, 0.020421095192432404, 0.03235999867320061, 0.019217435270547867, 0.019135117530822754, 0.03519751876592636, 0.010996297933161259, 0.04401442036032677, 0.016835959628224373, 0.016212480142712593, 0.023840539157390594, 0.04231660068035126, 0.037168409675359726, 0.009007316082715988, 0.015979532152414322, 0.005828788038343191, 0.02082640305161476, 0.028255829587578773, 0.03160589188337326, 0.02425200864672661, 0.0232852753251791, 0.01991749368607998, 0.02455976791679859, 0.02195737324655056, 0.01319314818829298, 0.020208798348903656, 0.03673402592539787]]]}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import circuitsvis as cv\n",
        "from IPython.display import display\n",
        "\n",
        "display(\n",
        "    cv.attention.attention_patterns(\n",
        "        tokens=reference_gpt2.to_str_tokens(reference_text), attention=cache[\"pattern\", 0][0]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0s9uSRCCTAI"
      },
      "source": [
        "You can also use the `attention_heads` function, which presents the data in a different way (the syntax is exactly the same as `attention_patterns`). Note, if you display this in VSCode then it may exhibit a bug where the main plot continually shrinks in size - if this happens, you should instead save the HTML (i.e. with `html = cv.attention.attention_heads(...); with open(\"attn_heads.html\", \"w\") as f: f.write(str(html))`) and open the plot in your browser.\n",
        "\n",
        "<!-- <details>\n",
        "<summary>Help - my <code>attention_heads</code> plots are behaving weirdly.</summary>\n",
        "\n",
        "This seems to be a bug in `circuitsvis` - on VSCode, the attention head plots continually shrink in size.\n",
        "\n",
        "Until this is fixed, one way to get around it is to open the plots in your browser. You can do this inline with the `webbrowser` library:\n",
        "\n",
        "```python\n",
        "attn_heads = cv.attention.attention_heads(\n",
        "    tokens=reference_gpt2.to_str_tokens(reference_text),\n",
        "    attention=cache[\"pattern\", 0][0]\n",
        ")\n",
        "\n",
        "path = \"attn_heads.html\"\n",
        "\n",
        "with open(path, \"w\") as f:\n",
        "    f.write(str(attn_heads))\n",
        "\n",
        "webbrowser.open(path)\n",
        "```\n",
        "\n",
        "To check exactly where this is getting saved, you can print your current working directory with `os.getcwd()`.\n",
        "</details> -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P8u_h5ZVCTAI",
        "outputId": "7e532e23-8f72-4f09-8194-cdb751b73d8c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x79d20b05da60>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-8646ee83-91a3\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-8646ee83-91a3\",\n",
              "      AttentionHeads,\n",
              "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9679255485534668, 0.0320744626224041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8024237155914307, 0.16839197278022766, 0.0291843693703413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6959055066108704, 0.12269632518291473, 0.1458849012851715, 0.03551323711872101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5661025047302246, 0.1470518857240677, 0.08665253221988678, 0.11258414387702942, 0.08760891109704971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.462187260389328, 0.13512833416461945, 0.09698352217674255, 0.1747375875711441, 0.04624601826071739, 0.08471736311912537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.43251603841781616, 0.1038287803530693, 0.08330139517784119, 0.06995753198862076, 0.074793741106987, 0.21568654477596283, 0.01991591602563858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2223673164844513, 0.09167695045471191, 0.0879632756114006, 0.25168734788894653, 0.08263692259788513, 0.10428164899349213, 0.06469017267227173, 0.09469638019800186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4049955904483795, 0.09078018367290497, 0.052373599261045456, 0.0262018870562315, 0.11047185957431793, 0.036674030125141144, 0.025538913905620575, 0.24528279900550842, 0.007681123912334442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39985957741737366, 0.04361315816640854, 0.061838846653699875, 0.072983518242836, 0.03661305829882622, 0.09147472679615021, 0.07241711020469666, 0.07013335078954697, 0.06429056823253632, 0.08677607029676437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09702547639608383, 0.03552757576107979, 0.02321481518447399, 0.03676706179976463, 0.025158395990729332, 0.2775617241859436, 0.07676512748003006, 0.1950119137763977, 0.05580100789666176, 0.14529386162757874, 0.03187303990125656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24143841862678528, 0.03971059247851372, 0.07687386870384216, 0.02804269827902317, 0.12435996532440186, 0.05601578578352928, 0.06063668429851532, 0.1284010261297226, 0.015699446201324463, 0.09114035964012146, 0.13185440003871918, 0.005826778244227171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1436309814453125, 0.05110500380396843, 0.05505896359682083, 0.07798513025045395, 0.0785427913069725, 0.03501971438527107, 0.13498607277870178, 0.2263406664133072, 0.041628528386354446, 0.03513140603899956, 0.020236020907759666, 0.04114445671439171, 0.05919027701020241, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3156284689903259, 0.06791999191045761, 0.037872400134801865, 0.01787460409104824, 0.08683164417743683, 0.02922779880464077, 0.017664164304733276, 0.18301638960838318, 0.0049878014251589775, 0.043228648602962494, 0.05172263830900192, 0.008913453668355942, 0.1289924532175064, 0.006119511555880308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28410202264785767, 0.0534539632499218, 0.023969221860170364, 0.022562265396118164, 0.04619826003909111, 0.06391074508428574, 0.04539212957024574, 0.07758504152297974, 0.027644319459795952, 0.05804117023944855, 0.17727358639240265, 0.0340060219168663, 0.03052728995680809, 0.03213079646229744, 0.023203188553452492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14103911817073822, 0.02857781946659088, 0.03760399669408798, 0.031378280371427536, 0.03697337582707405, 0.07347071915864944, 0.07151783257722855, 0.09211233258247375, 0.03358155116438866, 0.036391302943229675, 0.18937668204307556, 0.03244517743587494, 0.06021039932966232, 0.03916927054524422, 0.040409550070762634, 0.05574262514710426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20265290141105652, 0.030252812430262566, 0.060034118592739105, 0.021786168217658997, 0.10314235836267471, 0.045168377459049225, 0.04681026563048363, 0.10542114078998566, 0.011398817412555218, 0.07159949094057083, 0.10570329427719116, 0.004199369810521603, 0.11079790443181992, 0.013912520371377468, 0.02892351895570755, 0.03286949172616005, 0.005327519495040178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20498354732990265, 0.040072306990623474, 0.042298149317502975, 0.024939019232988358, 0.04992292821407318, 0.02937168814241886, 0.030769700184464455, 0.10315565019845963, 0.025490228086709976, 0.07886795699596405, 0.10560182482004166, 0.017352715134620667, 0.0808369442820549, 0.031286969780921936, 0.05451060086488724, 0.05288316681981087, 0.021742800250649452, 0.005913801025599241, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24350900948047638, 0.036364879459142685, 0.04196164757013321, 0.026215722784399986, 0.0404457151889801, 0.09965364634990692, 0.02575223334133625, 0.03249461576342583, 0.024459948763251305, 0.03520263731479645, 0.03383538872003555, 0.03347689285874367, 0.04664862900972366, 0.0279679112136364, 0.01864079385995865, 0.1176426038146019, 0.03875287249684334, 0.022786680608987808, 0.05418812856078148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14194567501544952, 0.03406403586268425, 0.033009905368089676, 0.020238704979419708, 0.03927316889166832, 0.026005549356341362, 0.006318638101220131, 0.04079786315560341, 0.03638003021478653, 0.14631050825119019, 0.016386179253458977, 0.023598456755280495, 0.01584276556968689, 0.04227606579661369, 0.022458229213953018, 0.06867397576570511, 0.027878474444150925, 0.03722239285707474, 0.08677610009908676, 0.13454324007034302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21778127551078796, 0.026903681457042694, 0.023647215217351913, 0.00710256164893508, 0.035170022398233414, 0.013998538255691528, 0.010392273776233196, 0.09431248158216476, 0.002962291007861495, 0.03783804550766945, 0.037923313677310944, 0.003733975812792778, 0.06506100296974182, 0.0036364595871418715, 0.014758051373064518, 0.12028629332780838, 0.004900882486253977, 0.008107366971671581, 0.01744985394179821, 0.24998730421066284, 0.004047101363539696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12187217175960541, 0.07663210481405258, 0.030231976881623268, 0.016371840611100197, 0.05268789455294609, 0.02140214666724205, 0.023403892293572426, 0.1064968928694725, 0.018582485616207123, 0.035091664642095566, 0.08394153416156769, 0.017393294721841812, 0.04183054342865944, 0.021453870460391045, 0.033331021666526794, 0.05027424544095993, 0.020740864798426628, 0.04090358689427376, 0.0305409524589777, 0.09200657159090042, 0.028245704248547554, 0.036564696580171585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2126019150018692, 0.02028411440551281, 0.050003714859485626, 0.015904176980257034, 0.05722508579492569, 0.022857310250401497, 0.046045877039432526, 0.03530842438340187, 0.011784469708800316, 0.041404832154512405, 0.016803612932562828, 0.015782058238983154, 0.02020842581987381, 0.013090190477669239, 0.020854240283370018, 0.06297556310892105, 0.018039435148239136, 0.018052963539958, 0.024445300921797752, 0.17059145867824554, 0.01593976467847824, 0.04152190312743187, 0.048275113105773926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2671400308609009, 0.035646166652441025, 0.0204229187220335, 0.006622722838073969, 0.04034103453159332, 0.019110344350337982, 0.01457529328763485, 0.05641632899641991, 0.008403637446463108, 0.015526894479990005, 0.04414669796824455, 0.011055916547775269, 0.040019966661930084, 0.009353090077638626, 0.019351882860064507, 0.07054154574871063, 0.01279882900416851, 0.012832626700401306, 0.014165611937642097, 0.1173698902130127, 0.0073127844370901585, 0.09727416932582855, 0.020751141011714935, 0.03882049769163132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.145912304520607, 0.03319380059838295, 0.03138771280646324, 0.009927908889949322, 0.052096571773290634, 0.01984088495373726, 0.01940172351896763, 0.0758240818977356, 0.012863251380622387, 0.03345127031207085, 0.016568399965763092, 0.014797154814004898, 0.059083860367536545, 0.015597395598888397, 0.011369233019649982, 0.021859485656023026, 0.019473880529403687, 0.014793704263865948, 0.05341865494847298, 0.0952148362994194, 0.01620457135140896, 0.06210917606949806, 0.06182851642370224, 0.06657972186803818, 0.03720196336507797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06265700608491898, 0.014285162091255188, 0.025387225672602654, 0.030092529952526093, 0.02124691754579544, 0.02952989935874939, 0.026446690782904625, 0.014830494299530983, 0.015861934050917625, 0.043314315378665924, 0.021963968873023987, 0.0199701189994812, 0.043428532779216766, 0.01869288831949234, 0.00947535876184702, 0.024197492748498917, 0.023853639140725136, 0.026908745989203453, 0.01406070590019226, 0.17528504133224487, 0.03583676367998123, 0.047922566533088684, 0.0357506163418293, 0.01207052357494831, 0.05927427485585213, 0.14765654504299164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09766793996095657, 0.03152173385024071, 0.02668641321361065, 0.03645578399300575, 0.034923702478408813, 0.08635788410902023, 0.013895384036004543, 0.03018672578036785, 0.019402572885155678, 0.035141680389642715, 0.04878159612417221, 0.012551559135317802, 0.04099079594016075, 0.020208820700645447, 0.012653263285756111, 0.007451050914824009, 0.013522980734705925, 0.024078071117401123, 0.043027088046073914, 0.15066799521446228, 0.02925257943570614, 0.018810182809829712, 0.016104495152831078, 0.028549866750836372, 0.029875919222831726, 0.05121561139822006, 0.040018316358327866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0915180891752243, 0.011421110481023788, 0.039799030870199203, 0.011658592149615288, 0.033443327993154526, 0.041076067835092545, 0.009538297541439533, 0.04061253368854523, 0.00911439023911953, 0.04690400883555412, 0.027317609637975693, 0.010844956152141094, 0.024547509849071503, 0.010004599578678608, 0.008095644414424896, 0.008396814577281475, 0.011855490505695343, 0.00818414706736803, 0.041040632873773575, 0.36258113384246826, 0.007537384983152151, 0.009961559437215328, 0.021045763045549393, 0.01185503788292408, 0.03005831502377987, 0.032811954617500305, 0.02886321023106575, 0.009912791661918163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1094629317522049, 0.025872724130749702, 0.023928716778755188, 0.020045259967446327, 0.035904448479413986, 0.031679846346378326, 0.029145298525691032, 0.11399827897548676, 0.013954722322523594, 0.03480715677142143, 0.0181056447327137, 0.01762225478887558, 0.01900731585919857, 0.015307595022022724, 0.009703018702566624, 0.01240796223282814, 0.020091699436306953, 0.02726253867149353, 0.0656459778547287, 0.02715539187192917, 0.02622661180794239, 0.018942993134260178, 0.04077142849564552, 0.019073303788900375, 0.021573422476649284, 0.030219439417123795, 0.07011830806732178, 0.06031463295221329, 0.041651081293821335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11406350880861282, 0.026556236669421196, 0.019958432763814926, 0.008931465446949005, 0.03494322672486305, 0.01683431677520275, 0.00937773659825325, 0.0445132739841938, 0.0037722205743193626, 0.02876030094921589, 0.020741166546940804, 0.0056509943678975105, 0.060077618807554245, 0.004424977116286755, 0.010821852833032608, 0.04112930968403816, 0.007085718214511871, 0.01043399702757597, 0.02654852531850338, 0.11019265651702881, 0.007190010044723749, 0.056519392877817154, 0.02802707441151142, 0.06370093673467636, 0.03407692909240723, 0.07150982320308685, 0.04093319550156593, 0.014252976514399052, 0.06984370201826096, 0.009128457866609097, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14399927854537964, 0.02045460231602192, 0.042623862624168396, 0.011592105031013489, 0.027789438143372536, 0.014342918992042542, 0.029106207191944122, 0.04215823858976364, 0.013669712468981743, 0.020581481978297234, 0.008641068823635578, 0.012402212247252464, 0.019577061757445335, 0.014879738911986351, 0.023319056257605553, 0.022367175668478012, 0.01441388763487339, 0.006065305322408676, 0.006985298823565245, 0.08859118074178696, 0.014219227246940136, 0.027541209012269974, 0.05707305297255516, 0.02498570829629898, 0.05733298510313034, 0.04808966442942619, 0.018268700689077377, 0.07940171658992767, 0.04377178102731705, 0.02484910562634468, 0.02090698853135109, 0.0, 0.0, 0.0, 0.0], [0.0778680145740509, 0.019732853397727013, 0.019906379282474518, 0.015179569832980633, 0.029269905760884285, 0.008963333442807198, 0.011427865363657475, 0.03169625625014305, 0.006965260952711105, 0.04064168408513069, 0.019985223188996315, 0.008789056912064552, 0.035749901086091995, 0.007953660562634468, 0.009612184949219227, 0.01496591791510582, 0.010367295704782009, 0.013544994406402111, 0.013747340068221092, 0.06818544864654541, 0.011837059631943703, 0.01935550943017006, 0.016761237755417824, 0.01630123145878315, 0.061250220984220505, 0.12023529410362244, 0.04739145189523697, 0.02382204681634903, 0.1494300365447998, 0.014121505431830883, 0.04741878807544708, 0.007523445412516594, 0.0, 0.0, 0.0], [0.14836610853672028, 0.03627423197031021, 0.02376876212656498, 0.005308398976922035, 0.03226036950945854, 0.01743944175541401, 0.015090282075107098, 0.04443071782588959, 0.004935787059366703, 0.021151496097445488, 0.02384909987449646, 0.006127791944891214, 0.04430980235338211, 0.005717848427593708, 0.006861453875899315, 0.016362618654966354, 0.007707127369940281, 0.009109631180763245, 0.028427591547369957, 0.14491389691829681, 0.0063516017980873585, 0.03453822806477547, 0.02327299490571022, 0.04803795367479324, 0.03441666439175606, 0.0697537213563919, 0.027561916038393974, 0.012016532011330128, 0.03535732254385948, 0.008575201965868473, 0.039163023233413696, 0.009715795516967773, 0.008826583623886108, 0.0, 0.0], [0.11389312893152237, 0.021931476891040802, 0.026447618380188942, 0.007602890953421593, 0.020530683919787407, 0.029713168740272522, 0.03694964200258255, 0.02875792607665062, 0.007981309667229652, 0.02935916930437088, 0.015349607914686203, 0.018420161679387093, 0.020850971341133118, 0.008514756336808205, 0.0109309246763587, 0.009227685630321503, 0.02127930149435997, 0.009222986176609993, 0.027651101350784302, 0.12458859384059906, 0.010509631596505642, 0.060961924493312836, 0.022033261135220528, 0.0303669311106205, 0.0274112019687891, 0.0345994271337986, 0.03202730417251587, 0.0395297072827816, 0.05353797599673271, 0.017732912674546242, 0.017497548833489418, 0.017771488055586815, 0.012080216780304909, 0.03473733365535736, 0.0], [0.13933587074279785, 0.02137126214802265, 0.014541374519467354, 0.00512328976765275, 0.0316351093351841, 0.010921812616288662, 0.012541361153125763, 0.02249288558959961, 0.004774261265993118, 0.024901418015360832, 0.01085835974663496, 0.010577717795968056, 0.02590608410537243, 0.005286504980176687, 0.016752300783991814, 0.04520438238978386, 0.012112239375710487, 0.014714688062667847, 0.014629189856350422, 0.08781161159276962, 0.007287844084203243, 0.07496534287929535, 0.015995554625988007, 0.043923430144786835, 0.041024137288331985, 0.07587804645299911, 0.0279245562851429, 0.015250173397362232, 0.013413447886705399, 0.01453278586268425, 0.027215447276830673, 0.03453554958105087, 0.018207423388957977, 0.0350533127784729, 0.02330125868320465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00041899713687598705, 0.9995810389518738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00013394799316301942, 0.00951186940073967, 0.990354061126709, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008606775081716478, 0.002610041992738843, 0.01506681740283966, 0.9814624786376953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.7170477298786864e-05, 0.0006769582978449762, 0.0012692962773144245, 0.00021407846361398697, 0.9978025555610657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.425408304901794e-05, 0.0007904706289991736, 0.0032152836211025715, 0.002708565443754196, 0.0013058249605819583, 0.9918956160545349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00014960514090489596, 0.001836186507716775, 0.0016375009436160326, 0.0010130589362233877, 0.004209812264889479, 8.004387927940115e-05, 0.9910737872123718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00026855681790038943, 0.0009259635698981583, 0.0008250513346865773, 0.0006819659029133618, 0.007268876302987337, 0.001351709826849401, 0.00034691678592935205, 0.9883310198783875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007326354272663593, 0.007828539237380028, 0.003931872546672821, 0.00018373994680587202, 6.433095404645428e-05, 0.00010083136294269934, 6.769891479052603e-05, 7.16408176231198e-05, 0.9804250597953796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.9175745769171044e-05, 9.137414599535987e-05, 0.0003339909017086029, 6.816770473960787e-05, 7.81233684392646e-05, 0.0009843030711635947, 0.00016941322246566415, 0.002541458932682872, 4.413309216033667e-05, 0.9956498742103577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.52032270206837e-06, 2.3466505808755755e-05, 9.186466195387766e-05, 8.013433398446068e-05, 3.939216912840493e-05, 8.521587733412161e-05, 2.5735900635481812e-05, 7.12082110112533e-05, 4.276964318705723e-06, 0.00015049769717734307, 0.9994226694107056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001040030736476183, 0.0022993639577180147, 0.0023920696694403887, 0.00031332348589785397, 0.00013362921890802681, 0.0005168464267626405, 0.0011971109779551625, 6.827456672908738e-05, 0.005444327834993601, 0.0002821744419634342, 4.3057352741016075e-05, 0.9862697720527649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.630400871974416e-05, 0.0003248225257266313, 0.0002445938589517027, 0.0015311642782762647, 0.0008613694808445871, 0.001294386456720531, 6.198453775141388e-05, 2.6642672310117632e-05, 4.8408594011561945e-05, 0.0019855634309351444, 0.0001397185551468283, 0.00011434270709287375, 0.9933207035064697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003044240642338991, 0.001822363119572401, 0.0009289864683523774, 4.880229971604422e-05, 1.6391151802963577e-05, 2.909561590058729e-05, 2.507976387278177e-05, 2.913023672590498e-05, 0.4563220143318176, 2.4578661395935342e-05, 2.4832152121234685e-05, 0.0030043956357985735, 1.6773799416114343e-06, 0.5346784591674805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003981802728958428, 0.0010285042226314545, 0.0008281139889732003, 0.0002375323383603245, 7.348884537350386e-05, 0.0014350343262776732, 6.76568306516856e-05, 0.0002954751253128052, 0.0001429583498975262, 9.929129737429321e-05, 4.608238214132143e-06, 0.0005140082212164998, 5.035671620134963e-06, 0.0001247556647285819, 0.9947452545166016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.074847912415862e-05, 0.0002652601688168943, 0.00011011176684405655, 0.00021231926803011447, 8.290550613310188e-05, 0.0011814204044640064, 1.5688703570049256e-05, 0.0016655954532325268, 1.1725322110578418e-05, 0.0020509432069957256, 0.00013842585030943155, 1.557362156745512e-05, 1.1507408089528326e-05, 9.066184247785714e-06, 0.00022655780776403844, 0.9939122200012207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00044135446660220623, 0.0006528966478072107, 0.0006495668785646558, 9.39807141548954e-05, 4.1127124859485775e-05, 0.00017028441652655602, 0.0005066706798970699, 2.889609277190175e-05, 0.002370184753090143, 0.00010454314178787172, 1.9230965335736983e-05, 0.47055861353874207, 1.6804015103843994e-05, 0.002284094225615263, 0.0002169813815271482, 3.276942879892886e-05, 0.5218120217323303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005350514547899365, 0.0006631249561905861, 0.00018957482825499028, 0.00011594546231208369, 3.930590901290998e-05, 8.452105976175517e-05, 0.0002685999497771263, 0.0003003481251653284, 0.00012727586727123708, 0.0001536341296741739, 2.152451270376332e-05, 0.00041020181379280984, 0.0015090395463630557, 0.00011659023584797978, 0.00013773961109109223, 7.38914095563814e-05, 0.00039899442344903946, 0.9948545694351196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002235247375210747, 0.0002502534771338105, 0.00011739339242922142, 1.8608268874231726e-05, 0.0006291492027230561, 0.0007579223602078855, 3.784089858527295e-05, 0.0033851468469947577, 1.791827889974229e-05, 0.00017818278865888715, 3.4344302548561245e-05, 7.747583731543273e-05, 6.471157394116744e-05, 1.5270292351488024e-05, 0.00029359618201851845, 0.0005734388250857592, 7.154398190323263e-05, 0.00015883143350947648, 0.993094801902771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00030641001649200916, 0.00041680067079141736, 0.00045197163126431406, 0.00015746380086056888, 0.0015800745459273458, 0.0022666300646960735, 0.00014483602717518806, 0.002518873196095228, 4.471185457077809e-05, 0.0027394674252718687, 0.0004348975489847362, 0.00015683105448260903, 2.8505710361059755e-05, 4.005823939223774e-05, 0.000593667384237051, 0.00011775208986364305, 0.00014039620873518288, 0.00018060374713968486, 0.000964188133366406, 0.9867159128189087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009046883322298527, 0.0007260903948917985, 6.491786189144477e-05, 4.578270090860315e-05, 3.669531724881381e-05, 3.389696212252602e-05, 4.1313247493235394e-05, 9.000120189739391e-05, 0.016163920983672142, 1.895378591143526e-05, 3.351377745275386e-05, 0.002181082731112838, 5.341176802176051e-06, 0.018749451264739037, 0.00017897749785333872, 0.00049936881987378, 0.0024355670902878046, 4.2716070311143994e-05, 7.329296204261482e-05, 1.9154376786900684e-05, 0.9495131969451904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00021946315246168524, 0.0011669575469568372, 0.00021983245096635073, 0.000987629871815443, 0.00031338492408394814, 0.00012072655226802453, 5.631538442685269e-06, 2.4260069039883092e-05, 4.5442018745234236e-05, 1.8529613953433e-05, 1.4025728887645528e-05, 1.0154997653444298e-05, 0.0004018025065306574, 4.052646545460448e-05, 0.0001710674405330792, 9.8690579761751e-06, 9.488572686677799e-06, 0.0003931091050617397, 5.709419838240137e-06, 1.78443115146365e-05, 2.8530441340990365e-05, 0.9957762360572815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00019360966689419, 0.0008434188202954829, 0.0005215293494984508, 2.5664539862191305e-05, 0.0004623319546226412, 0.00025401570019312203, 1.8471217117621563e-05, 0.00011509784235386178, 0.0002728897088672966, 0.0001543665857752785, 1.2149133908678778e-05, 0.0006913738907314837, 5.695979780284688e-05, 0.00024024760932661593, 3.827492764685303e-05, 9.934448462445289e-05, 0.0006488916114903986, 8.011733007151634e-05, 0.00019218819215893745, 2.552944715716876e-05, 0.00032434772583656013, 0.0010871071135625243, 0.9936420321464539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001607762067578733, 0.17697355151176453, 0.015483579598367214, 0.0003713874612003565, 0.0003786337038036436, 0.0001645270676817745, 0.0003277379728388041, 0.00016989692812785506, 0.002122961450368166, 3.573095455067232e-05, 6.090143870096654e-05, 0.0004562163958325982, 1.544778933748603e-05, 0.002254315186291933, 0.0015666879480704665, 0.00011843751417472959, 0.00046998911420814693, 5.0373157137073576e-05, 0.00012108059308957309, 6.008965283399448e-05, 0.0008920569671317935, 0.0007518448401242495, 0.0002689965476747602, 0.7952778339385986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003919860755559057, 0.00021421183191705495, 0.0005306116072461009, 1.0745787221821956e-05, 0.00011862369865411893, 4.2257714085280895e-05, 0.0002116035611834377, 4.6925462811486796e-05, 0.00044815789442509413, 0.0001069127902155742, 3.935461791115813e-05, 0.00016830845561344177, 0.00017352333816234022, 0.00045245056389831007, 0.00014294101856648922, 0.00011699317838065326, 0.00017526798183098435, 0.00010119943908648565, 4.251387144904584e-05, 2.037170452240389e-05, 3.837128315353766e-05, 0.00011344613449182361, 0.00025279278634116054, 6.991026748437434e-05, 0.995970606803894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00021530695084948093, 0.00010005839430959895, 0.002380918012931943, 0.0019831403624266386, 0.0011120118433609605, 5.563466766034253e-05, 0.0006109262467361987, 0.0002456435759086162, 8.819004870019853e-05, 0.0011510398471727967, 0.00010669898620108142, 0.00017554867372382432, 5.736272214562632e-05, 7.814793207217008e-05, 0.00024573446717113256, 9.59466979111312e-06, 0.00017032392497640103, 2.8972674044780433e-05, 1.4011699022375979e-05, 0.00016692081408109516, 1.2888869605376385e-05, 0.000244955561356619, 0.0005147012416273355, 4.942109444527887e-05, 0.0005746558308601379, 0.9896071553230286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00011423406976973638, 0.0008627417264506221, 0.0007732232334092259, 0.0007090753642842174, 0.0007292137597687542, 0.001403162837959826, 0.00021403594291768968, 0.0001766648201737553, 6.622044020332396e-05, 3.215937249478884e-05, 0.00045330580906011164, 0.00012008492194581777, 2.2129028366180137e-05, 5.807503475807607e-05, 0.00012917433923576027, 1.9079670892097056e-05, 0.00011076666851295158, 8.564189556636848e-06, 2.363054773013573e-05, 0.00033799809170886874, 5.2118928579147905e-05, 0.0001445568195777014, 0.00019694949151016772, 0.0004510525905061513, 2.057626443274785e-05, 8.764302765484899e-05, 0.9926835894584656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00019798318680841476, 0.00019567922572605312, 0.00022612222528550774, 0.00041943631367757916, 0.0005979692214168608, 0.0004517437773756683, 0.00034782872535288334, 0.0002585809852462262, 2.8019851015415043e-05, 0.0007220002007670701, 0.00013010443944949657, 0.0011632051318883896, 6.916901475051418e-05, 2.4789105736999772e-05, 0.00010386004578322172, 0.00038124900311231613, 0.0011587797198444605, 0.0003314440546091646, 0.00024494522949680686, 0.0001275516115128994, 0.0001609843602636829, 1.9267865354777314e-05, 0.0002717415918596089, 2.0765532099176198e-05, 6.82506724842824e-05, 0.0008764249505475163, 0.000678215641528368, 0.9907240271568298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.157182800350711e-05, 0.0006791104678995907, 0.0007090707076713443, 0.00024164833303075284, 0.00041205380694009364, 0.0009237417252734303, 0.00020848539134021848, 6.639285857090726e-05, 0.00011664817429846153, 8.601925947004929e-05, 0.010591291822493076, 0.00033729069400578737, 2.1898467821301892e-05, 0.00010110715084010735, 0.00010436092270538211, 5.8587360399542376e-05, 0.00032512095640413463, 1.5854115190450102e-05, 5.03360297443578e-06, 0.00040948984678834677, 1.3119491086399648e-05, 5.313343717716634e-05, 1.1887247637787368e-05, 5.5366654123645276e-05, 1.2197681826364715e-05, 8.952635107561946e-05, 0.002243548631668091, 0.0002104189625242725, 0.9818660616874695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007582924445159733, 0.0012331459438428283, 8.604941103840247e-05, 6.291332101682201e-05, 2.8791788281523623e-05, 3.316687434562482e-05, 7.622719567734748e-05, 0.00010868187382584438, 0.006450857501477003, 0.0001478909543948248, 1.0376495993114077e-05, 0.0023889727890491486, 7.883606303948909e-05, 0.007510701660066843, 0.0002874316123779863, 0.0001367574732284993, 0.002760297618806362, 0.0007447169627994299, 8.811110456008464e-05, 2.4702098016859964e-05, 0.006188873201608658, 0.00011647059727692977, 0.00017244012269657105, 0.0002621751045808196, 0.00018419795378576964, 4.432135756360367e-05, 4.855170482187532e-05, 8.903061097953469e-05, 2.6887826606980525e-05, 0.9698501229286194, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002462745178490877, 0.00035919941728934646, 0.00020521896658465266, 9.387754107592627e-05, 8.577331027481705e-05, 5.495216100825928e-05, 4.531839658739045e-05, 1.0722179467848036e-05, 4.867117604590021e-05, 0.00011017607903340831, 0.00010064091475214809, 9.772245539352298e-05, 0.0005496814846992493, 4.362943582236767e-05, 3.9457921957364306e-05, 7.140226807678118e-05, 9.81435805442743e-05, 5.7009699958143756e-05, 2.4251130525954068e-05, 2.3145676095737144e-06, 5.05694406456314e-05, 0.00011318492033751681, 0.00029069941956549883, 6.889968790346757e-05, 0.0006683265673927963, 0.0002321746142115444, 8.348713890882209e-06, 1.743464781611692e-05, 1.0273119187331758e-05, 0.0001388570381095633, 0.9960569143295288, 0.0, 0.0, 0.0, 0.0], [0.00011105906014563516, 3.59915939043276e-05, 4.416057709022425e-05, 0.000225963638513349, 0.00024025869788601995, 1.7348933397443034e-05, 7.204298162832856e-05, 0.0002373898751102388, 8.274747960967943e-05, 0.00010178551019635051, 7.876389645389281e-06, 6.391833449015394e-05, 3.295210990472697e-05, 7.889195694588125e-05, 0.00011627462663454935, 7.139148237911286e-06, 6.571759877260774e-05, 5.3963635764375795e-06, 8.33402282296447e-06, 1.9613898984971456e-05, 4.11063629144337e-05, 8.538003021385521e-05, 3.1616138585377485e-05, 9.91699198493734e-06, 2.3832410079194233e-05, 0.0018293517641723156, 2.6111230909009464e-05, 3.3135107514681295e-05, 1.461270858271746e-05, 0.0008547278121113777, 0.00016745159518904984, 0.9953078627586365, 0.0, 0.0, 0.0], [0.0022552248556166887, 0.0004647754249162972, 0.00012283753312658519, 0.006661214865744114, 8.828951831674203e-05, 0.00024942762684077024, 0.00017555151134729385, 2.656347533047665e-05, 0.004149142652750015, 0.00020833106827922165, 1.597336449776776e-05, 0.0007248223409987986, 1.231808346346952e-05, 0.004929245449602604, 0.0007067776750773191, 2.7460220735520124e-05, 0.0008252456318587065, 5.1487324526533484e-05, 9.107245205086656e-06, 0.0011702000629156828, 0.0011320505291223526, 0.0003872279485221952, 0.00010000276961363852, 0.0005395385669544339, 0.00012797686213161796, 7.418715540552512e-05, 0.0006351851625367999, 5.991848956909962e-05, 0.00020302357734180987, 0.022641262039542198, 7.111399463610724e-05, 0.003479855600744486, 0.947674572467804, 0.0, 0.0], [0.00010488830594113097, 0.0005403999239206314, 0.0002700613404158503, 2.7820002287626266e-05, 0.0008878550142981112, 0.00025317323161289096, 0.0002921410487033427, 0.0009951486717909575, 3.943215779145248e-05, 6.531640246976167e-05, 5.198342842049897e-05, 0.0006716360803693533, 1.9524222807376646e-05, 3.796441524173133e-05, 0.0003154709411319345, 0.00015760367386974394, 0.0006809124606661499, 0.00017366770771332085, 0.0002327592665096745, 0.0004935214528813958, 0.00015254261961672455, 8.968886686488986e-05, 0.0014225832419469953, 0.00022503116633743048, 0.0001539226941531524, 0.00010696918616304174, 0.005650249309837818, 0.0008653252734802663, 0.0002874955243896693, 0.00013868528185412288, 1.4354200175148435e-05, 2.81620305031538e-05, 0.00011612025991780683, 0.9844375848770142, 0.0], [0.001883037039078772, 0.0002301395288668573, 7.19053641660139e-05, 3.798290890699718e-06, 0.002256361534819007, 4.367974543129094e-05, 0.0001278294512303546, 0.0006368020549416542, 0.0005363994278013706, 5.325703568814788e-06, 7.917847688077018e-05, 2.60159868048504e-05, 1.1253255252086092e-05, 0.0005611243541352451, 9.103791853704024e-06, 0.00021052229567430913, 2.689111715881154e-05, 3.242438833694905e-05, 0.0002593934768810868, 0.00045266668894328177, 0.0011520993430167437, 1.1493529200379271e-05, 4.818234810954891e-05, 0.00010571501479716972, 8.452797919744626e-05, 0.00010020854097092524, 2.848370604624506e-05, 2.0415431208675727e-05, 1.8022955146079767e-06, 7.628954335814342e-05, 4.6043314796406776e-05, 9.9735647381749e-05, 5.258399141894188e-06, 0.00019488483667373657, 0.9905610680580139]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9424744844436646, 0.05752556398510933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8506749868392944, 0.09740973263978958, 0.051915328949689865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7641512751579285, 0.10970378667116165, 0.07497041672468185, 0.05117451399564743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6748190522193909, 0.08416198194026947, 0.054702531546354294, 0.07581549137830734, 0.11050093173980713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6857607364654541, 0.08229528367519379, 0.052021175622940063, 0.08139178901910782, 0.04085880517959595, 0.05767223984003067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6174606084823608, 0.05653452128171921, 0.09111695736646652, 0.06854882091283798, 0.06338420510292053, 0.03596974164247513, 0.066985122859478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6047279834747314, 0.06088966503739357, 0.05921151489019394, 0.09558156877756119, 0.042659129947423935, 0.031843431293964386, 0.042630650103092194, 0.06245602294802666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4008438289165497, 0.07533580809831619, 0.042708419263362885, 0.011760729365050793, 0.02668057195842266, 0.01349207665771246, 0.028465470299124718, 0.01390060130506754, 0.3868124783039093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49680259823799133, 0.06792881339788437, 0.05792006477713585, 0.07101531326770782, 0.06963258981704712, 0.018800102174282074, 0.06757563352584839, 0.06346483528614044, 0.06656690686941147, 0.020293204113841057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5176078081130981, 0.08289013803005219, 0.05239768326282501, 0.06842362135648727, 0.04608829692006111, 0.026865946128964424, 0.08181481808423996, 0.03230837732553482, 0.05516275763511658, 0.018549619242548943, 0.01789088360965252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3038182556629181, 0.03185644373297691, 0.02915770374238491, 0.011053649708628654, 0.013536774553358555, 0.016536902636289597, 0.015181961469352245, 0.01551173534244299, 0.026294974610209465, 0.0168909952044487, 0.011886665597558022, 0.5082739591598511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3585987985134125, 0.07880907505750656, 0.059028659015893936, 0.044458676129579544, 0.07822324335575104, 0.019679518416523933, 0.051331207156181335, 0.04009842500090599, 0.08024682104587555, 0.02781190536916256, 0.010250619612634182, 0.13610360026359558, 0.015359464101493359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2511676251888275, 0.04623398557305336, 0.02783856727182865, 0.007056493312120438, 0.01724417321383953, 0.008997929282486439, 0.017309946939349174, 0.009924139827489853, 0.25275108218193054, 0.012778297066688538, 0.008546075783669949, 0.04791995882987976, 0.006098275538533926, 0.28613337874412537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39800775051116943, 0.06433819979429245, 0.049798544496297836, 0.059495650231838226, 0.03182113543152809, 0.0307147353887558, 0.05899552255868912, 0.05480390414595604, 0.03919370844960213, 0.03556445986032486, 0.024916481226682663, 0.04571932554244995, 0.016671665012836456, 0.038943100720644, 0.051015838980674744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3903382420539856, 0.0754939392209053, 0.03844676911830902, 0.043667785823345184, 0.017820749431848526, 0.01271218154579401, 0.04530724138021469, 0.03603021055459976, 0.042170681059360504, 0.01675303280353546, 0.0422486774623394, 0.0509234182536602, 0.030772075057029724, 0.04072083905339241, 0.05648886784911156, 0.060105253010988235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1818235218524933, 0.018224777653813362, 0.017477909103035927, 0.006372256204485893, 0.007922588847577572, 0.01006288081407547, 0.008703161962330341, 0.010297482833266258, 0.015354447066783905, 0.011538181453943253, 0.007091047707945108, 0.3139554262161255, 0.0060198185965418816, 0.015887578949332237, 0.015422005206346512, 0.013188592158257961, 0.3406583368778229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23881423473358154, 0.07684360444545746, 0.04843559488654137, 0.028319768607616425, 0.042976249009370804, 0.019430750980973244, 0.03321721404790878, 0.027472922578454018, 0.018975932151079178, 0.04046749696135521, 0.020095612853765488, 0.05857318267226219, 0.03530573472380638, 0.019691884517669678, 0.09703770279884338, 0.03909805044531822, 0.061994519084692, 0.09324946999549866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3563612401485443, 0.04354535788297653, 0.0543937012553215, 0.03599720075726509, 0.055608730763196945, 0.03285680338740349, 0.019443854689598083, 0.06911692023277283, 0.020649442449212074, 0.03360532596707344, 0.027618741616606712, 0.03408000245690346, 0.02684745565056801, 0.020337311550974846, 0.022298937663435936, 0.036227356642484665, 0.034644752740859985, 0.022655004635453224, 0.05371185019612312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3967011272907257, 0.05178235098719597, 0.039961930364370346, 0.06630745530128479, 0.045571859925985336, 0.02398340031504631, 0.01939675584435463, 0.021365977823734283, 0.020253777503967285, 0.036855824291706085, 0.009492042474448681, 0.041810017079114914, 0.014498689211905003, 0.019783735275268555, 0.029715238139033318, 0.046315453946590424, 0.042466454207897186, 0.03147520124912262, 0.02202763967216015, 0.020235029980540276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2315138727426529, 0.13258197903633118, 0.0602610819041729, 0.01138360146433115, 0.024262722581624985, 0.01455346867442131, 0.016979562118649483, 0.013957405462861061, 0.02247590944170952, 0.027721282094717026, 0.02060709521174431, 0.040846824645996094, 0.027723226696252823, 0.02455071359872818, 0.03857921063899994, 0.04770100861787796, 0.04407113417983055, 0.07720746099948883, 0.046044714748859406, 0.04773344472050667, 0.02924429252743721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20264172554016113, 0.04893084242939949, 0.038946814835071564, 0.026632292196154594, 0.040943484753370285, 0.016175054013729095, 0.04388014227151871, 0.04927310347557068, 0.0374428927898407, 0.018747955560684204, 0.010438336059451103, 0.03027418442070484, 0.011668812483549118, 0.03915901109576225, 0.0836191177368164, 0.026806535199284554, 0.03237595781683922, 0.026771049946546555, 0.041368670761585236, 0.04380548745393753, 0.09921547025442123, 0.03088301047682762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22999967634677887, 0.029275385662913322, 0.024823682382702827, 0.030747536569833755, 0.024439770728349686, 0.0250781811773777, 0.01904827542603016, 0.04161752015352249, 0.02524642087519169, 0.05536346510052681, 0.013840350322425365, 0.03206312283873558, 0.023373719304800034, 0.02689637988805771, 0.037655871361494064, 0.02870968170464039, 0.03498142957687378, 0.038269270211458206, 0.05304878577589989, 0.07750774174928665, 0.042357511818408966, 0.0629706084728241, 0.02268563210964203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2523007094860077, 0.04309259355068207, 0.047794342041015625, 0.02153482288122177, 0.05364762991666794, 0.014357623644173145, 0.016968194395303726, 0.012399846687912941, 0.028107941150665283, 0.022964561358094215, 0.013637302443385124, 0.03462432697415352, 0.013057571835815907, 0.029753565788269043, 0.025925690308213234, 0.03689541295170784, 0.03646587207913399, 0.020091162994503975, 0.03424844145774841, 0.032270632684230804, 0.07516519725322723, 0.033814020454883575, 0.05794446915388107, 0.04293809086084366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24815592169761658, 0.0418383851647377, 0.03725353255867958, 0.019914183765649796, 0.060311757028102875, 0.013761507347226143, 0.01023701298981905, 0.027118362486362457, 0.021247489377856255, 0.014996419660747051, 0.015956413000822067, 0.019741930067539215, 0.01694285310804844, 0.02278241701424122, 0.021159427240490913, 0.01341978833079338, 0.02113155648112297, 0.015880078077316284, 0.03851574286818504, 0.03509928658604622, 0.06386469304561615, 0.04215894639492035, 0.05595177412033081, 0.06510591506958008, 0.057454630732536316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24590614438056946, 0.039794620126485825, 0.034050047397613525, 0.03872010111808777, 0.028344355523586273, 0.024568263441324234, 0.013687246479094028, 0.01988093927502632, 0.017507929354906082, 0.04131213203072548, 0.024649064987897873, 0.017028072848916054, 0.015493782237172127, 0.01803991198539734, 0.02871253527700901, 0.00894533284008503, 0.017858823761343956, 0.029846539720892906, 0.026982231065630913, 0.06119256466627121, 0.03972141072154045, 0.04008691385388374, 0.04656379669904709, 0.04659209027886391, 0.046358175575733185, 0.028156954795122147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.242995023727417, 0.03093666210770607, 0.037281107157468796, 0.029979800805449486, 0.03951822966337204, 0.020689722150564194, 0.02446378953754902, 0.016162265092134476, 0.02351461909711361, 0.015184110961854458, 0.009779488667845726, 0.010400430299341679, 0.00883074663579464, 0.02398892305791378, 0.024419227614998817, 0.03784200921654701, 0.010589987970888615, 0.013367552310228348, 0.0162633266299963, 0.09984056651592255, 0.02563280053436756, 0.027902817353606224, 0.05468779057264328, 0.03170407935976982, 0.027479570358991623, 0.016517242416739464, 0.08002806454896927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24383299052715302, 0.021781539544463158, 0.01905849762260914, 0.02660839818418026, 0.03740561008453369, 0.02708663046360016, 0.0050316075794398785, 0.026656057685613632, 0.017429368570446968, 0.028662465512752533, 0.012151014991104603, 0.03022322990000248, 0.0140682989731431, 0.018160909414291382, 0.015435303561389446, 0.01572182960808277, 0.03215308487415314, 0.024972990155220032, 0.04793378338217735, 0.045989975333213806, 0.031192155554890633, 0.03841525316238403, 0.037881236523389816, 0.03472229093313217, 0.035507507622241974, 0.03336033970117569, 0.05460802838206291, 0.023949556052684784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3087880611419678, 0.040824342519044876, 0.010766173712909222, 0.02708977274596691, 0.019433291628956795, 0.03355548530817032, 0.010839526541531086, 0.01149557065218687, 0.011286423541605473, 0.019319292157888412, 0.03442364186048508, 0.010595869272947311, 0.019463734701275826, 0.011577978730201721, 0.014172404073178768, 0.02159341238439083, 0.010569152422249317, 0.01821252517402172, 0.007991206832230091, 0.05231866613030434, 0.019707782194018364, 0.035325199365615845, 0.02959824912250042, 0.028512969613075256, 0.02101978100836277, 0.018976135179400444, 0.031007932499051094, 0.017736954614520073, 0.10379855334758759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11270298063755035, 0.013211610727012157, 0.015115493908524513, 0.008062336593866348, 0.018075060099363327, 0.020267315208911896, 0.009121795184910297, 0.021654397249221802, 0.024600312113761902, 0.012220281176269054, 0.005230679642409086, 0.021195195615291595, 0.007505763787776232, 0.027240077033638954, 0.0168289877474308, 0.009307198226451874, 0.0237741656601429, 0.009840190410614014, 0.02352040819823742, 0.0180962011218071, 0.11592711508274078, 0.008296091109514236, 0.01503841858357191, 0.016261838376522064, 0.022837121039628983, 0.007970292121171951, 0.010345992632210255, 0.013601294718682766, 0.009923162870109081, 0.36222824454307556, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19907145202159882, 0.023352961987257004, 0.02753552421927452, 0.02074119821190834, 0.049442391842603683, 0.039645493030548096, 0.011580482125282288, 0.038496050983667374, 0.012212725356221199, 0.012634873390197754, 0.018897853791713715, 0.011502721346914768, 0.014417950063943863, 0.012855138629674911, 0.01591630093753338, 0.009284348227083683, 0.011929103173315525, 0.014574798755347729, 0.02956238016486168, 0.030921466648578644, 0.049348846077919006, 0.026833010837435722, 0.03316975012421608, 0.02651391550898552, 0.038417842239141464, 0.03666592016816139, 0.03740684315562248, 0.03744916990399361, 0.041813697665929794, 0.04080501198768616, 0.027000796049833298, 0.0, 0.0, 0.0, 0.0], [0.13580846786499023, 0.02159818820655346, 0.028431465849280357, 0.021366795524954796, 0.03184176981449127, 0.028310758993029594, 0.011232445947825909, 0.016139335930347443, 0.023436741903424263, 0.025144271552562714, 0.012804528698325157, 0.01200050301849842, 0.02091227099299431, 0.025003299117088318, 0.027692237868905067, 0.017305919900536537, 0.012859742157161236, 0.01606629602611065, 0.03279004245996475, 0.03829026594758034, 0.060804788023233414, 0.03674997761845589, 0.0352473147213459, 0.03857800364494324, 0.03904816508293152, 0.036643389612436295, 0.014530431479215622, 0.02163226343691349, 0.010490997694432735, 0.06733931601047516, 0.03867284581065178, 0.04122709482908249, 0.0, 0.0, 0.0], [0.13088135421276093, 0.023744333535432816, 0.0201143529266119, 0.009702397510409355, 0.02695222944021225, 0.013591095805168152, 0.009517530910670757, 0.013271704316139221, 0.027617931365966797, 0.011498380452394485, 0.008886140771210194, 0.016865815967321396, 0.009971975348889828, 0.031318601220846176, 0.01495381724089384, 0.015636594966053963, 0.01875588297843933, 0.008822468109428883, 0.02425832487642765, 0.01859987899661064, 0.06659714132547379, 0.02393534407019615, 0.030215002596378326, 0.038479700684547424, 0.06054788827896118, 0.03886096179485321, 0.021039558574557304, 0.026919951662421227, 0.03078671544790268, 0.0633939579129219, 0.053022902458906174, 0.07499753683805466, 0.016242535784840584, 0.0, 0.0], [0.21679528057575226, 0.03523937612771988, 0.01448057685047388, 0.03231681138277054, 0.021502694115042686, 0.019766855984926224, 0.007716964464634657, 0.03142577409744263, 0.011421254836022854, 0.03985080122947693, 0.005697546061128378, 0.013826759532094002, 0.011217723600566387, 0.011028866283595562, 0.0143423555418849, 0.01669159345328808, 0.013800648972392082, 0.00905416626483202, 0.016551576554775238, 0.04516449198126793, 0.01674339734017849, 0.04049498215317726, 0.04600658640265465, 0.039180245250463486, 0.020771801471710205, 0.04241836071014404, 0.029444055631756783, 0.01654653064906597, 0.0433904305100441, 0.01802881620824337, 0.017493009567260742, 0.031954456120729446, 0.023179978132247925, 0.026455210521817207, 0.0], [0.12406577169895172, 0.05575519800186157, 0.025793127715587616, 0.007745688781142235, 0.019214725121855736, 0.011872387491166592, 0.009303719736635685, 0.0158426184207201, 0.012728424742817879, 0.012888258323073387, 0.013962898403406143, 0.01662725768983364, 0.015507101081311703, 0.013195222243666649, 0.01732509955763817, 0.021147968247532845, 0.017335494980216026, 0.015824295580387115, 0.024794377386569977, 0.01190303172916174, 0.03651022911071777, 0.023874733597040176, 0.04022133722901344, 0.06286037713289261, 0.10149350762367249, 0.053322602063417435, 0.02168961614370346, 0.018244285136461258, 0.00840698555111885, 0.023202305659651756, 0.04960416257381439, 0.020869310945272446, 0.016017954796552658, 0.011101935058832169, 0.04974794387817383]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10778012126684189, 0.8922198414802551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011847443878650665, 0.5536144971847534, 0.4345380365848541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06322271376848221, 0.021719155833125114, 0.09427293390035629, 0.8207851648330688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005095744971185923, 0.0005348753184080124, 0.0010105489054694772, 0.004657563753426075, 0.9887012243270874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005585952196270227, 0.00030240038176998496, 0.0007955086184665561, 0.000678032694850117, 0.028760135173797607, 0.9638778567314148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00026657298440113664, 0.00015396179514937103, 4.344203625805676e-05, 0.0003163387009408325, 0.007582378573715687, 0.008635696955025196, 0.9830015897750854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006940618040971458, 4.8331738071283326e-05, 4.51133782917168e-05, 2.3520799004472792e-05, 0.0022377653513103724, 0.001208052271977067, 0.00932135060429573, 0.9864218235015869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04771990329027176, 0.006346914451569319, 0.0055076126009225845, 0.012776720337569714, 0.012552589178085327, 0.012200524099171162, 0.0077606067061424255, 0.017114857211709023, 0.8780202269554138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.403780859429389e-05, 7.299120738935017e-07, 1.2948523817613022e-06, 1.0040552069767728e-06, 1.519242869107984e-05, 3.6095178074901924e-05, 3.1514438887825236e-05, 0.0010808249935507774, 4.2368381400592625e-05, 0.9986969828605652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00029844240634702146, 1.0225176993117202e-05, 2.077381759590935e-05, 1.0716730685089715e-05, 7.45383367757313e-05, 0.00016580561350565404, 0.001366860349662602, 0.0025834825355559587, 5.024059646530077e-05, 0.3243955075740814, 0.6710233688354492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009233689866960049, 0.0007820426253601909, 0.0006810433696955442, 0.0018207868561148643, 0.0043833889067173, 0.01750914193689823, 0.0033242488279938698, 0.0176074355840683, 0.08099658787250519, 0.10943042486906052, 0.014291894622147083, 0.739939272403717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002393030736129731, 3.3237915886275005e-06, 2.283279172843322e-05, 1.024476659949869e-05, 1.0253623258904554e-05, 4.496401015785523e-05, 2.357668745389674e-05, 6.216618930920959e-05, 0.00032929476583376527, 0.00874954555183649, 0.001878871233202517, 0.0014183465391397476, 0.9872072339057922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012295344844460487, 0.0005298624164424837, 0.00035605113953351974, 0.000600671861320734, 0.000532753299921751, 0.0005349713028408587, 0.00034733518259599805, 0.0008671165560372174, 0.03432308882474899, 0.013273634947836399, 0.007531193550676107, 0.059418000280857086, 0.09377512335777283, 0.775614857673645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.850895053707063e-05, 1.18633588499506e-05, 5.970547135802917e-06, 4.359468675829703e-06, 6.933053100510733e-06, 5.567324842559174e-05, 8.762052857491653e-06, 2.213004518125672e-05, 0.000222383372602053, 0.0002802505623549223, 0.0008127276669256389, 0.0015677304472774267, 0.00018956426356453449, 0.005879418458789587, 0.9908536672592163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.475000115344301e-05, 8.603436072007753e-06, 3.744852165254997e-06, 1.4634181866313156e-07, 2.7017360935133183e-06, 1.1417348105169367e-05, 8.62081469676923e-06, 9.928095096256584e-05, 3.1195138490147656e-06, 0.00022620789241045713, 0.0005323346122168005, 2.980485987791326e-05, 0.0013675636146217585, 5.107997276354581e-05, 0.009570816531777382, 0.9879898428916931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003944714087992907, 0.00013029150431975722, 9.947719081537798e-05, 0.00019776365661527961, 0.00042658488382585347, 0.0014889850281178951, 0.0002834683400578797, 0.001535675604827702, 0.004810090642422438, 0.005567723419517279, 0.0010473616421222687, 0.040826573967933655, 0.009189031086862087, 0.09278517216444016, 0.015853017568588257, 0.027940914034843445, 0.7938732504844666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00021723586542066187, 2.3531161787104793e-05, 7.806292160239536e-06, 4.7329585868283175e-06, 1.567117919876182e-06, 8.667402653372847e-06, 1.2646223694900982e-05, 6.129271787358448e-05, 0.00018869442283175886, 0.000590129173360765, 0.0004205662407912314, 0.000974651426076889, 0.0004217766399960965, 0.004066708497703075, 0.001442242180928588, 0.011960018426179886, 0.022401923313736916, 0.9571957588195801, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000736045534722507, 3.0168180273904e-06, 1.355472249997547e-06, 1.4014716498422786e-06, 3.387705146451481e-05, 3.752294651349075e-05, 1.0748700333351735e-05, 0.0004302710294723511, 1.6196761862374842e-05, 0.0006748265004716814, 0.0005265924264676869, 0.00012409152986947447, 4.7107158025028184e-05, 0.00024138158187270164, 0.000688658154103905, 0.0003870209329761565, 0.002144154626876116, 0.0017651687376201153, 0.99213045835495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.529821803269442e-06, 4.013174681460896e-09, 4.275890752580835e-09, 9.052372185180957e-09, 5.135176479598158e-07, 3.731759534275625e-06, 1.4824270522240113e-07, 4.655122666008538e-06, 1.663049964406582e-08, 3.0296805562102236e-06, 3.1919844332151115e-05, 1.4017439298186218e-07, 4.954938503942685e-07, 2.3671027804539335e-07, 7.952955343171197e-07, 0.00018607293895911425, 2.446675580358715e-06, 1.198231075250078e-05, 0.0005082339630462229, 0.9992390871047974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0094178831204772, 0.00017362393555231392, 0.00019593223987612873, 0.00010542469681240618, 0.00012100092135369778, 0.00013750340440310538, 0.00020822319493163377, 0.00026208770577795804, 0.0009803799912333488, 0.00017425195255782455, 0.0013313923263922334, 0.0032773104030638933, 0.004840620793402195, 0.012378789484500885, 0.0018258984200656414, 0.024282028898596764, 0.054799634963274, 0.07428482919931412, 0.07759273052215576, 0.10845338553190231, 0.6251571178436279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00017886326531879604, 2.971776439153473e-06, 1.2879190762760118e-06, 1.6619660527794622e-06, 3.1533879791822983e-06, 7.608537998748943e-06, 4.4805625520893955e-07, 4.628845999832265e-06, 4.462066499399953e-06, 4.640815404854948e-06, 4.678119239542866e-06, 2.225518983323127e-05, 0.0006885039038024843, 5.880855314899236e-05, 5.511291601578705e-05, 0.0013147679856047034, 0.0004210406041238457, 0.0005279280012473464, 0.0003059153677895665, 0.0011363023659214377, 0.004935138393193483, 0.9903197884559631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0009000818245112896, 3.4609118301887065e-05, 6.000087068969151e-06, 1.3317927596290247e-06, 8.38242340250872e-06, 7.950181498017628e-06, 8.352956228918629e-07, 5.017455350753153e-06, 1.10855626189732e-05, 1.5506166164414026e-05, 2.244969073217362e-05, 3.239461511839181e-05, 7.153368642320856e-05, 0.00011106140300398692, 6.552076229127124e-06, 3.557855961844325e-05, 0.00046084250789135695, 0.0006021021399646997, 0.007735583931207657, 0.004731385502964258, 0.012920125387609005, 0.01699913665652275, 0.9552805423736572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.094504300970584e-05, 5.4195235861698166e-05, 2.1191000996623188e-05, 8.66032394242211e-07, 5.2413856792554725e-06, 2.8113959160691593e-06, 9.647644674259936e-07, 4.259611614543246e-06, 6.819939244451234e-06, 2.6370025807409547e-06, 1.0387340807938017e-05, 3.1177733035292476e-05, 2.5747020117705688e-05, 8.829349098959938e-05, 0.00010530044528422877, 0.00037444676854647696, 0.000583377608563751, 0.000901932711713016, 0.00043120095506310463, 0.004991116467863321, 0.0035159247927367687, 0.015127472579479218, 0.01838499866425991, 0.9552486538887024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001992677425732836, 5.897880441807501e-07, 4.093087113687943e-07, 5.283650352794211e-07, 4.0437427628603473e-07, 6.811440016463166e-07, 2.501958533684956e-07, 3.190993993484881e-07, 5.018010142521234e-06, 3.0599362617067527e-06, 4.776871264766669e-06, 8.10624987934716e-06, 1.7871061572805047e-05, 5.904932913836092e-05, 7.019503300398355e-06, 5.101946953800507e-05, 0.00015419672126881778, 0.00015557766892015934, 0.0004630949115380645, 0.00018736722995527089, 0.0029354498255997896, 0.006998695898801088, 0.004895060323178768, 0.010302482172846794, 0.9735496640205383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.041884312755428e-05, 7.668157664397768e-09, 6.183969958328817e-08, 4.109947226993427e-08, 3.1613333817404055e-07, 1.000401113060434e-07, 6.658505213863464e-08, 4.780262656822742e-07, 4.035145551029018e-08, 6.753223260602681e-06, 8.574266985306167e-08, 1.0514212078760465e-07, 3.2702735097700497e-06, 4.896527343589696e-07, 1.2450341273506638e-06, 9.069827683561016e-06, 2.0693071292043896e-06, 8.541695024177898e-06, 4.513616659096442e-05, 8.528171747457236e-05, 8.476238144794479e-05, 0.0010267900070175529, 0.0013347743079066277, 0.00029600696871057153, 0.005626779980957508, 0.9914274215698242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003747456066776067, 1.2430081142156268e-07, 2.5229135758308985e-07, 3.052446118090302e-07, 4.772525699081598e-06, 6.075436544961121e-07, 8.501713182340609e-07, 1.1030826499336399e-05, 8.098967185787842e-08, 9.651284926803783e-07, 7.193352189460711e-07, 3.233935217394901e-07, 1.760539589668042e-06, 4.446817740699771e-07, 3.2987631470859924e-07, 2.4300254153786227e-05, 3.6642647955886787e-06, 3.0616429285146296e-06, 2.627123103593476e-05, 0.0003426712064538151, 2.0788162146345712e-05, 0.00013409748498816043, 0.0003047241480089724, 9.803599095903337e-05, 0.0004919680068269372, 0.004237066023051739, 0.9939160943031311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00023197566042654216, 7.363608460764226e-07, 1.0658028486432158e-06, 4.7497891841885576e-07, 2.187780410167761e-06, 2.0741656499012606e-06, 1.3842078772086097e-07, 2.5106405701080803e-06, 1.971591530036676e-07, 6.6719812821247615e-06, 8.991777349365293e-07, 6.362178623930959e-07, 6.54478981232387e-07, 7.71795953369292e-07, 4.801884188054828e-07, 1.1122274372610264e-05, 5.561904345086077e-06, 3.862742687488208e-06, 6.753690831828862e-05, 0.0002897945523727685, 4.372486364445649e-05, 0.0001520898222224787, 0.0009337703813798726, 0.00018159403407480568, 8.423287363257259e-05, 0.009933846071362495, 0.00872314628213644, 0.9793182611465454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001570491585880518, 3.1231866159942e-07, 2.931937217454106e-07, 3.137160149435658e-07, 2.196094328610343e-06, 1.416437385159952e-06, 1.1236390946578467e-06, 1.3091786286167917e-06, 5.921503998251865e-08, 7.978082408044429e-07, 2.8036795356456423e-06, 1.9766959269418294e-07, 3.9940181295605726e-07, 2.3048993114116456e-07, 2.2642550447926624e-06, 1.6729478375054896e-05, 1.6667632962708012e-06, 2.8725464744638884e-06, 2.4946944904513657e-05, 0.000255328108323738, 4.849699962505838e-06, 4.708060805569403e-05, 5.325665188138373e-05, 4.240333510097116e-05, 0.00020874878100585192, 0.002043810673058033, 0.08346720784902573, 0.003673004684969783, 0.9099873304367065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010030783014371991, 7.6059291131969076e-06, 5.478914772538701e-06, 4.704095772467554e-06, 1.081826439985889e-06, 7.246848667818995e-07, 6.05722732416325e-07, 1.5847862187001738e-06, 3.183097578585148e-05, 1.8444867464495474e-06, 1.372381689179747e-06, 6.841019057901576e-06, 4.996121333533665e-06, 0.00014220476441551, 2.102600319631165e-06, 2.046115514531266e-05, 6.875464896438643e-05, 8.339442138094455e-05, 7.060833013383672e-05, 0.0002227009244961664, 0.001345351804047823, 0.0011953135253861547, 0.0007637708331458271, 0.0034127647522836924, 0.009595116600394249, 0.008245964534580708, 0.004028412513434887, 0.015673451125621796, 0.03710906207561493, 0.916948676109314, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001459806226193905, 1.3442446800127072e-07, 3.0679700557811884e-07, 1.270083913595954e-07, 9.539687795268037e-08, 4.421364252493731e-08, 7.270958946037354e-09, 2.1630643232128932e-07, 1.7861789558537566e-07, 1.1440956626529442e-07, 4.546703280539077e-08, 1.1406693545268354e-07, 1.7846363675744215e-07, 8.568713383283466e-07, 1.0497500113615388e-07, 1.2474934010242578e-06, 1.1682669764923048e-06, 6.484989967248111e-07, 9.92306559055578e-06, 2.663562190718949e-05, 2.1481049770954996e-05, 7.192366319941357e-05, 0.00015873332449700683, 0.00014563243894372135, 0.002426169579848647, 0.0015144959324970841, 0.0007063171942718327, 0.0022442848421633244, 0.004566820338368416, 0.0098323505371809, 0.9781236052513123, 0.0, 0.0, 0.0, 0.0], [1.069877362169791e-05, 5.128429236833654e-08, 7.382501365782446e-08, 9.797533095934341e-08, 4.944888019053906e-07, 6.26972450845642e-07, 2.625736783556931e-07, 7.361940106420661e-07, 2.510118690679519e-07, 2.1764876692031976e-06, 5.363761488297314e-07, 8.606898518337402e-07, 2.15158095784318e-07, 1.0358799045206979e-06, 2.489508972303156e-07, 1.3481056157615967e-05, 8.521090421709232e-06, 5.148511263541877e-06, 4.645090939447982e-06, 1.6832656910992227e-05, 5.864661216037348e-05, 3.652455416158773e-05, 0.0001648572797421366, 1.194501146528637e-05, 0.0005173988756723702, 0.0024279106874018908, 0.00034773556399159133, 0.001596406102180481, 0.009022929705679417, 0.0131637342274189, 0.06333828717470169, 0.9092466831207275, 0.0, 0.0, 0.0], [0.0012287315912544727, 8.40765733300941e-06, 8.36397612147266e-06, 8.199041985790245e-06, 3.972181730205193e-06, 3.98727206629701e-06, 1.5942525806167396e-06, 4.764995537698269e-06, 4.4619187065109145e-06, 8.699216778040864e-06, 3.4823106034309603e-06, 4.087222350790398e-06, 4.383185569167836e-06, 1.2878696907137055e-05, 2.7650021365843713e-06, 1.1550820090633351e-05, 2.8508402465377003e-05, 1.972618883883115e-05, 8.00795532995835e-05, 0.00016381594468839467, 0.00027661045896820724, 0.0004829977115150541, 0.0005903012352064252, 0.0011750631965696812, 0.003466710913926363, 0.005802728235721588, 0.011907555162906647, 0.016952987760305405, 0.028466511517763138, 0.06137577071785927, 0.1151759997010231, 0.20177730917930603, 0.5509369969367981, 0.0, 0.0], [3.7825222534593195e-05, 6.459638512978927e-08, 1.9273654672247176e-08, 7.97582799805241e-08, 6.70032989091851e-07, 1.246432361767802e-07, 3.072165100093116e-08, 3.367146348409733e-07, 9.954005975032487e-08, 4.541520297607349e-07, 3.406023196816932e-08, 1.7256137141430372e-07, 3.3590222869861464e-07, 3.2563374929850397e-07, 1.1636628549638317e-08, 3.2042125894804485e-06, 1.2533513427115395e-06, 1.7663039670878788e-06, 1.1125961464131251e-05, 2.0410294382600114e-05, 8.103446816676296e-06, 1.2881072507298086e-05, 0.0001419320615241304, 1.1411116247472819e-05, 0.00010671327618183568, 0.00010951135482173413, 0.0017927108565345407, 0.0015404949663206935, 0.0012465217150747776, 0.001597587252035737, 0.0008927045855671167, 0.009557021781802177, 0.009279942139983177, 0.9736242294311523, 0.0], [0.0003539702738635242, 2.644042524480028e-06, 1.7576187474332983e-06, 1.2348102700343588e-06, 5.949696969764773e-06, 1.3091880646243226e-06, 3.362112579452514e-07, 2.4850550062183174e-07, 6.705453188260435e-07, 6.699517740571537e-08, 6.061940212021e-07, 4.6190581315386225e-07, 2.3573320504510775e-06, 1.4622218031945522e-06, 2.976372286411788e-07, 1.6005819816200528e-06, 2.4609041702206014e-06, 1.93171831597283e-06, 3.200153514626436e-05, 2.4652015781612135e-05, 3.429641219554469e-05, 0.00016550855070818216, 7.883973739808425e-05, 0.00018387149611953646, 0.0011651519453153014, 0.00012255352339707315, 0.0011725194053724408, 0.0004984785919077694, 0.003501486498862505, 0.0034007455687969923, 0.011839520186185837, 0.005179095547646284, 0.01671386882662773, 0.02912766858935356, 0.9263803958892822]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9238102436065674, 0.076189786195755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3758925199508667, 0.10050597041845322, 0.5236014723777771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4121372103691101, 0.08231587707996368, 0.18084770441055298, 0.32469916343688965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14052286744117737, 0.005812318529933691, 0.02827639877796173, 0.057330358773469925, 0.7680581212043762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01923070289194584, 0.0014746824745088816, 0.0016810809029266238, 0.004905843175947666, 0.02590659074485302, 0.9468010663986206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006040879059582949, 0.00465822359547019, 0.012865043245255947, 0.008953888900578022, 0.07021678984165192, 0.12025337666273117, 0.7770117521286011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016248270869255066, 0.003929380793124437, 0.01283666305243969, 0.0050996290519833565, 0.017354188486933708, 0.015599329024553299, 0.13602769374847412, 0.7929048538208008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13423295319080353, 0.07014799863100052, 0.03862922266125679, 0.03592688590288162, 0.057204850018024445, 0.06419351696968079, 0.039089810103178024, 0.2145734429359436, 0.3460012674331665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0035958767402917147, 0.00038495013723149896, 0.0004921660292893648, 0.0008088782778941095, 0.0025900956243276596, 0.0024076495319604874, 0.00017131817003246397, 0.011153002269566059, 0.0021147800143808126, 0.9762812852859497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00022834539413452148, 4.666255335905589e-05, 8.20648274384439e-05, 7.73067949921824e-05, 0.00012034264364046976, 0.004319249652326107, 0.003844224149361253, 0.0011965001467615366, 0.00016446944209747016, 0.8530561923980713, 0.13686463236808777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06578907370567322, 0.019290771335363388, 0.020492712035775185, 0.02195679023861885, 0.02668667584657669, 0.08618342131376266, 0.031040910631418228, 0.16103023290634155, 0.03016255795955658, 0.21323662996292114, 0.07554485648870468, 0.24858537316322327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0091233616694808, 0.003399315755814314, 0.016818268224596977, 0.004648813512176275, 0.014602279290556908, 0.05833255499601364, 0.07909014075994492, 0.01766362413764, 0.016087286174297333, 0.15053559839725494, 0.3343389332294464, 0.05438896268606186, 0.24097083508968353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04253435879945755, 0.016550593078136444, 0.00781342014670372, 0.006833470892161131, 0.009650973603129387, 0.009173317812383175, 0.005910308565944433, 0.030093083158135414, 0.05324167385697365, 0.035758912563323975, 0.11968675255775452, 0.07133748382329941, 0.2969222068786621, 0.2944934666156769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01015804149210453, 0.004377418663352728, 0.006503189913928509, 0.0035466866102069616, 0.006157051771879196, 0.005149823613464832, 0.00415825005620718, 0.014994033612310886, 0.017724117264151573, 0.008609655313193798, 0.01355727482587099, 0.02768983505666256, 0.027776136994361877, 0.08518616110086441, 0.7644124031066895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005760938511230052, 3.7584886740660295e-05, 3.10057403112296e-05, 2.8090940759284422e-05, 0.00011757229367503896, 0.0010626487201079726, 0.0008489798638038337, 0.0023644287139177322, 0.0003171181015204638, 0.0005040704854764044, 0.0005438972148112953, 0.0009964655619114637, 0.004787205718457699, 0.0016582146054133773, 0.021181106567382812, 0.9649454951286316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05710114166140556, 0.012982725165784359, 0.012463358230888844, 0.012371201068162918, 0.013064763508737087, 0.03530251979827881, 0.013208819553256035, 0.06362833827733994, 0.01058889739215374, 0.06113193929195404, 0.027357207611203194, 0.08200789242982864, 0.039974603801965714, 0.043028347194194794, 0.06893416494131088, 0.06733901053667068, 0.37951505184173584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0503818579018116, 0.010253237560391426, 0.0090173976495862, 0.007853331044316292, 0.008382104337215424, 0.01603054441511631, 0.007579756900668144, 0.01656814105808735, 0.009558068588376045, 0.020098412409424782, 0.028027672320604324, 0.03172842040657997, 0.02179395779967308, 0.03942328318953514, 0.11988719552755356, 0.047830868512392044, 0.14773686230182648, 0.4078488349914551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009583805687725544, 0.000512220780365169, 0.0006106934160925448, 0.0009717896464280784, 0.0022611040621995926, 0.004041267558932304, 0.0003397607943043113, 0.0023014822509139776, 0.0014669822994619608, 0.004360880237072706, 0.01003958098590374, 0.003883794415742159, 0.0019065379165112972, 0.004968367516994476, 0.003599880263209343, 0.00279565853998065, 0.015628818422555923, 0.014497026801109314, 0.916230320930481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03377581015229225, 0.000847293937113136, 0.000936156720854342, 0.0006967576337046921, 0.004600140266120434, 0.0032576012890785933, 0.00042183659388683736, 0.007556704338639975, 0.0010570589220151305, 0.0036437923554331064, 0.00017823875532485545, 0.0020456223282963037, 0.0014812109293416142, 0.002918047597631812, 0.0056848181411623955, 0.06616660207509995, 0.006820718292146921, 0.005966115742921829, 0.02230619266629219, 0.8296393752098083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014338110573589802, 0.004506281577050686, 0.0022934817243367434, 0.004502634052187204, 0.006348524242639542, 0.006440699566155672, 0.0030759212095290422, 0.0034293788485229015, 0.008825044147670269, 0.013563881628215313, 0.008806233294308186, 0.015333065763115883, 0.010930363088846207, 0.03256243094801903, 0.041650157421827316, 0.029358427971601486, 0.06823207437992096, 0.10101231187582016, 0.1282440572977066, 0.08141805976629257, 0.41512882709503174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012516949325799942, 0.003707381198182702, 0.0011323615908622742, 0.002044015796855092, 0.0021037994883954525, 0.0007217562524601817, 0.0003587715036701411, 0.001065456890501082, 0.003341867122799158, 0.003534771502017975, 0.0018008319893851876, 0.005131382495164871, 0.005956846289336681, 0.011681467294692993, 0.023353110998868942, 0.02462637796998024, 0.023082591593265533, 0.02405393123626709, 0.04505402594804764, 0.04447478801012039, 0.09848442673683167, 0.6617730855941772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.023378070443868637, 0.0029700936283916235, 0.0022721635177731514, 0.003121254500001669, 0.010448776185512543, 0.0027957085985690355, 0.0009500705054961145, 0.006640286184847355, 0.0025093024596571922, 0.0062158978544175625, 0.0018756617791950703, 0.004366475157439709, 0.00589492404833436, 0.007904240861535072, 0.011842506937682629, 0.01178030576556921, 0.01693400926887989, 0.015606722794473171, 0.03699192404747009, 0.0567626953125, 0.03885180875658989, 0.3010689318180084, 0.4288182556629181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04225084185600281, 0.009647662751376629, 0.013069666922092438, 0.0034939260222017765, 0.008718243800103664, 0.000871762225870043, 0.002113070571795106, 0.002520154230296612, 0.0028259295504540205, 0.0030562577303498983, 0.005475995130836964, 0.0044675893150269985, 0.005966206081211567, 0.008145663887262344, 0.027670925483107567, 0.013382639735937119, 0.01818912662565708, 0.0327802412211895, 0.028848370537161827, 0.05995951220393181, 0.09605949372053146, 0.20931926369667053, 0.10138271749019623, 0.299784779548645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02581804059445858, 0.0012453027302399278, 0.0012367722811177373, 0.003155822865664959, 0.002605457790195942, 0.00111783214379102, 0.00023053256154526025, 0.0010614549973979592, 0.0012552995467558503, 0.0014470183523371816, 0.000608303293120116, 0.0021444340236485004, 0.0017222757451236248, 0.003063679439947009, 0.0021307107526808977, 0.001739518134854734, 0.007489562500268221, 0.004201179835945368, 0.016367288306355476, 0.017187541350722313, 0.016647031530737877, 0.06787324696779251, 0.07546130567789078, 0.04369649291038513, 0.7004938721656799, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007508307229727507, 0.000129139210912399, 0.0002290404518134892, 0.0003099401656072587, 0.001587574020959437, 0.00015740787785034627, 0.0003654661704786122, 0.0002631948736961931, 0.000246187555603683, 0.004963845480233431, 0.000849328760523349, 0.00020542528363876045, 0.0035996558144688606, 0.0006757518276572227, 0.0006743200938217342, 0.0028660325333476067, 0.0007401989423669875, 0.0012410666095092893, 0.003433941164985299, 0.0033488052431493998, 0.005896294955164194, 0.015315243974328041, 0.013584447093307972, 0.0038060718216001987, 0.10587524622678757, 0.8221280574798584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015146811492741108, 0.0002837269857991487, 0.0004323886532802135, 0.0012392130447551608, 0.0026600700803101063, 0.0003459537692833692, 0.0002954266674350947, 0.0018772060284391046, 0.00023691226670052856, 0.0001321921736234799, 0.00033548023202456534, 0.00022997868654783815, 0.0002714901929721236, 0.00042095404933206737, 0.0008192576933652163, 0.00030394643545150757, 0.0006469363579526544, 0.00038042673259042203, 0.002392594236880541, 0.002976798452436924, 0.0025756123941391706, 0.005941804498434067, 0.005901212338358164, 0.005208782851696014, 0.025423740968108177, 0.023241249844431877, 0.9002798795700073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02088216505944729, 0.0006866250187158585, 0.0014190289657562971, 0.0016247222665697336, 0.00546672660857439, 0.0019930703565478325, 0.00034445608616806567, 0.0014866290148347616, 0.00038602756103500724, 0.00029867971898056567, 0.0003715484344866127, 0.0005332494038157165, 0.0002567080082371831, 0.0006083346670493484, 0.0003786252054851502, 0.0013748218771070242, 0.0013781338930130005, 0.0009236651239916682, 0.02337499149143696, 0.0377323217689991, 0.004063979256898165, 0.021846620365977287, 0.01851237565279007, 0.005047195125371218, 0.018440252169966698, 0.063994862139225, 0.33002781867980957, 0.4365464150905609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0027297879569232464, 0.00011315734445815906, 0.00025743208243511617, 0.00030652937130071223, 0.000801237765699625, 0.0008870935998857021, 0.00010111573647009209, 0.002048567635938525, 0.0001429120311513543, 0.0001989804586628452, 0.0004309819487389177, 7.435747102135792e-05, 0.00011077825183747336, 0.00022297585383057594, 0.0001040010538417846, 0.0007566184503957629, 0.00018428782641422004, 0.0003102098125964403, 0.0010590286692604423, 0.005394387524574995, 0.001371139194816351, 0.0017238226719200611, 0.003438346553593874, 0.0007791529642418027, 0.0027107952628284693, 0.01124660111963749, 0.261861652135849, 0.04286465793848038, 0.6577694416046143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007169218733906746, 0.002651232061907649, 0.002445027930662036, 0.0030232518911361694, 0.002686190651729703, 0.0007135469932109118, 0.0005127682234160602, 0.0003864864120259881, 0.0009532018448226154, 0.00044078443897888064, 0.0008591757505200803, 0.0012491066008806229, 0.0009424777235835791, 0.0016617255751043558, 0.00044353160774335265, 0.0014648421201854944, 0.00357746216468513, 0.003767341375350952, 0.01212292816489935, 0.006853919476270676, 0.005249569658190012, 0.019704239442944527, 0.026669243350625038, 0.04096020385622978, 0.23853963613510132, 0.05725704878568649, 0.04040539637207985, 0.10933997482061386, 0.0773630291223526, 0.3305874168872833, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011626669205725193, 0.0019658172968775034, 0.000917952274903655, 0.0018197438912466168, 0.002078979043290019, 0.00029357150197029114, 0.00010028555698227137, 0.0005799982463940978, 0.00048541222349740565, 9.764838614501059e-05, 0.00015712776803411543, 0.0004106420965399593, 0.00048777772462926805, 0.0007517866906709969, 0.0007532837917096913, 0.001224212464876473, 0.0010826849611476064, 0.0014821895165368915, 0.002774250227957964, 0.003610333427786827, 0.002137242117896676, 0.009361447766423225, 0.014277668669819832, 0.01184671651571989, 0.04729335382580757, 0.0450628325343132, 0.041560713201761246, 0.0428079329431057, 0.07079774886369705, 0.10084830224514008, 0.581305742263794, 0.0, 0.0, 0.0, 0.0], [0.003873431822285056, 0.0002557098923716694, 0.0006259249639697373, 0.000584395369514823, 0.0012326474534347653, 0.0003945602220483124, 0.0003326675505377352, 0.000155819216161035, 0.00016472722927574068, 0.0007726292824372649, 0.00038669779314659536, 0.00027824417338706553, 0.00015239718777593225, 0.00025198518414981663, 6.452928209910169e-05, 0.0001726413902360946, 0.0007133573526516557, 0.0005384791293181479, 0.007539561949670315, 0.006723249331116676, 0.0013963915407657623, 0.003110357094556093, 0.005501283798366785, 0.0024135871790349483, 0.03896054998040199, 0.023422332480549812, 0.009641138836741447, 0.025750914588570595, 0.12702471017837524, 0.040059298276901245, 0.5142089128494263, 0.183296799659729, 0.0, 0.0, 0.0], [0.015151124447584152, 0.0013760678702965379, 0.001556050730869174, 0.002171710366383195, 0.0025110093411058187, 0.0017854940379038453, 0.00047008675755932927, 0.0006788119790144265, 0.0003899070725310594, 0.000990037340670824, 0.00038026587571948767, 0.0004182497796136886, 0.0004435285518411547, 0.0005140134016983211, 0.00016592239262536168, 0.0006932563264854252, 0.0009629515116102993, 0.0007656944217160344, 0.004365222062915564, 0.006436268333345652, 0.0018688277341425419, 0.008356153033673763, 0.006384759210050106, 0.005890706554055214, 0.0311870276927948, 0.04100944846868515, 0.028566081076860428, 0.041577309370040894, 0.04076458513736725, 0.06712851673364639, 0.30426710844039917, 0.21618831157684326, 0.1645854264497757, 0.0, 0.0], [0.01735411025583744, 0.0005264717037789524, 0.0006208933773450553, 0.0016926310490816832, 0.0062972563318908215, 0.0010202114935964346, 7.362550968537107e-05, 0.0006762267439626157, 0.0004448311519809067, 7.778873259667307e-05, 4.973804243491031e-05, 0.00030359765514731407, 0.00017341799684800208, 0.0005162435118108988, 0.00027352795586921275, 0.0007444001385010779, 0.0006022222223691642, 0.0004544502589851618, 0.002665339270606637, 0.0026638780254870653, 0.00255159311927855, 0.007818794809281826, 0.009490984492003918, 0.0009830398485064507, 0.007624231278896332, 0.01155234407633543, 0.09579716622829437, 0.08069915324449539, 0.09889809042215347, 0.03799614682793617, 0.058356162160634995, 0.11718904972076416, 0.11656810343265533, 0.317244291305542, 0.0], [0.010796324349939823, 0.0030184590723365545, 0.001701078494079411, 0.0027613970451056957, 0.005546445492655039, 0.0005509481416083872, 0.00022208325390238315, 0.00023305864306166768, 0.0008555068634450436, 8.429402078036219e-05, 0.00013491010759025812, 0.00040303386049345136, 0.000215685271541588, 0.0009122335468418896, 0.0007261995342560112, 0.000381884747184813, 0.0007406792719848454, 0.0007301223231479526, 0.0007852279813960195, 0.0013473377330228686, 0.004313784185796976, 0.007729172706604004, 0.005422808229923248, 0.006747075822204351, 0.013981975615024567, 0.0046309903264045715, 0.01939181238412857, 0.02813372202217579, 0.016861911863088608, 0.07724329829216003, 0.054351557046175, 0.13139016926288605, 0.15014052391052246, 0.08434383571147919, 0.36317044496536255]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19326065480709076, 0.806739330291748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09132398664951324, 0.002221891889348626, 0.9064540863037109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07127534598112106, 0.010394592769443989, 0.014608741737902164, 0.9037212133407593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007525176741182804, 8.942753629526123e-05, 7.544117397628725e-05, 3.4135705391236115e-06, 0.9923065304756165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004521052353084087, 4.280496796127409e-06, 9.23039042390883e-05, 2.3636208425159566e-05, 1.1194401849934366e-05, 0.9953475594520569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007938149385154247, 0.00010465264494996518, 4.188252205494791e-05, 8.376279765798245e-06, 0.0002111142239300534, 3.129796368739335e-06, 0.9916926622390747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0024528438225388527, 1.0800486961670686e-05, 1.541069650556892e-05, 2.252152597748136e-07, 3.925116834579967e-05, 5.133605554874521e-06, 2.3800452254363336e-05, 0.9974525570869446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1994485706090927, 0.17831814289093018, 0.06548021733760834, 0.13276450335979462, 0.038584496825933456, 0.010353409685194492, 0.02143358625471592, 0.006723292637616396, 0.3468937277793884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0014458474470302463, 8.054695967985026e-07, 3.064583142986521e-05, 7.412913873849902e-07, 2.0274023881938774e-06, 1.1259035090915859e-05, 1.8223380493509467e-06, 8.012933540157974e-05, 1.0569633701607017e-07, 0.9984266757965088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002338021993637085, 1.2498689102358185e-05, 2.2450123651651666e-05, 4.236504537402652e-06, 2.952029092284647e-07, 1.8947090438814485e-06, 7.769858348183334e-05, 8.969064765551593e-06, 4.6951996068855806e-08, 1.1347678992024157e-06, 0.9975327253341675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.047514598816633224, 0.05268267169594765, 0.020408129319548607, 0.05853002145886421, 0.007166564930230379, 0.008201424963772297, 0.011846396140754223, 0.0017474401975050569, 0.02496333047747612, 0.002697254763916135, 0.0014261913020163774, 0.7628161311149597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006070799194276333, 0.00012957923172507435, 5.9433408750919625e-05, 5.6593407862237655e-06, 0.000261532433796674, 0.0001224183215526864, 1.039932612911798e-05, 1.1076393093389925e-05, 4.060476612721686e-07, 0.0003600465424824506, 2.0115392544539645e-05, 1.364392119285185e-07, 0.9929484128952026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09530565142631531, 0.14180326461791992, 0.050381824374198914, 0.10299666970968246, 0.02981208637356758, 0.0065894098952412605, 0.016824396327137947, 0.004481856245547533, 0.2310645431280136, 0.01943543553352356, 0.01087439525872469, 0.0554320253431797, 0.035438716411590576, 0.19955970346927643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027447892352938652, 0.00014065386494621634, 0.00019846689247060567, 3.4967801184393466e-05, 5.2821637837041635e-06, 0.00015024232561700046, 8.128373883664608e-05, 1.2125184184696991e-05, 6.303911504801363e-05, 6.543227209476754e-05, 2.832501195371151e-06, 3.8907375710550696e-05, 5.673653049598215e-07, 4.210495171719231e-05, 0.9717161655426025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004212113097310066, 3.069683225476183e-05, 6.369430047925562e-05, 8.254540944108157e-07, 8.262124993052566e-07, 3.868334897560999e-05, 4.268802967999363e-06, 3.819402536464622e-06, 1.2628001400116773e-07, 0.00013782735913991928, 1.7806096366257407e-05, 1.7100200366826357e-08, 5.979872184980195e-06, 6.190298051933496e-08, 2.2941551378607983e-06, 0.9954808950424194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01984681561589241, 0.03168346360325813, 0.012553269974887371, 0.03571881726384163, 0.004399014636874199, 0.004350571893155575, 0.007427369710057974, 0.0009372886270284653, 0.012662888504564762, 0.0016050540143623948, 0.0007319960277527571, 0.45634064078330994, 0.002010870724916458, 0.009759286418557167, 0.008237500675022602, 0.0002594128018245101, 0.39147573709487915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027297193184494972, 0.002435704693198204, 0.000270681717665866, 7.525561522925273e-05, 1.3686832062376197e-05, 5.773221346316859e-06, 0.00043018313590437174, 1.4438141079153866e-05, 4.835136132896878e-05, 5.3261013817973435e-05, 9.613298971089534e-06, 6.846687028883025e-05, 0.0003037676215171814, 2.878388659155462e-05, 3.8663900340907276e-05, 2.592678902146872e-05, 4.680045822169632e-05, 0.9688333868980408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006310692988336086, 3.294691487099044e-05, 9.895685252558906e-06, 7.334591032304161e-07, 9.119849710259587e-05, 4.094936593901366e-05, 8.511712621839251e-06, 9.950720414053649e-05, 1.9264832928911346e-07, 8.829235298435378e-07, 1.8906122249973123e-06, 1.1808716635641758e-06, 3.1165220661932835e-06, 9.474767637129844e-08, 3.3017577152349986e-06, 2.5855299099930562e-05, 7.711314538028091e-07, 2.670870799192926e-06, 0.993365466594696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0011340547353029251, 6.961935469007585e-06, 1.2364386748231482e-05, 4.0065501138997206e-07, 5.351819345378317e-05, 5.240101017989218e-06, 4.4595133658731356e-05, 0.0001645079319132492, 1.43445042510848e-08, 1.0388027931185206e-06, 4.778887523571029e-05, 5.058683782976914e-08, 9.468226949138625e-07, 7.475676078172455e-09, 6.603933684345975e-07, 3.843118065560702e-06, 3.346431398654204e-08, 2.4119779595821456e-07, 1.664778210397344e-05, 0.9985070824623108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08800850063562393, 0.18921291828155518, 0.04556255787611008, 0.08163286745548248, 0.017358072102069855, 0.004830402787774801, 0.01895878091454506, 0.0046201348304748535, 0.06910265237092972, 0.012970476411283016, 0.01034302357584238, 0.053664132952690125, 0.009830275550484657, 0.05797472596168518, 0.011936412192881107, 0.009446634911000729, 0.04662337899208069, 0.07882610708475113, 0.010427414439618587, 0.0020946746226400137, 0.1765759140253067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015971189364790916, 0.0030620202887803316, 0.0001418951724190265, 0.0007885742816142738, 4.2993720853701234e-05, 4.131205059820786e-05, 6.306861905613914e-05, 3.5465150176605675e-06, 2.173127722926438e-05, 1.7860953448689543e-05, 1.021398747980129e-05, 2.659637902979739e-05, 3.785558510571718e-05, 1.3186871001380496e-05, 0.00018817662203218788, 4.96388247483992e-06, 1.808511296985671e-05, 4.8640275053912774e-05, 4.463595359993633e-06, 2.4802482130326098e-06, 1.2178916222183034e-05, 0.9794788956642151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007472248747944832, 0.0003719076921697706, 7.639092655153945e-05, 1.1135921340610366e-05, 3.014870708284434e-05, 1.1014448318746872e-05, 5.4528827604372054e-05, 2.2444413843913935e-05, 1.1283866115263663e-05, 2.858791958715301e-05, 5.627749487757683e-06, 7.513612217735499e-05, 7.73430074332282e-05, 6.5297231230943e-06, 8.796931069809943e-06, 8.651516509416979e-06, 5.072796193417162e-05, 7.040868240437703e-06, 3.187646871083416e-05, 1.4034918649485917e-06, 7.0035935095802415e-06, 7.040079799480736e-05, 0.9915595650672913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.022045431658625603, 0.2804945707321167, 0.01667475514113903, 0.00015087143401615322, 0.0006804479635320604, 2.739412411756348e-05, 0.000893833814188838, 1.2499208423832897e-05, 0.00026655328110791743, 5.584168320638128e-06, 5.109103221911937e-05, 9.500434680376202e-05, 1.8194792573922314e-05, 0.00018282832752447575, 0.0016493599396198988, 2.793522253341507e-05, 6.991919508436695e-05, 7.67756937420927e-05, 2.088613109663129e-05, 4.512568466452649e-06, 0.00014541397104039788, 0.00044705031905323267, 5.5147884268080816e-05, 0.6759039163589478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018799467012286186, 0.0019184600096195936, 0.001052386942319572, 7.228145841509104e-05, 0.00013796599523629993, 5.2088158554397523e-05, 6.334375211736187e-05, 9.731957106851041e-06, 8.120811253320426e-05, 5.998387496219948e-05, 9.635974492994137e-06, 4.818717934540473e-05, 4.688356784754433e-05, 5.250570393400267e-05, 0.00044942021486349404, 0.00028932970599271357, 3.537202792358585e-05, 0.00022377951245289296, 0.00020208986825309694, 3.112006879746332e-06, 3.522854967741296e-05, 9.85500228125602e-05, 0.0001810147223295644, 0.00012300792150199413, 0.9759548306465149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0016589773586019874, 6.632470558542991e-06, 3.9323436794802547e-05, 5.512135885510361e-06, 7.328279025387019e-05, 5.176194690648117e-07, 8.362664084415883e-05, 1.611540574231185e-05, 1.840793260043938e-07, 0.00020032616157550365, 1.8497462406230625e-06, 7.683021863158501e-08, 1.8051048755296506e-05, 9.2597367995495e-08, 6.612178822251735e-06, 1.9627846086223144e-06, 5.0048470257024746e-08, 6.371125493842555e-08, 4.881635504716542e-07, 3.839143118966604e-06, 1.8601461704292888e-08, 1.6708657994968235e-06, 8.81660753293545e-07, 6.673329977502362e-08, 1.8785125632803101e-07, 0.9978796243667603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005040663294494152, 0.0003915553097613156, 0.0005618694121949375, 0.0001452302240068093, 3.9371810999000445e-05, 5.409949881141074e-05, 0.0002847950381692499, 4.8287358367815614e-05, 3.1043107355799293e-06, 6.896255217725411e-05, 0.0002681412152014673, 4.210924998915289e-06, 1.211988455906976e-05, 2.0253935417713365e-06, 3.188776099705137e-05, 1.1356515642546583e-05, 3.0187973152351333e-06, 1.2622882422874682e-05, 7.4655627031461336e-06, 3.027799039045931e-06, 4.951110668116598e-07, 3.0154526029946283e-05, 1.8863744116970338e-05, 4.151238499616738e-06, 5.031317414250225e-06, 6.069065875635715e-06, 0.9929414987564087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012448659399524331, 0.00017617024423088878, 2.4151706384145655e-05, 1.2456669537641574e-05, 5.2113035053480417e-05, 2.3546019292552955e-05, 5.673440682585351e-05, 0.00045827668509446084, 2.498383537385962e-06, 0.0001134940903284587, 4.92024228151422e-05, 1.3444526302919257e-05, 7.735934195807204e-05, 1.343708390777465e-06, 6.0608936109929346e-06, 0.00010331763769499958, 8.745474588067736e-06, 1.0811555512191262e-05, 0.00015856359095778316, 1.9056049040955259e-06, 5.418784780886199e-07, 1.23213567349012e-06, 6.472226232290268e-05, 3.58905344910454e-06, 8.650893505546264e-06, 2.9628010906890268e-06, 1.3278948244987987e-05, 0.9973099231719971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001973336096853018, 0.000975057715550065, 7.218521204777062e-05, 9.848424087977037e-05, 4.960866863257252e-05, 5.434062040876597e-05, 0.00037972061545588076, 6.1846380958741065e-06, 1.0831167855940294e-06, 4.491214440349722e-06, 0.0004798358422704041, 9.928667168424e-07, 1.3564583241532091e-05, 6.477196734522295e-07, 1.0186131476075388e-05, 5.581331606663298e-06, 7.113490596566407e-07, 5.998076062496693e-07, 3.2010875656851567e-06, 2.2882857138029067e-06, 1.513085550186588e-07, 7.13077315595001e-06, 1.7937989014171762e-06, 2.4025746824918315e-05, 2.833120333889383e-07, 1.2269149920030031e-05, 0.00023325506481342018, 0.00031319662230089307, 0.9952757358551025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03009931929409504, 0.09027381241321564, 0.028149735182523727, 0.15763863921165466, 0.02647356316447258, 0.003006009152159095, 0.01721954345703125, 0.002244672505185008, 0.0312004704028368, 0.011351735331118107, 0.0013561322120949626, 0.029119184240698814, 0.016773544251918793, 0.023998118937015533, 0.009450536221265793, 0.006288206670433283, 0.023923054337501526, 0.05829622969031334, 0.009904226288199425, 0.00037797351251356304, 0.02459513582289219, 0.04042007029056549, 0.02788674458861351, 0.009823571890592575, 0.04994712397456169, 0.0010651156771928072, 0.014632536098361015, 0.011246390640735626, 0.0020601563155651093, 0.2411784827709198, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004169422201812267, 0.0006143286009319127, 0.0005938469548709691, 0.00011036222713300958, 9.005509491544217e-05, 1.3705158380616922e-05, 0.0005903488490730524, 2.6892357709584758e-06, 8.671501745993737e-06, 4.6116343582980335e-05, 1.005678677756805e-05, 5.362908268580213e-06, 5.1998453272972256e-05, 4.802413968718611e-06, 2.1195246517891064e-05, 2.478504757164046e-05, 3.4400409276713617e-06, 1.8410850316286087e-05, 7.055151218082756e-05, 5.603974386758637e-07, 5.060179319116287e-06, 2.2592128516407683e-05, 6.252538150874898e-05, 1.861934651969932e-05, 0.00014118559192866087, 2.6331084882258438e-05, 1.261043394151784e-06, 1.0759850965769147e-06, 3.093194322900672e-07, 5.7930542425310705e-06, 0.9932644367218018, 0.0, 0.0, 0.0, 0.0], [0.010566665790975094, 0.0013905882369726896, 0.0004313627432566136, 0.00102959293872118, 0.003916396759450436, 0.00015029506175778806, 0.0019935970194637775, 0.00030443735886365175, 2.984509410453029e-05, 0.0006592923309653997, 1.2659825188165996e-05, 7.52750929677859e-05, 0.0003976769803557545, 1.7276539438171312e-05, 0.00038583489367738366, 2.1061901861685328e-05, 5.340313873603009e-05, 6.33502786513418e-05, 0.00012688428978435695, 6.783195203752257e-06, 2.7170561224920675e-05, 0.0001300896255997941, 3.859863136312924e-05, 4.366646317066625e-05, 8.064098437898792e-06, 0.0007468670373782516, 8.195245754905045e-06, 9.368611063109711e-05, 6.252459570532665e-06, 4.44724500994198e-05, 0.00020698650041595101, 0.9770136475563049, 0.0, 0.0, 0.0], [0.017131494358181953, 0.10981207340955734, 0.04528498649597168, 0.16663989424705505, 0.046834930777549744, 0.012714344076812267, 0.0249418206512928, 0.0024605076760053635, 0.016514169052243233, 0.014018183574080467, 0.002804650692269206, 0.017261289060115814, 0.05619140341877937, 0.011843182146549225, 0.024518407881259918, 0.008004877716302872, 0.013582986779510975, 0.027696531265974045, 0.007881486788392067, 0.00137596414424479, 0.009033635258674622, 0.037480004131793976, 0.01436882559210062, 0.016579674556851387, 0.031486254185438156, 0.0022351096849888563, 0.00703256344422698, 0.020338818430900574, 0.0021573668345808983, 0.015735741704702377, 0.03529254347085953, 0.017795007675886154, 0.16295132040977478, 0.0, 0.0], [0.002736238529905677, 0.003270441899076104, 0.00024938516435213387, 2.9521106625907123e-05, 0.00271907658316195, 1.5680814613006078e-05, 0.0011440073139965534, 3.528553861542605e-05, 1.9352071831235662e-05, 3.620963980210945e-05, 1.2202231118862983e-05, 0.00012145649816375226, 4.9556045269127935e-05, 1.1851500858028885e-05, 8.826622070046142e-05, 3.184522211086005e-05, 8.618923311587423e-05, 0.00013057797332294285, 9.267545829061419e-05, 1.8444527086103335e-05, 4.454882855497999e-06, 1.4211034795152955e-05, 0.0002081980783259496, 6.224932440090925e-05, 2.7289963327348232e-05, 8.527088539267424e-06, 0.0010931706055998802, 0.001025898614898324, 1.8266431652591564e-05, 9.8163227448822e-06, 7.599958848913957e-07, 4.151809662289452e-06, 8.365892426809296e-06, 0.9866164922714233, 0.0], [0.01330177579075098, 0.0020241800229996443, 0.0009810654446482658, 0.00027103975298814476, 0.026242606341838837, 6.968415254959837e-05, 0.0001882462966023013, 0.00033232770510949194, 0.00020717503502964973, 0.0003558363241609186, 1.868877916422207e-05, 0.00031016356660984457, 0.00028844247572124004, 0.00014157580153550953, 0.0002101896534441039, 0.0001373013947159052, 0.0002454255591146648, 0.0005858636577613652, 0.0008409089641645551, 0.00037898452137596905, 0.00011255513527430594, 0.0009485286427661777, 0.0002581722801551223, 0.0005371636361815035, 0.0002370645379414782, 9.896155825117603e-05, 1.4541836208081804e-05, 7.514374010497704e-05, 1.014245117403334e-05, 7.690775237279013e-05, 6.643286906182766e-05, 5.4460040701087564e-05, 0.00010782018944155425, 0.002189124934375286, 0.9480814933776855]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9360752105712891, 0.06392484903335571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8446659445762634, 0.06946852803230286, 0.0858655497431755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6426600813865662, 0.1298869252204895, 0.1711716651916504, 0.056281283497810364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5074959993362427, 0.0778627097606659, 0.0726853534579277, 0.10711849480867386, 0.23483744263648987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4970756471157074, 0.06315259635448456, 0.11559104174375534, 0.08851397037506104, 0.1019636020064354, 0.13370312750339508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3081282079219818, 0.06775975227355957, 0.13057535886764526, 0.05440935492515564, 0.040503185242414474, 0.36059141159057617, 0.03803273290395737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32434970140457153, 0.06349694728851318, 0.07783651351928711, 0.07798176258802414, 0.07410477846860886, 0.13590554893016815, 0.07038860768079758, 0.1759362369775772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16412915289402008, 0.03469284996390343, 0.05131255462765694, 0.013317004777491093, 0.17712706327438354, 0.15951897203922272, 0.09812309592962265, 0.2969047427177429, 0.0048745498061180115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18775461614131927, 0.05488045886158943, 0.10758274793624878, 0.043910037726163864, 0.1406543254852295, 0.1169673353433609, 0.052460040897130966, 0.1536639779806137, 0.04935268685221672, 0.09277379512786865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2051711529493332, 0.04006878286600113, 0.0833921805024147, 0.04565277695655823, 0.05697013437747955, 0.13319888710975647, 0.026416387408971786, 0.09950856864452362, 0.05013459175825119, 0.21417362987995148, 0.04531294107437134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10754457861185074, 0.020955437794327736, 0.052468445152044296, 0.008330851793289185, 0.179975226521492, 0.10652031749486923, 0.07210806012153625, 0.20191140472888947, 0.003346041776239872, 0.14021334052085876, 0.10356738418340683, 0.003058961359784007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09423349797725677, 0.022835399955511093, 0.055588554590940475, 0.026967836543917656, 0.12799426913261414, 0.07631109654903412, 0.07361152023077011, 0.16634684801101685, 0.030196361243724823, 0.11622445285320282, 0.13079150021076202, 0.022433562204241753, 0.056465137749910355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11027710139751434, 0.019917329773306847, 0.03387210890650749, 0.008012221194803715, 0.12686960399150848, 0.12052717059850693, 0.06604591012001038, 0.2115958034992218, 0.0029103788547217846, 0.13361383974552155, 0.07830416411161423, 0.005965670570731163, 0.07863972336053848, 0.0034490155521780252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16007709503173828, 0.05452117323875427, 0.059736259281635284, 0.02020750753581524, 0.05266043543815613, 0.10011067986488342, 0.1172926053404808, 0.14998744428157806, 0.017248356714844704, 0.05625280365347862, 0.09442038089036942, 0.01204691082239151, 0.020297693088650703, 0.01824457198381424, 0.06689620018005371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17850056290626526, 0.04271138459444046, 0.05876289680600166, 0.025501543655991554, 0.02821972221136093, 0.0939594954252243, 0.035697728395462036, 0.03853301703929901, 0.027574097737669945, 0.124172143638134, 0.0990019217133522, 0.02991955727338791, 0.04168912395834923, 0.030038557946681976, 0.08029220253229141, 0.06542609632015228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08262613415718079, 0.01422164961695671, 0.03910333290696144, 0.005809779744595289, 0.14161063730716705, 0.08671101182699203, 0.05503493919968605, 0.1562698781490326, 0.002328178845345974, 0.116793192923069, 0.08067946881055832, 0.0021917957346886396, 0.09792859852313995, 0.002736868103966117, 0.03297452628612518, 0.08037843555212021, 0.002601497806608677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09858329594135284, 0.028320662677288055, 0.05263178050518036, 0.017858650535345078, 0.06163658946752548, 0.08070764690637589, 0.07397957891225815, 0.09560469537973404, 0.009335814975202084, 0.08467230945825577, 0.11269160360097885, 0.018467867746949196, 0.03856263309717178, 0.01105150580406189, 0.06964194774627686, 0.09237801283597946, 0.022560443729162216, 0.03131493553519249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1495792120695114, 0.01304806862026453, 0.033948518335819244, 0.015061767771840096, 0.04509885236620903, 0.08479965478181839, 0.027256974950432777, 0.17206282913684845, 0.01685032621026039, 0.10883237421512604, 0.11793845146894455, 0.00832325965166092, 0.01613432541489601, 0.017726469784975052, 0.0261734277009964, 0.05189085379242897, 0.00897608045488596, 0.010605713352560997, 0.0756927952170372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2303972691297531, 0.024296822026371956, 0.02655998058617115, 0.03924617916345596, 0.04230226203799248, 0.04924338683485985, 0.007979441434144974, 0.0732208788394928, 0.03455185517668724, 0.066019207239151, 0.038301702588796616, 0.03672322630882263, 0.024140117689967155, 0.0371052585542202, 0.028557147830724716, 0.054463934153318405, 0.03901507332921028, 0.015944402664899826, 0.04610009118914604, 0.0858316496014595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05691659078001976, 0.006225025746971369, 0.011754424311220646, 0.003549681045114994, 0.07110726088285446, 0.08006573468446732, 0.02216234989464283, 0.11016800999641418, 0.001048491452820599, 0.08122199028730392, 0.026672057807445526, 0.002196080284193158, 0.030598552897572517, 0.0012014044914394617, 0.014937776140868664, 0.14736883342266083, 0.0026267541106790304, 0.03338916227221489, 0.11049015820026398, 0.18504451215267181, 0.001255226437933743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09241706877946854, 0.02605961263179779, 0.024830594658851624, 0.01475398801267147, 0.07309960573911667, 0.04160081222653389, 0.02818295545876026, 0.10522367805242538, 0.01020055916160345, 0.02671685628592968, 0.03863626345992088, 0.008342117071151733, 0.034165363758802414, 0.011011882685124874, 0.02702196314930916, 0.10600946843624115, 0.009498462080955505, 0.0161230880767107, 0.06257017701864243, 0.19003154337406158, 0.010448906570672989, 0.04305500164628029, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.061736516654491425, 0.007029621861875057, 0.01948661170899868, 0.010366822592914104, 0.046012863516807556, 0.07236862182617188, 0.02275238372385502, 0.08978495746850967, 0.005041901022195816, 0.07019016891717911, 0.07947878539562225, 0.006475386209785938, 0.03835069015622139, 0.005680922418832779, 0.015840988606214523, 0.053441066294908524, 0.00752498023211956, 0.018862146884202957, 0.09784611314535141, 0.19087882339954376, 0.006985302083194256, 0.027727801352739334, 0.04613658785820007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.043498445302248, 0.006029140669852495, 0.016271812841296196, 0.0049628885462880135, 0.0923277959227562, 0.05643606558442116, 0.024273188784718513, 0.10004424303770065, 0.0013475836021825671, 0.04695264995098114, 0.04337000846862793, 0.002612092299386859, 0.025980042293667793, 0.0015367756132036448, 0.013811733573675156, 0.12162507325410843, 0.0030840584076941013, 0.014781144447624683, 0.08252862840890884, 0.20843428373336792, 0.00210581230930984, 0.033566392958164215, 0.04992128536105156, 0.00449881749227643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05493931844830513, 0.005164694972336292, 0.013282540254294872, 0.006816815119236708, 0.08581957966089249, 0.04258367791771889, 0.010111798532307148, 0.10901319235563278, 0.0030670405831187963, 0.04195145517587662, 0.03668754920363426, 0.003877607174217701, 0.036396291106939316, 0.003642829367890954, 0.015713095664978027, 0.04514279216527939, 0.004770637024194002, 0.010733411647379398, 0.12949080765247345, 0.18343371152877808, 0.005763917230069637, 0.06008811667561531, 0.064203642308712, 0.008479914627969265, 0.01882552169263363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1161927878856659, 0.024008184671401978, 0.0175008662045002, 0.022795306518673897, 0.05027655512094498, 0.032025471329689026, 0.020647751167416573, 0.039747435599565506, 0.023735977709293365, 0.026677902787923813, 0.018856432288885117, 0.02817135490477085, 0.034608811140060425, 0.02664371207356453, 0.022768095135688782, 0.023577352985739708, 0.031199194490909576, 0.022620437666773796, 0.09706811606884003, 0.06436188519001007, 0.03251432627439499, 0.04557201638817787, 0.04268260300159454, 0.028252843767404556, 0.025809554383158684, 0.08168511837720871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11220825463533401, 0.00527593120932579, 0.01370137371122837, 0.006475640926510096, 0.05825747549533844, 0.0559183694422245, 0.01302725076675415, 0.10451260209083557, 0.00401367386803031, 0.040113665163517, 0.03787229582667351, 0.0031745261512696743, 0.012129995971918106, 0.004096257966011763, 0.007334528956562281, 0.017732810229063034, 0.003475234843790531, 0.0030595515854656696, 0.09483390301465988, 0.2000264972448349, 0.005673970095813274, 0.01637454330921173, 0.017230207100510597, 0.004368433263152838, 0.009308066219091415, 0.09713462740182877, 0.052670352160930634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06115267053246498, 0.004939327482134104, 0.009762823581695557, 0.005227167624980211, 0.036462754011154175, 0.03137053921818733, 0.008218889124691486, 0.11535759270191193, 0.0032728654332458973, 0.0382491871714592, 0.033371757715940475, 0.002179377246648073, 0.007692963350564241, 0.003454807912930846, 0.00908544659614563, 0.027900516986846924, 0.002366592874750495, 0.0039482396095991135, 0.0407714881002903, 0.2757468521595001, 0.003546664956957102, 0.012455109506845474, 0.03261313587427139, 0.003209816524758935, 0.0036030937917530537, 0.1000962108373642, 0.08892866224050522, 0.03501545637845993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11957036703824997, 0.008050519041717052, 0.013377297669649124, 0.0070892684161663055, 0.025275396183133125, 0.05149080976843834, 0.006585441064089537, 0.061659809201955795, 0.005620481446385384, 0.055614862591028214, 0.027291810140013695, 0.004286487121134996, 0.00769842928275466, 0.005996248684823513, 0.00794201996177435, 0.02879050374031067, 0.00487096793949604, 0.004313753917813301, 0.02622806839644909, 0.15385550260543823, 0.010709965601563454, 0.009564646519720554, 0.029178379103541374, 0.005329276900738478, 0.008051513694226742, 0.07812704890966415, 0.10984012484550476, 0.0295210313051939, 0.0940699353814125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02588074654340744, 0.003286874620243907, 0.009190612472593784, 0.002271318808197975, 0.04206257686018944, 0.0403556153178215, 0.01510707288980484, 0.04801337048411369, 0.0008096095989458263, 0.0390641987323761, 0.026566801592707634, 0.0015204494120553136, 0.02122018113732338, 0.0009539546445012093, 0.007810375653207302, 0.03313515707850456, 0.00187924993224442, 0.010119674727320671, 0.06751003116369247, 0.12262912094593048, 0.0015832221833989024, 0.022168036550283432, 0.0307852104306221, 0.004318807739764452, 0.01872900314629078, 0.1447751820087433, 0.06957430392503738, 0.1138874888420105, 0.07182329893112183, 0.002968475455418229, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04612509533762932, 0.004929370246827602, 0.011905019171535969, 0.0059399111196398735, 0.050862327218055725, 0.03915584832429886, 0.011702246963977814, 0.07777240127325058, 0.0027224929071962833, 0.029330715537071228, 0.035436611622571945, 0.0025086570531129837, 0.011883251368999481, 0.002963855629786849, 0.008878662250936031, 0.018936671316623688, 0.002804588759317994, 0.004066924564540386, 0.06637166440486908, 0.16173599660396576, 0.004074744414538145, 0.017417894676327705, 0.048458121716976166, 0.005489852279424667, 0.014467369765043259, 0.0888427346944809, 0.05744141340255737, 0.048157572746276855, 0.09182099252939224, 0.0047510224394500256, 0.023045990616083145, 0.0, 0.0, 0.0, 0.0], [0.0286165252327919, 0.003539714263752103, 0.012825751677155495, 0.003731105476617813, 0.022132832556962967, 0.026339074596762657, 0.015483633615076542, 0.046924490481615067, 0.001677015912719071, 0.05343088135123253, 0.038187284022569656, 0.00252948934212327, 0.02768225222826004, 0.0019447177182883024, 0.010427966713905334, 0.02030639350414276, 0.003083116840571165, 0.008337556384503841, 0.06147442385554314, 0.056954674422740936, 0.0030909229535609484, 0.01978730410337448, 0.037704236805438995, 0.004031910095363855, 0.02077089436352253, 0.12126167118549347, 0.08733708411455154, 0.07036233693361282, 0.09933116286993027, 0.005798673722893, 0.06381495296955109, 0.021079953759908676, 0.0, 0.0, 0.0], [0.022769229486584663, 0.0023638124112039804, 0.006953613366931677, 0.0009745152783580124, 0.03343130648136139, 0.0309631135314703, 0.012881077826023102, 0.0763968825340271, 0.00026210371288470924, 0.030449921265244484, 0.03674255311489105, 0.000567060720641166, 0.014569047838449478, 0.0003055332927033305, 0.005948364734649658, 0.022492554038763046, 0.0007025580271147192, 0.0048664468340575695, 0.060261812061071396, 0.1558590531349182, 0.000500177382491529, 0.019988082349300385, 0.03086847811937332, 0.0031281488481909037, 0.012151171453297138, 0.11994658410549164, 0.07597392052412033, 0.09628817439079285, 0.07584258168935776, 0.0010643766727298498, 0.03271332010626793, 0.01111111044883728, 0.0006632998120039701, 0.0, 0.0], [0.06755813211202621, 0.0033527954947203398, 0.008972212672233582, 0.003402541158720851, 0.056073080748319626, 0.030404701828956604, 0.013628306798636913, 0.07952424883842468, 0.0025889384560287, 0.03472939133644104, 0.01531597413122654, 0.002527100732550025, 0.00768547086045146, 0.0026928249280899763, 0.007113001774996519, 0.02612846903502941, 0.002773371059447527, 0.007069498300552368, 0.05076207220554352, 0.17593896389007568, 0.003935441840440035, 0.010542858392000198, 0.012697337195277214, 0.002831442980095744, 0.00498349079862237, 0.05610370263457298, 0.1027865782380104, 0.07864399999380112, 0.06361376494169235, 0.004290642682462931, 0.01244904100894928, 0.007846906781196594, 0.0035741617903113365, 0.037459541112184525, 0.0], [0.058894261717796326, 0.004834294319152832, 0.008816243149340153, 0.004917600657790899, 0.05724450200796127, 0.04719964414834976, 0.010384353809058666, 0.04373682290315628, 0.003253214992582798, 0.027000511065125465, 0.015386003069579601, 0.005444497801363468, 0.018304413184523582, 0.003610058454796672, 0.011856132186949253, 0.07255370169878006, 0.0060180784203112125, 0.006411904469132423, 0.05586158484220505, 0.08374674618244171, 0.003973668906837702, 0.01859060488641262, 0.019445111975073814, 0.0038806768134236336, 0.008932654745876789, 0.12242709845304489, 0.040986306965351105, 0.07429765164852142, 0.05774557590484619, 0.0063186343759298325, 0.013084126636385918, 0.023065797984600067, 0.005796521902084351, 0.04094136878848076, 0.015039587393403053]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9780336022377014, 0.02196633629500866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5068987607955933, 0.42791464924812317, 0.06518664956092834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34595051407814026, 0.23385089635849, 0.1913881152868271, 0.22881050407886505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.27859705686569214, 0.17525731027126312, 0.11037100106477737, 0.2518094778060913, 0.18396514654159546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20804190635681152, 0.0882713571190834, 0.061608146876096725, 0.25848427414894104, 0.27056995034217834, 0.11302442848682404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1632562130689621, 0.12141187489032745, 0.11990706622600555, 0.16166450083255768, 0.10774080455303192, 0.29750359058380127, 0.02851596660912037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1228092834353447, 0.0397898368537426, 0.045145437121391296, 0.13578511774539948, 0.09269556403160095, 0.11808718740940094, 0.3369846045970917, 0.10870295763015747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07854471355676651, 0.035703860223293304, 0.02910536900162697, 0.05200909078121185, 0.10322193801403046, 0.062225185334682465, 0.06801242381334305, 0.1702916920185089, 0.40088576078414917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08555343002080917, 0.04508211836218834, 0.020755302160978317, 0.05748790502548218, 0.05853370949625969, 0.038125380873680115, 0.031640272587537766, 0.14470809698104858, 0.39396733045578003, 0.12414634227752686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03400759771466255, 0.005801306571811438, 0.004264358896762133, 0.014554589055478573, 0.002058125799521804, 0.010052242316305637, 0.015462438575923443, 0.014919949695467949, 0.07456015050411224, 0.8029414415359497, 0.02137780375778675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.036581333726644516, 0.008552639745175838, 0.009085922501981258, 0.01071860920637846, 0.031510576605796814, 0.07786071300506592, 0.02809949964284897, 0.05203400179743767, 0.09175647795200348, 0.24980762600898743, 0.22384561598300934, 0.18014705181121826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03899509087204933, 0.013953062705695629, 0.027150364592671394, 0.015978632494807243, 0.006068874150514603, 0.015332898125052452, 0.0073584397323429585, 0.008143594488501549, 0.09236103296279907, 0.09582390636205673, 0.3970893919467926, 0.22508259117603302, 0.05666206404566765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02941764146089554, 0.006853987462818623, 0.005433529615402222, 0.008306891657412052, 0.015738293528556824, 0.008708913810551167, 0.008349095471203327, 0.023920103907585144, 0.046946827322244644, 0.04814496263861656, 0.0930999144911766, 0.15290866792201996, 0.1485418677330017, 0.4036293625831604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0371282659471035, 0.007584462407976389, 0.0035451471339911222, 0.008117970079183578, 0.018834207206964493, 0.005904970224946737, 0.009632603265345097, 0.011076663620769978, 0.04249943792819977, 0.015083963982760906, 0.01984347216784954, 0.11177285760641098, 0.12816858291625977, 0.33317869901657104, 0.24762879312038422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024791479110717773, 0.0022572369780391455, 0.0019112303853034973, 0.003149640979245305, 0.0017746681114658713, 0.003080856753513217, 0.019880713894963264, 0.006427106447517872, 0.015317467041313648, 0.003226602915674448, 0.020296048372983932, 0.05772729218006134, 0.02255523018538952, 0.08885949850082397, 0.714112401008606, 0.01463242806494236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019352810457348824, 0.002735717687755823, 0.002700645010918379, 0.0028163986280560493, 0.007300620432943106, 0.016268717125058174, 0.0051347059197723866, 0.010258648544549942, 0.01379147358238697, 0.03380442410707474, 0.033944789320230484, 0.024110401049256325, 0.053474944084882736, 0.09690996259450912, 0.2761882543563843, 0.2219037562608719, 0.17930372059345245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016778266057372093, 0.0013836651341989636, 0.0012504421174526215, 0.0019532653968781233, 0.001228307606652379, 0.003427051240578294, 0.001771017094142735, 0.002587685827165842, 0.009956514462828636, 0.007537410128861666, 0.004963121376931667, 0.023668866604566574, 0.017456673085689545, 0.06967746466398239, 0.2612769901752472, 0.24082402884960175, 0.17677928507328033, 0.15747997164726257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05475038290023804, 0.009201948530972004, 0.003783299820497632, 0.006891878787428141, 0.007006865926086903, 0.005267786327749491, 0.0019135883776471019, 0.006649003829807043, 0.0224907249212265, 0.007203699089586735, 0.039859868586063385, 0.026306964457035065, 0.03598390519618988, 0.10654615610837936, 0.14742803573608398, 0.029531899839639664, 0.14834171533584595, 0.23425260186195374, 0.1065896525979042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08004871755838394, 0.00356274307705462, 0.0033941506408154964, 0.011285580694675446, 0.012208586558699608, 0.0019434967543929815, 0.003920826595276594, 0.024116624146699905, 0.02334999106824398, 0.008975883945822716, 0.005343946162611246, 0.025336073711514473, 0.013870186172425747, 0.10103640705347061, 0.03973820060491562, 0.08061374723911285, 0.12086467444896698, 0.1229468509554863, 0.1413252353668213, 0.1761181354522705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013053345493972301, 0.0019795631524175406, 0.0016182123217731714, 0.0014078525127843022, 0.0014868241269141436, 0.0013099159114062786, 0.0016642939299345016, 0.0025665161665529013, 0.003062670351937413, 0.010340572334825993, 0.007755252066999674, 0.00892942026257515, 0.00886954739689827, 0.01716512441635132, 0.07265801727771759, 0.08664456754922867, 0.06223953887820244, 0.16528475284576416, 0.07255075871944427, 0.09155549108982086, 0.36785778403282166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012316005304455757, 0.0011592352529987693, 0.0007622393313795328, 0.0019507510587573051, 0.0012718499638140202, 0.0006892282981425524, 0.0005458982777781785, 0.00260300375521183, 0.003917665220797062, 0.0005409365985542536, 0.0012741906102746725, 0.006503158248960972, 0.005551592446863651, 0.017973441630601883, 0.013353326357901096, 0.038051243871450424, 0.043033964931964874, 0.03958652913570404, 0.02230064943432808, 0.03898366913199425, 0.5949543118476868, 0.1526770442724228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013724959455430508, 0.001612572930753231, 0.0003289871383458376, 0.0010084330569952726, 0.0011758027831092477, 0.0007259281119331717, 0.0005918759270571172, 0.000961559999268502, 0.0031186218839138746, 0.005970012862235308, 0.0030334636103361845, 0.003344496013596654, 0.008407552726566792, 0.013658510521054268, 0.005607037339359522, 0.005321719218045473, 0.019289923831820488, 0.02910967357456684, 0.013599644415080547, 0.03133779391646385, 0.25137242674827576, 0.5305220484733582, 0.056176941841840744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016002366319298744, 0.0009560448816046119, 0.0005680455942638218, 0.0015549738891422749, 0.0015755707863718271, 0.0006219720817171037, 0.0011257637524977326, 0.0014368736883625388, 0.0023100459948182106, 0.0009028321946971118, 0.0013921464560553432, 0.0036725918762385845, 0.003632282605394721, 0.009217401966452599, 0.008623878471553326, 0.027025727555155754, 0.021376436576247215, 0.03330108895897865, 0.038854021579027176, 0.03905842825770378, 0.2659664750099182, 0.19372612237930298, 0.09792876243591309, 0.22917026281356812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009987279772758484, 0.0009651743457652628, 0.0006041582673788071, 0.0009222141234204173, 0.0008805796969681978, 0.0005974340601824224, 0.00021149194799363613, 0.0006455681868828833, 0.0012417667312547565, 0.0006859695422463119, 0.0007031502318568528, 0.0014577421825379133, 0.0018487719353288412, 0.005077196750789881, 0.0019275662489235401, 0.012413403019309044, 0.008568298071622849, 0.012073671445250511, 0.02193666435778141, 0.0291941799223423, 0.14272768795490265, 0.09834033995866776, 0.11847668141126633, 0.3163197338581085, 0.21219336986541748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01686086691915989, 0.0019703253637999296, 0.0008858375367708504, 0.001765639171935618, 0.002392833586782217, 0.0005271151894703507, 0.0003617889597080648, 0.0006361057749018073, 0.00224113161675632, 0.0008515844820067286, 0.00038157758535817266, 0.002274829428642988, 0.0018798474920913577, 0.0072922417894005775, 0.002146675018593669, 0.0025263046845793724, 0.010355675593018532, 0.011969316750764847, 0.006590907461941242, 0.012827474623918533, 0.12130498141050339, 0.06624650955200195, 0.14612388610839844, 0.28280729055404663, 0.24703305959701538, 0.049746185541152954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.026405010372400284, 0.0014231009408831596, 0.0016234476352110505, 0.002576404018327594, 0.002689703833311796, 0.001225753454491496, 0.0010898751206696033, 0.0009538460872136056, 0.0019223564304411411, 0.0024115294218063354, 0.0024579435121268034, 0.0014354214072227478, 0.005378495901823044, 0.0047323452308773994, 0.0019391176756471395, 0.007957505993545055, 0.00608688872307539, 0.012657439336180687, 0.011602526530623436, 0.029096635058522224, 0.08598874509334564, 0.0766589343547821, 0.03624012693762779, 0.131333589553833, 0.19490279257297516, 0.21766333281993866, 0.131547212600708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.023896077647805214, 0.0020674974657595158, 0.0025093802250921726, 0.0018511994276195765, 0.003160968190059066, 0.000900563201867044, 0.00026854267343878746, 0.0005213551339693367, 0.0017872147727757692, 0.001930898055434227, 0.001015822752378881, 0.001044267090037465, 0.001567705417983234, 0.0040601021610200405, 0.0008207396022044122, 0.003358299843966961, 0.004117123316973448, 0.007223031017929316, 0.014547302387654781, 0.04635155200958252, 0.05601867288351059, 0.03840016946196556, 0.041609954088926315, 0.10494539886713028, 0.1578821837902069, 0.12118801474571228, 0.1909026801586151, 0.16605331003665924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04075776785612106, 0.0039583598263561726, 0.005698095075786114, 0.003957982175052166, 0.0014047796139493585, 0.0003276943461969495, 0.0006401922437362373, 0.0012045823968946934, 0.0022385590709745884, 0.0007448496762663126, 0.0038365793880075216, 0.0016206831205636263, 0.0010148307774215937, 0.00426118727773428, 0.0009652962326072156, 0.00039543205639347434, 0.00540107162669301, 0.007263401057571173, 0.00576681038364768, 0.029991835355758667, 0.04173656553030014, 0.017527665942907333, 0.025155046954751015, 0.0756526067852974, 0.24542629718780518, 0.06668493896722794, 0.26483193039894104, 0.055024128407239914, 0.08651075512170792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011784794740378857, 0.0013947563711553812, 0.0009515657438896596, 0.000895321078132838, 0.0010372711112722754, 0.0004972644383087754, 0.00025283885770477355, 0.00043175695464015007, 0.0005345691461116076, 0.00028229248709976673, 0.00042747301631607115, 0.0005479558021761477, 0.0008038750966079533, 0.0011037482181563973, 0.0010882882634177804, 0.0026353762950748205, 0.0020033165346831083, 0.002939451951533556, 0.005114209372550249, 0.009162317961454391, 0.020236428827047348, 0.014397266320884228, 0.014386608265340328, 0.05287303775548935, 0.044258106499910355, 0.0717473104596138, 0.08077163249254227, 0.11779720336198807, 0.1448613852262497, 0.3947826325893402, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012992850504815578, 0.0016676135128363967, 0.0010021079797297716, 0.0011761257192119956, 0.0007638346287421882, 0.0004005827067885548, 0.00012849250924773514, 0.00010518684575799853, 0.0005606432096101344, 0.00014079366519581527, 0.00012207566760480404, 0.00039859922253526747, 0.00022988310956861824, 0.0011077818926423788, 0.0003631032013799995, 0.0008891792385838926, 0.0014402443775907159, 0.0014520194381475449, 0.002630571834743023, 0.0031673822086304426, 0.01722465269267559, 0.010722342878580093, 0.0050229961052536964, 0.045778512954711914, 0.04751962050795555, 0.027067044749855995, 0.05216856673359871, 0.055007923394441605, 0.11481013894081116, 0.44568830728530884, 0.14825090765953064, 0.0, 0.0, 0.0, 0.0], [0.011720003560185432, 0.0009638665360398591, 0.0016792761161923409, 0.0009598789620213211, 0.001183533575385809, 0.00035873393062502146, 0.0001312520180363208, 0.0002098587719956413, 0.00035185745218768716, 0.00011673840344883502, 0.00033267223625443876, 0.00020899836090393364, 0.0001630404294701293, 0.0005591597873717546, 0.00017877924256026745, 0.0005847528809681535, 0.0006520423339679837, 0.000810088706202805, 0.0008232013205997646, 0.006545142736285925, 0.007790668401867151, 0.006622510030865669, 0.005052968394011259, 0.014489847235381603, 0.02494208700954914, 0.01901032216846943, 0.02852548100054264, 0.036787740886211395, 0.14266954362392426, 0.23489893972873688, 0.3008542060852051, 0.14982274174690247, 0.0, 0.0, 0.0], [0.011463269591331482, 0.0009014818351715803, 0.0005477445083670318, 0.0005869870656169951, 0.0005616629496216774, 0.00023434772447217256, 0.00013944678357802331, 0.00019926785898860544, 0.0003140303597319871, 0.0001251463545486331, 0.00021479520364664495, 0.0002481348055880517, 0.0002290619013365358, 0.0005020766402594745, 0.00045190236414782703, 0.0006676735356450081, 0.0007638593669980764, 0.0009467154741287231, 0.001009436440654099, 0.0037195703480392694, 0.007444886025041342, 0.00450055580586195, 0.001834433525800705, 0.012973621487617493, 0.015522468835115433, 0.021838270127773285, 0.01622895523905754, 0.024697456508874893, 0.0380532369017601, 0.16302332282066345, 0.11826053261756897, 0.22884775698184967, 0.3229479193687439, 0.0, 0.0], [0.009539726190268993, 0.0014243277255445719, 0.00099445809610188, 0.000965558341704309, 0.0007854430587030947, 0.00030160610913299024, 0.00011159564746776596, 0.0008093689102679491, 0.00040054635610431433, 8.517073729308322e-05, 0.000630756898317486, 0.00020861541270278394, 0.0002525561139918864, 0.0005451844772323966, 0.00024275557370856404, 0.0005828303983435035, 0.0005503923748619854, 0.001054856344126165, 0.0010979125509038568, 0.004033542238175869, 0.005151547957211733, 0.00725124916061759, 0.003988179378211498, 0.012260395102202892, 0.013561543077230453, 0.03828657045960426, 0.06675273180007935, 0.013111520558595657, 0.10093282908201218, 0.13179117441177368, 0.05432303622364998, 0.15251490473747253, 0.3083244860172272, 0.06713256984949112, 0.0], [0.009234576486051083, 0.0018696906045079231, 0.0015434968518093228, 0.0012878915295004845, 0.0009349415195174515, 0.00028256099903956056, 0.00044942696695216, 0.0005595001857727766, 0.0003277683863416314, 7.203824497992173e-05, 0.00010657920938683674, 0.00026362462085671723, 0.0003654732136055827, 0.0003748312301468104, 0.0003117537416983396, 0.0008969141053967178, 0.0006347454618662596, 0.0008650016388855875, 0.0008020036621019244, 0.0006307897856459022, 0.003218781901523471, 0.0038458341732621193, 0.0030004349537193775, 0.007814166136085987, 0.01010721456259489, 0.016721554100513458, 0.007672085892409086, 0.010031219571828842, 0.005356388166546822, 0.07757057994604111, 0.03774448111653328, 0.13809102773666382, 0.19567598402500153, 0.030743561685085297, 0.4305931031703949]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8970723748207092, 0.10292764008045197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7731762528419495, 0.17108596861362457, 0.05573779717087746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21909849345684052, 0.0959283784031868, 0.15399755537509918, 0.5309755802154541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49329182505607605, 0.12421070784330368, 0.08378960937261581, 0.2104450762271881, 0.08826279640197754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4792534112930298, 0.1148393303155899, 0.05825285241007805, 0.12140917778015137, 0.19296903908252716, 0.033276282250881195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33760711550712585, 0.1303829401731491, 0.12365781515836716, 0.1684831827878952, 0.0394856296479702, 0.1552271544933319, 0.045156147330999374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31243136525154114, 0.10335514694452286, 0.07322125136852264, 0.13077445328235626, 0.08650774508714676, 0.20371733605861664, 0.04714134708046913, 0.042851291596889496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1071995422244072, 0.032564762979745865, 0.04615401849150658, 0.12522782385349274, 0.011105234734714031, 0.03433002531528473, 0.007858379743993282, 0.011366566643118858, 0.6241937279701233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3028891086578369, 0.07804971933364868, 0.05937647446990013, 0.09426911175251007, 0.17377148568630219, 0.03861626237630844, 0.04802529886364937, 0.039512552320957184, 0.13237623870372772, 0.03311377763748169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13027667999267578, 0.04213492572307587, 0.07258214056491852, 0.1092287003993988, 0.03630439564585686, 0.19112560153007507, 0.03369800001382828, 0.05715862289071083, 0.11187217384576797, 0.16414125263690948, 0.05147745832800865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09464417397975922, 0.02925342693924904, 0.03811942785978317, 0.1498957872390747, 0.020670875906944275, 0.07631716877222061, 0.008947468362748623, 0.02004508674144745, 0.30578556656837463, 0.0475209504365921, 0.010440836660563946, 0.19835928082466125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1444079577922821, 0.06329525262117386, 0.07617762684822083, 0.07194560021162033, 0.03394109010696411, 0.08442068099975586, 0.03594024106860161, 0.07685539871454239, 0.1158827692270279, 0.05951954796910286, 0.061835020780563354, 0.14841710031032562, 0.027361813932657242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0414787232875824, 0.011494407430291176, 0.017643535509705544, 0.045997269451618195, 0.0040850103832781315, 0.013701111078262329, 0.0028709012549370527, 0.00451077613979578, 0.24164839088916779, 0.009729515761137009, 0.002616736339405179, 0.2641771137714386, 0.008053780533373356, 0.3319928050041199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15155856311321259, 0.037725016474723816, 0.02733066864311695, 0.06052478030323982, 0.030143296346068382, 0.028034880757331848, 0.013341412879526615, 0.02250303141772747, 0.11653435230255127, 0.05189972370862961, 0.01055865827947855, 0.10229875147342682, 0.015167291276156902, 0.14137379825115204, 0.19100579619407654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2839045226573944, 0.0650240108370781, 0.032383374869823456, 0.02959110401570797, 0.0424320288002491, 0.028469771146774292, 0.041533127427101135, 0.08465301245450974, 0.0438549667596817, 0.02753039449453354, 0.09218151867389679, 0.03751113638281822, 0.04891907051205635, 0.04984966292977333, 0.07913841307163239, 0.0130238002166152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04885758459568024, 0.014007368125021458, 0.019542623311281204, 0.07337553054094315, 0.010089147835969925, 0.039725709706544876, 0.00431005097925663, 0.010590329766273499, 0.1530359983444214, 0.026499038562178612, 0.0054172552190721035, 0.09647627919912338, 0.0128067247569561, 0.20478658378124237, 0.14743395149707794, 0.009689189493656158, 0.12335669249296188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05943119525909424, 0.025951169431209564, 0.035473912954330444, 0.039079755544662476, 0.018049322068691254, 0.023087238892912865, 0.010503753088414669, 0.030069539323449135, 0.09918276965618134, 0.03614409640431404, 0.01841004006564617, 0.11741487681865692, 0.017167577520012856, 0.12769994139671326, 0.08459021896123886, 0.03790270909667015, 0.14577233791351318, 0.07406949996948242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2724890112876892, 0.045022718608379364, 0.04612240567803383, 0.042051974684000015, 0.03813564032316208, 0.05454425886273384, 0.025706542655825615, 0.01925414800643921, 0.04536456987261772, 0.05106879770755768, 0.021479347720742226, 0.05142940580844879, 0.03568309172987938, 0.05110248178243637, 0.04221019893884659, 0.038132812827825546, 0.057898253202438354, 0.023540087044239044, 0.03876426815986633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2398124784231186, 0.03723882883787155, 0.04641323164105415, 0.018074776977300644, 0.028609465807676315, 0.031563613563776016, 0.023263663053512573, 0.05314118415117264, 0.0367298349738121, 0.04436158016324043, 0.014090005308389664, 0.04079654812812805, 0.013384051620960236, 0.04018275439739227, 0.02512497827410698, 0.022283194586634636, 0.04457437992095947, 0.0263572558760643, 0.018502116203308105, 0.1954961121082306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03447255492210388, 0.007049778942018747, 0.008516236208379269, 0.019823292270302773, 0.0020061940886080265, 0.008738482370972633, 0.001380531000904739, 0.0025849840603768826, 0.1296386569738388, 0.004980518948286772, 0.001454297685995698, 0.09793511778116226, 0.00424265768378973, 0.1747492551803589, 0.02057535946369171, 0.0029217286501079798, 0.12519218027591705, 0.017666740342974663, 0.008172447793185711, 0.0064639742486178875, 0.32143494486808777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07532121986150742, 0.017385119572281837, 0.02649960294365883, 0.03820114582777023, 0.013464294373989105, 0.017004910856485367, 0.005682714749127626, 0.008161388337612152, 0.08791027218103409, 0.015652010217308998, 0.0046223788522183895, 0.06870011985301971, 0.017068399116396904, 0.11098408699035645, 0.08843358606100082, 0.015540479682385921, 0.08290654420852661, 0.03445707634091377, 0.034902893006801605, 0.022669030353426933, 0.1672758311033249, 0.04715689271688461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11039689928293228, 0.017618604004383087, 0.012073233723640442, 0.07903026789426804, 0.04707182198762894, 0.028393451124429703, 0.010853300802409649, 0.03898292034864426, 0.04254176840186119, 0.05313577130436897, 0.010616586543619633, 0.04066743701696396, 0.016578692942857742, 0.05044252425432205, 0.04148310795426369, 0.011694187298417091, 0.04894394055008888, 0.04587525129318237, 0.06803464144468307, 0.03145821765065193, 0.07373650372028351, 0.09332357347011566, 0.02704726718366146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05010591074824333, 0.011403633281588554, 0.018980011343955994, 0.04829110950231552, 0.005478166975080967, 0.027938108891248703, 0.0034753403160721064, 0.009667658247053623, 0.08883960545063019, 0.02145979180932045, 0.009184256196022034, 0.06738956272602081, 0.006293781567364931, 0.11730515956878662, 0.05559389665722847, 0.023259565234184265, 0.08538829535245895, 0.030172361060976982, 0.018553778529167175, 0.04972720891237259, 0.138699471950531, 0.03593090921640396, 0.029570572078227997, 0.04729196056723595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03365061804652214, 0.03973431885242462, 0.013943268917500973, 0.02215501107275486, 0.007374102249741554, 0.012534331530332565, 0.003937930800020695, 0.0055880313739180565, 0.052764154970645905, 0.01135347317904234, 0.0029761556070297956, 0.06122001260519028, 0.007114534731954336, 0.06609286367893219, 0.01845719665288925, 0.004707180894911289, 0.07780604809522629, 0.015934068709611893, 0.016269709914922714, 0.027332952246069908, 0.08945078402757645, 0.028283191844820976, 0.01342833787202835, 0.24125008285045624, 0.12664161622524261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10162996500730515, 0.0481734536588192, 0.02274153009057045, 0.017647162079811096, 0.01635766215622425, 0.014718171209096909, 0.02023891732096672, 0.03009829856455326, 0.038364384323358536, 0.02529747039079666, 0.039593473076820374, 0.04179808869957924, 0.01849495805799961, 0.043456628918647766, 0.023876946419477463, 0.013411915861070156, 0.04804754629731178, 0.021995287388563156, 0.03074478916823864, 0.05168474093079567, 0.05786484479904175, 0.04216013476252556, 0.050390034914016724, 0.08024894446134567, 0.07608184963464737, 0.024882826954126358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06603521853685379, 0.020660124719142914, 0.02168169990181923, 0.03408763185143471, 0.015279398299753666, 0.01844198815524578, 0.010789580643177032, 0.05595836043357849, 0.03565485402941704, 0.02173885516822338, 0.025664953514933586, 0.03946555405855179, 0.01909186877310276, 0.04260497912764549, 0.04514036700129509, 0.012913588434457779, 0.047355785965919495, 0.025561857968568802, 0.03524414449930191, 0.0974637046456337, 0.05611313134431839, 0.035938456654548645, 0.032566994428634644, 0.04301987215876579, 0.046976763755083084, 0.0324612595140934, 0.062089040875434875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10541093349456787, 0.01697310246527195, 0.020341018214821815, 0.03266652673482895, 0.021851157769560814, 0.03178992122411728, 0.005571207031607628, 0.0241945069283247, 0.0167404655367136, 0.016082551330327988, 0.013484911993145943, 0.02279035933315754, 0.020844904705882072, 0.019816400483250618, 0.007412003353238106, 0.013035072013735771, 0.026982463896274567, 0.010132258757948875, 0.01766769215464592, 0.2972625494003296, 0.023457160219550133, 0.03235583007335663, 0.032245323061943054, 0.01998010091483593, 0.05017198249697685, 0.04827893152832985, 0.03308818116784096, 0.01937238685786724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11478212475776672, 0.02845187857747078, 0.03015810437500477, 0.029890719801187515, 0.015577699989080429, 0.04523628205060959, 0.00815667025744915, 0.04677765816450119, 0.02057458460330963, 0.018089186400175095, 0.016638455912470818, 0.02435150370001793, 0.014281022362411022, 0.022870570421218872, 0.024558458477258682, 0.021522246301174164, 0.027740145102143288, 0.012263163924217224, 0.01678968220949173, 0.030601773411035538, 0.033104460686445236, 0.04230615124106407, 0.050134167075157166, 0.039895687252283096, 0.025471467524766922, 0.03835654631257057, 0.14836569130420685, 0.040621932595968246, 0.012431957758963108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010402965359389782, 0.003988310694694519, 0.00753655843436718, 0.023714076727628708, 0.0015746989520266652, 0.0045564970932900906, 0.0011461435351520777, 0.0020206542685627937, 0.08388333022594452, 0.0060935490764677525, 0.0012243662495166063, 0.08011975884437561, 0.003282929537817836, 0.1148514598608017, 0.02013854682445526, 0.00387402530759573, 0.1035565659403801, 0.01623990572988987, 0.006219523027539253, 0.011158788576722145, 0.12897227704524994, 0.016916092485189438, 0.008813062682747841, 0.028795938938856125, 0.060593489557504654, 0.0056185950525105, 0.016893547028303146, 0.008791644126176834, 0.017022375017404556, 0.20200031995773315, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05472033470869064, 0.015954433009028435, 0.012098275125026703, 0.022833751514554024, 0.018985217437148094, 0.028783902525901794, 0.008076783269643784, 0.008372064679861069, 0.039564043283462524, 0.012315313331782818, 0.009588331915438175, 0.023571277037262917, 0.010643109679222107, 0.046638429164886475, 0.0145158926025033, 0.012394603341817856, 0.027597365900874138, 0.02169143222272396, 0.020180562511086464, 0.018239211291074753, 0.05496654659509659, 0.03711783513426781, 0.02424500696361065, 0.03499608114361763, 0.1494767814874649, 0.02901950664818287, 0.043276481330394745, 0.015866439789533615, 0.0451154001057148, 0.11428382992744446, 0.02487177588045597, 0.0, 0.0, 0.0, 0.0], [0.028266336768865585, 0.008342590183019638, 0.009693165309727192, 0.024003315716981888, 0.01240698155015707, 0.009731604717671871, 0.0072547742165625095, 0.011378857307136059, 0.04525343328714371, 0.014661085791885853, 0.004759799689054489, 0.032793063670396805, 0.009599774144589901, 0.05662675201892853, 0.023795723915100098, 0.004614101257175207, 0.039821475744247437, 0.021238990128040314, 0.025286555290222168, 0.10159800946712494, 0.09278310090303421, 0.026123860850930214, 0.015091420151293278, 0.03458565101027489, 0.06182192638516426, 0.013406998477876186, 0.016889771446585655, 0.030893532559275627, 0.028194863349199295, 0.1103137880563736, 0.04056955873966217, 0.03819922357797623, 0.0, 0.0, 0.0], [0.005920095834881067, 0.002644824329763651, 0.005754891317337751, 0.021997179836034775, 0.0013081278884783387, 0.005726536735892296, 0.0008704044157639146, 0.0018940422451123595, 0.052954982966184616, 0.00472501153126359, 0.0009999445173889399, 0.04342709854245186, 0.002174984198063612, 0.0736372247338295, 0.01701577752828598, 0.003086993470788002, 0.057790882885456085, 0.010734478943049908, 0.0034258230589330196, 0.01033270638436079, 0.08509064465761185, 0.012429158203303814, 0.0062302350997924805, 0.022221006453037262, 0.06411111354827881, 0.0050534834153950214, 0.018152374774217606, 0.007594150025397539, 0.0067864395678043365, 0.16716453433036804, 0.013871795497834682, 0.014755620621144772, 0.2501174509525299, 0.0, 0.0], [0.059587135910987854, 0.014287109486758709, 0.00968867726624012, 0.028474608436226845, 0.028604796156287193, 0.026259329169988632, 0.0088196424767375, 0.022136058658361435, 0.01791020855307579, 0.026397546753287315, 0.01724359393119812, 0.02598380856215954, 0.006316181272268295, 0.020043157041072845, 0.015440626069903374, 0.02594027668237686, 0.0301030445843935, 0.01836533658206463, 0.023130422458052635, 0.02621460147202015, 0.031157266348600388, 0.028986169025301933, 0.028961259871721268, 0.016435226425528526, 0.03480091691017151, 0.03794368356466293, 0.0738067477941513, 0.03077242523431778, 0.028517240658402443, 0.07387102395296097, 0.02458771876990795, 0.035234082490205765, 0.08090808987617493, 0.023072006180882454, 0.0], [0.052589885890483856, 0.0082823745906353, 0.0046865916810929775, 0.011556110344827175, 0.00212435913272202, 0.007376655004918575, 0.0025699108373373747, 0.005167303141206503, 0.06430476158857346, 0.008688678964972496, 0.004349819850176573, 0.054052047431468964, 0.003567329840734601, 0.08101722598075867, 0.021457038819789886, 0.004144071601331234, 0.0662156268954277, 0.01871691830456257, 0.009488231502473354, 0.0060385484248399734, 0.10274301469326019, 0.014565224759280682, 0.009106291458010674, 0.021657677367329597, 0.03524801880121231, 0.004852634854614735, 0.008422155864536762, 0.019589491188526154, 0.011885890737175941, 0.14464665949344635, 0.016607560217380524, 0.02283478155732155, 0.08476626873016357, 0.015126866288483143, 0.05155404657125473]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8803902864456177, 0.11960969120264053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8001627922058105, 0.1442255973815918, 0.05561167001724243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6471942067146301, 0.1470176875591278, 0.07931006699800491, 0.1264779418706894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6291002035140991, 0.13269931077957153, 0.0830739215016365, 0.10306606441736221, 0.052060455083847046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5631014108657837, 0.12375932186841965, 0.11159726977348328, 0.10842740535736084, 0.08343346416950226, 0.009681181982159615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49733906984329224, 0.11400073021650314, 0.07851863652467728, 0.10408833622932434, 0.08229987323284149, 0.08720175176858902, 0.03655163571238518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.46186619997024536, 0.10720600932836533, 0.07680266350507736, 0.09525886178016663, 0.11179571598768234, 0.04683655872941017, 0.0632898136973381, 0.03694411367177963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.408801794052124, 0.11223537474870682, 0.06194954738020897, 0.08138207346200943, 0.06888709217309952, 0.04759938269853592, 0.05779566988348961, 0.06300586462020874, 0.09834322333335876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33778560161590576, 0.07768949121236801, 0.06164025515317917, 0.08030420541763306, 0.09243479371070862, 0.12569791078567505, 0.043102771043777466, 0.08006508648395538, 0.08753130584955215, 0.013748622499406338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4084458351135254, 0.07972611486911774, 0.05943279713392258, 0.07098966836929321, 0.06258385628461838, 0.0729871317744255, 0.05290912836790085, 0.06663116067647934, 0.08486582338809967, 0.030785243958234787, 0.01064338069409132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3284088671207428, 0.08126053214073181, 0.05222120136022568, 0.0667019784450531, 0.06221221014857292, 0.04688326269388199, 0.047482267022132874, 0.04943711683154106, 0.0864436998963356, 0.05108509585261345, 0.04660412669181824, 0.08125964552164078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28456372022628784, 0.0733422115445137, 0.059566278010606766, 0.05995685234665871, 0.0626126304268837, 0.04492250457406044, 0.053548913449048996, 0.055395208299160004, 0.0760505199432373, 0.0543915219604969, 0.05521012842655182, 0.08481413871049881, 0.03562536835670471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2986925542354584, 0.08053489029407501, 0.04630003869533539, 0.05841612070798874, 0.05245252326130867, 0.03589674457907677, 0.043130062520504, 0.04816412553191185, 0.07179585844278336, 0.03588228300213814, 0.03498636558651924, 0.06638612598180771, 0.04749887436628342, 0.0798635482788086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26184865832328796, 0.06895221769809723, 0.04662094637751579, 0.05860459432005882, 0.04692878574132919, 0.05568011850118637, 0.04915207624435425, 0.04117779806256294, 0.074907585978508, 0.03198425844311714, 0.03257225826382637, 0.07257071882486343, 0.03739878535270691, 0.08542973548173904, 0.036171406507492065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2941746413707733, 0.05360913649201393, 0.038608793169260025, 0.04952675849199295, 0.04060918465256691, 0.0414932444691658, 0.029716243967413902, 0.04536984860897064, 0.06024932861328125, 0.04159966856241226, 0.06637393683195114, 0.05982467904686928, 0.04050290957093239, 0.06734268367290497, 0.060957394540309906, 0.010041479952633381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24078045785427094, 0.057315003126859665, 0.03812981769442558, 0.047623757272958755, 0.04672614857554436, 0.03515474870800972, 0.034621816128492355, 0.0374724380671978, 0.062347810715436935, 0.0395454578101635, 0.035744328051805496, 0.05874497443437576, 0.03407842293381691, 0.07071566581726074, 0.054391175508499146, 0.039451491087675095, 0.06715650856494904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19008122384548187, 0.055469125509262085, 0.03824989125132561, 0.04468472674489021, 0.0434919036924839, 0.03729136288166046, 0.035000309348106384, 0.03413337841629982, 0.05614841356873512, 0.029018184170126915, 0.026478607207536697, 0.06265047192573547, 0.03502201288938522, 0.06568854302167892, 0.0571419820189476, 0.04781633988022804, 0.07356446981430054, 0.06806915998458862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23406480252742767, 0.04765676334500313, 0.03626639395952225, 0.043501537293195724, 0.044823311269283295, 0.030926158651709557, 0.024145537987351418, 0.03047104738652706, 0.051002658903598785, 0.03852143883705139, 0.04128360003232956, 0.05289097875356674, 0.027892805635929108, 0.057388786226511, 0.06067002937197685, 0.04387103021144867, 0.059330206364393234, 0.05117018148303032, 0.024122724309563637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3121168911457062, 0.04305696487426758, 0.030739204958081245, 0.0399012416601181, 0.04073915258049965, 0.033973559737205505, 0.013991210609674454, 0.0325016975402832, 0.04214293509721756, 0.03136739134788513, 0.05722324550151825, 0.0420997329056263, 0.032853297889232635, 0.04662720113992691, 0.048747774213552475, 0.02173059806227684, 0.047223784029483795, 0.029857579618692398, 0.04530390352010727, 0.007802661508321762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1958305388689041, 0.05227471888065338, 0.03251207619905472, 0.03705889731645584, 0.04335429146885872, 0.02764130011200905, 0.02745206654071808, 0.033081553876399994, 0.04532438889145851, 0.02540675923228264, 0.02478163130581379, 0.03888050094246864, 0.03024730272591114, 0.050895120948553085, 0.04128778353333473, 0.03749212250113487, 0.04425322636961937, 0.04428720474243164, 0.04519396275281906, 0.05072396248579025, 0.07202054560184479, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16079998016357422, 0.048410702496767044, 0.0330209955573082, 0.0344170480966568, 0.03531977906823158, 0.023897025734186172, 0.026063477620482445, 0.02863973192870617, 0.04453875869512558, 0.02494947984814644, 0.02971617318689823, 0.04013000801205635, 0.02485905960202217, 0.05134394019842148, 0.0537353977560997, 0.04527629166841507, 0.04680595546960831, 0.0346059687435627, 0.04245501384139061, 0.05485451593995094, 0.06976334005594254, 0.046397317200899124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18932504951953888, 0.03910360485315323, 0.024852028116583824, 0.03345050662755966, 0.0386015847325325, 0.024109292775392532, 0.020502105355262756, 0.024301744997501373, 0.03976471722126007, 0.03418167307972908, 0.03484787046909332, 0.036197811365127563, 0.023668942973017693, 0.0450248122215271, 0.03498944267630577, 0.026825517416000366, 0.04153793305158615, 0.037366610020399094, 0.042022790759801865, 0.05591040849685669, 0.06404420733451843, 0.056186333298683167, 0.03318498656153679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16596607863903046, 0.03388110175728798, 0.02065752074122429, 0.03212727978825569, 0.03747253492474556, 0.026519475504755974, 0.01988290250301361, 0.025609642267227173, 0.04091744124889374, 0.02261033095419407, 0.019720884039998055, 0.03376534581184387, 0.023503810167312622, 0.046445246785879135, 0.035414308309555054, 0.02736842632293701, 0.03876943141222, 0.031460732221603394, 0.04639927297830582, 0.04867471009492874, 0.06382153183221817, 0.06529751420021057, 0.046299051493406296, 0.047415394335985184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15514099597930908, 0.036314792931079865, 0.022236905992031097, 0.028097422793507576, 0.04015664383769035, 0.024055976420640945, 0.01740090921521187, 0.021498557180166245, 0.03675065562129021, 0.017986752092838287, 0.019703922793269157, 0.02832779660820961, 0.02260461077094078, 0.04168051481246948, 0.030497953295707703, 0.025585582479834557, 0.03248761221766472, 0.027014948427677155, 0.04112284258008003, 0.04738448187708855, 0.0638233870267868, 0.056550100445747375, 0.041199978440999985, 0.06263260543346405, 0.059744078665971756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12975940108299255, 0.027339685708284378, 0.02995753102004528, 0.02270284853875637, 0.037815336138010025, 0.031446345150470734, 0.017136769369244576, 0.04656492918729782, 0.03061830997467041, 0.018781673163175583, 0.025273209437727928, 0.028721973299980164, 0.019090931862592697, 0.03481000289320946, 0.02617022767663002, 0.02681772969663143, 0.03296039626002312, 0.024960240349173546, 0.05474759638309479, 0.0578010119497776, 0.056176237761974335, 0.03305983543395996, 0.05767423287034035, 0.046674203127622604, 0.06228698045015335, 0.02065236121416092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18126995861530304, 0.027924932539463043, 0.028055919334292412, 0.029457418248057365, 0.028532754629850388, 0.020307764410972595, 0.019550152122974396, 0.03153108060359955, 0.029232840985059738, 0.021110545843839645, 0.014580844901502132, 0.022505322471261024, 0.016256749629974365, 0.031508851796388626, 0.024519700556993484, 0.03659053519368172, 0.025034507736563683, 0.020030660554766655, 0.04726614058017731, 0.12142346054315567, 0.0418962687253952, 0.03646092116832733, 0.03734692931175232, 0.03705747798085213, 0.035210929811000824, 0.024784492328763008, 0.010552847757935524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1419323980808258, 0.026873400434851646, 0.023394420742988586, 0.024198895320296288, 0.03441091999411583, 0.031768206506967545, 0.014282823540270329, 0.027884989976882935, 0.027823274955153465, 0.02026795595884323, 0.020075349137187004, 0.026035411283373833, 0.015271048992872238, 0.031183555722236633, 0.02134445309638977, 0.030780872330069542, 0.029686488211154938, 0.024966169148683548, 0.03290623426437378, 0.0812656506896019, 0.04738020896911621, 0.0395050123333931, 0.03810605779290199, 0.03920024633407593, 0.047230418771505356, 0.032237764447927475, 0.04768495261669159, 0.02230280078947544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1936107724905014, 0.028910452499985695, 0.01741074211895466, 0.024991966784000397, 0.02041228860616684, 0.03692351281642914, 0.018564047291874886, 0.02249111421406269, 0.026469897478818893, 0.01985173299908638, 0.016706908121705055, 0.020129598677158356, 0.01730293408036232, 0.02887752279639244, 0.019370291382074356, 0.02151290699839592, 0.02260466292500496, 0.019465506076812744, 0.03218546509742737, 0.09415601193904877, 0.03964084014296532, 0.046928733587265015, 0.03296547383069992, 0.034327469766139984, 0.035498879849910736, 0.04152423143386841, 0.03800845891237259, 0.024193771183490753, 0.00496391486376524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13062261044979095, 0.029238125309348106, 0.020562490448355675, 0.024924928322434425, 0.026433376595377922, 0.020880043506622314, 0.01689508929848671, 0.020366210490465164, 0.030794672667980194, 0.016811517998576164, 0.014352652244269848, 0.026399681344628334, 0.01796814426779747, 0.03419142961502075, 0.025793632492423058, 0.02088005840778351, 0.029983339831233025, 0.0225768331438303, 0.031984005123376846, 0.0387752465903759, 0.04729927331209183, 0.039518099278211594, 0.035695526748895645, 0.04647781699895859, 0.045603714883327484, 0.027694009244441986, 0.0283762626349926, 0.029506973922252655, 0.033888138830661774, 0.06550601869821548, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10399015247821808, 0.02196613699197769, 0.016451170668005943, 0.022787991911172867, 0.02435714565217495, 0.01997542381286621, 0.013678604736924171, 0.020524611696600914, 0.02641664445400238, 0.01582498662173748, 0.018124759197235107, 0.022938068956136703, 0.015249828808009624, 0.02995176613330841, 0.019568651914596558, 0.017790067940950394, 0.026331381872296333, 0.020062360912561417, 0.03040565736591816, 0.05837803706526756, 0.04746948182582855, 0.03560006991028786, 0.033618565648794174, 0.039051614701747894, 0.046234603971242905, 0.03415835276246071, 0.05063628777861595, 0.03304954245686531, 0.04132761061191559, 0.06007474660873413, 0.034005604684352875, 0.0, 0.0, 0.0, 0.0], [0.10689456015825272, 0.023425208404660225, 0.01831112429499626, 0.02227621152997017, 0.019986260682344437, 0.018345672637224197, 0.01589350774884224, 0.0198027566075325, 0.025829363614320755, 0.0160794910043478, 0.016656849533319473, 0.02581821382045746, 0.012892837636172771, 0.029111457988619804, 0.020739195868372917, 0.017621513456106186, 0.029654454439878464, 0.024281147867441177, 0.028045887127518654, 0.05205394700169563, 0.04263105243444443, 0.03251812234520912, 0.037380319088697433, 0.038434360176324844, 0.03982122242450714, 0.02629011683166027, 0.0352063849568367, 0.031386297196149826, 0.03282343968749046, 0.061947036534547806, 0.03762543946504593, 0.04021657630801201, 0.0, 0.0, 0.0], [0.1222902461886406, 0.02516898512840271, 0.01671406999230385, 0.022033262997865677, 0.023000743240118027, 0.015408718958497047, 0.014958010986447334, 0.018676770851016045, 0.026191165670752525, 0.012370303273200989, 0.01071577612310648, 0.021631909534335136, 0.013984632678329945, 0.02889922820031643, 0.023200996220111847, 0.01821659691631794, 0.02428124099969864, 0.018235312774777412, 0.021653978154063225, 0.03633743152022362, 0.03855650871992111, 0.03691945970058441, 0.033792268484830856, 0.042588260024785995, 0.03839157149195671, 0.02329576015472412, 0.030805250629782677, 0.024493306875228882, 0.03010578453540802, 0.05652609467506409, 0.03756684437394142, 0.04159916564822197, 0.051390375941991806, 0.0, 0.0], [0.13871711492538452, 0.02196723036468029, 0.01668298803269863, 0.021551381796598434, 0.026049228385090828, 0.015379131771624088, 0.012522310018539429, 0.02002521976828575, 0.021879851818084717, 0.014553075656294823, 0.015628254041075706, 0.018288591876626015, 0.0124217439442873, 0.023633427917957306, 0.017220688983798027, 0.020091669633984566, 0.02015187218785286, 0.018530184403061867, 0.02421250194311142, 0.07234078645706177, 0.03423938527703285, 0.030147042125463486, 0.031458817422389984, 0.030202969908714294, 0.030948735773563385, 0.024833209812641144, 0.030743272975087166, 0.022636571899056435, 0.04456690326333046, 0.04173138737678528, 0.028924651443958282, 0.029865309596061707, 0.04288145527243614, 0.024973047897219658, 0.0], [0.12327976524829865, 0.026707442477345467, 0.01483471505343914, 0.018021516501903534, 0.017764994874596596, 0.013351651839911938, 0.014073795638978481, 0.01872303895652294, 0.023980092257261276, 0.021256309002637863, 0.017004823312163353, 0.020616674795746803, 0.012905529700219631, 0.02609744854271412, 0.02155427262187004, 0.015845773741602898, 0.02278093993663788, 0.023595383390784264, 0.019861752167344093, 0.021922387182712555, 0.03597114235162735, 0.03369682654738426, 0.02117166854441166, 0.035360533744096756, 0.03450926020741463, 0.021897651255130768, 0.03512424975633621, 0.02411290444433689, 0.03299051895737648, 0.046776361763477325, 0.030424457043409348, 0.03270316496491432, 0.03790726885199547, 0.042624954134225845, 0.040550798177719116]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6533872485160828, 0.3466127812862396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4451116919517517, 0.3337683379650116, 0.2211199402809143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5459807515144348, 0.15291084349155426, 0.07645456492900848, 0.22465379536151886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.42720288038253784, 0.1412525624036789, 0.06143972650170326, 0.11979992687702179, 0.2503049373626709, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4097929298877716, 0.11732906848192215, 0.06548823416233063, 0.12367463111877441, 0.04222371056675911, 0.24149145185947418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.36435145139694214, 0.15547122061252594, 0.08527877181768417, 0.08832608163356781, 0.04993733763694763, 0.03409624099731445, 0.22253885865211487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.35626861453056335, 0.09063341468572617, 0.05006815120577812, 0.10755757242441177, 0.06895481050014496, 0.04669608548283577, 0.04097529500722885, 0.2388460487127304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3461388945579529, 0.14562258124351501, 0.09470635652542114, 0.1049964502453804, 0.06400175392627716, 0.04047239571809769, 0.03757920861244202, 0.044482164084911346, 0.12200023978948593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20510224997997284, 0.04824315756559372, 0.05157081410288811, 0.09953966736793518, 0.06673121452331543, 0.04558688774704933, 0.03648391366004944, 0.08169859647750854, 0.08583586663007736, 0.27920761704444885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23016957938671112, 0.07576318085193634, 0.062430281192064285, 0.061968352645635605, 0.05024825036525726, 0.037962619215250015, 0.057705141603946686, 0.05617324262857437, 0.06585753709077835, 0.041665591299533844, 0.26005616784095764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2668822705745697, 0.09969270974397659, 0.06880498677492142, 0.10110108554363251, 0.036257702857255936, 0.04876029118895531, 0.0317954383790493, 0.03426745906472206, 0.09192278981208801, 0.044060155749320984, 0.024279996752738953, 0.152175173163414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24808602035045624, 0.05943755805492401, 0.03645307943224907, 0.09643884003162384, 0.04665256291627884, 0.043580614030361176, 0.026409663259983063, 0.038718484342098236, 0.06937100738286972, 0.035532157868146896, 0.02358422242105007, 0.05824919790029526, 0.21748659014701843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22227588295936584, 0.08784299343824387, 0.06428328156471252, 0.07245951145887375, 0.05153009295463562, 0.03354167565703392, 0.03151150792837143, 0.043959807604551315, 0.10531804710626602, 0.03629286214709282, 0.03349636122584343, 0.07923727482557297, 0.03496609628200531, 0.10328467935323715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26255419850349426, 0.07451014220714569, 0.04962189495563507, 0.0651395171880722, 0.02218240685760975, 0.03923412412405014, 0.02143390290439129, 0.02829248458147049, 0.06496230512857437, 0.022169629111886024, 0.018070973455905914, 0.05796553194522858, 0.018188010901212692, 0.06176503747701645, 0.19390982389450073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21454617381095886, 0.05207953229546547, 0.04338602349162102, 0.05108674243092537, 0.023057056590914726, 0.03987297788262367, 0.021457543596625328, 0.043103158473968506, 0.057124003767967224, 0.047324102371931076, 0.02007635310292244, 0.04863850027322769, 0.03173767402768135, 0.05389070510864258, 0.03922811895608902, 0.21339136362075806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.169346421957016, 0.0575847402215004, 0.04318231716752052, 0.06501621007919312, 0.025769712403416634, 0.035840604454278946, 0.023403938859701157, 0.028633087873458862, 0.06884393095970154, 0.03735613077878952, 0.021079331636428833, 0.12265525758266449, 0.02518490143120289, 0.07096559554338455, 0.049235545098781586, 0.028457917273044586, 0.12744443118572235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1294490247964859, 0.043515175580978394, 0.02870734967291355, 0.045572541654109955, 0.021282192319631577, 0.019885342568159103, 0.028857694938778877, 0.034781113266944885, 0.055325932800769806, 0.030885059386491776, 0.02108755148947239, 0.06504065543413162, 0.04043160006403923, 0.057976022362709045, 0.041369806975126266, 0.02854405716061592, 0.06784921884536743, 0.23943962156772614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14163608849048615, 0.03578965365886688, 0.028365228325128555, 0.04538756608963013, 0.04637839272618294, 0.03978871926665306, 0.014343786984682083, 0.049597978591918945, 0.04732619971036911, 0.030782440677285194, 0.018412159755825996, 0.04871036857366562, 0.02340163290500641, 0.047455623745918274, 0.03751208633184433, 0.023782698437571526, 0.04894063621759415, 0.033790670335292816, 0.23859809339046478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1335032433271408, 0.03222054988145828, 0.02058890275657177, 0.03780217468738556, 0.04108010604977608, 0.03671093285083771, 0.02595440484583378, 0.04136637970805168, 0.043265700340270996, 0.030096469447016716, 0.026812905445694923, 0.04010694473981857, 0.024385906755924225, 0.04430920630693436, 0.0337374247610569, 0.02071092277765274, 0.04079744592308998, 0.032650161534547806, 0.03506242111325264, 0.2588377892971039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11974352598190308, 0.03914882242679596, 0.028956562280654907, 0.03342708572745323, 0.037695933133363724, 0.0205439031124115, 0.01755896955728531, 0.032658424228429794, 0.06372418999671936, 0.03310192748904228, 0.02986794151365757, 0.053869184106588364, 0.022512977942824364, 0.07236675173044205, 0.041434261947870255, 0.03790142759680748, 0.06002624332904816, 0.04586021229624748, 0.05091096833348274, 0.031955886632204056, 0.1267348974943161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11878620088100433, 0.03957203030586243, 0.02322298102080822, 0.053640808910131454, 0.03261677548289299, 0.01737094298005104, 0.011663909070193768, 0.016273824498057365, 0.05014302581548691, 0.013260260224342346, 0.0104869045317173, 0.03813209384679794, 0.04193669185042381, 0.05336223170161247, 0.030979983508586884, 0.019617725163698196, 0.040241554379463196, 0.03244159370660782, 0.020540127530694008, 0.026845507323741913, 0.05771108716726303, 0.2511536478996277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10596504807472229, 0.03639821708202362, 0.02373066358268261, 0.02770346589386463, 0.029520327225327492, 0.016958514228463173, 0.009277226403355598, 0.019281184300780296, 0.043534498661756516, 0.02543571963906288, 0.01544105727225542, 0.0416172631084919, 0.018472323194146156, 0.04617342725396156, 0.026975227519869804, 0.016877293586730957, 0.0436592735350132, 0.020190222188830376, 0.01864578202366829, 0.01635969616472721, 0.05703481659293175, 0.06433956325054169, 0.27640920877456665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08669393509626389, 0.1400514841079712, 0.05404340475797653, 0.026910439133644104, 0.02693350799381733, 0.01693662256002426, 0.017527246847748756, 0.011132634244859219, 0.033167172223329544, 0.009116585366427898, 0.014021700248122215, 0.02812526933848858, 0.012107604183256626, 0.03627436235547066, 0.03099164552986622, 0.015099077485501766, 0.03022146411240101, 0.020815474912524223, 0.018955033272504807, 0.021182596683502197, 0.04364987835288048, 0.04377347603440285, 0.025040630251169205, 0.23722875118255615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10505463182926178, 0.024722838774323463, 0.02343858778476715, 0.02425646223127842, 0.021477699279785156, 0.014111106283962727, 0.012018012814223766, 0.015707308426499367, 0.042195845395326614, 0.016803370788693428, 0.011159364134073257, 0.03127181529998779, 0.020320698618888855, 0.04702334851026535, 0.039886802434921265, 0.02585337497293949, 0.034509602934122086, 0.02452259697020054, 0.017594218254089355, 0.021597163751721382, 0.06303168833255768, 0.05036986619234085, 0.02654913067817688, 0.040915295481681824, 0.24560922384262085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07146886736154556, 0.015683092176914215, 0.019199566915631294, 0.02765510231256485, 0.025888733565807343, 0.011495732702314854, 0.013834545388817787, 0.0250062458217144, 0.032857514917850494, 0.04069042578339577, 0.019407067447900772, 0.036282770335674286, 0.02667134441435337, 0.03698843717575073, 0.0253913477063179, 0.012203282676637173, 0.04081625118851662, 0.022441420704126358, 0.018680062144994736, 0.03714069724082947, 0.05291350930929184, 0.03374897688627243, 0.03600706160068512, 0.027396058663725853, 0.04157791659235954, 0.24855394661426544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09520066529512405, 0.02339908853173256, 0.01624995656311512, 0.03728703409433365, 0.027069473639130592, 0.02442619949579239, 0.016916710883378983, 0.02051924541592598, 0.03561447188258171, 0.01724678836762905, 0.01696517877280712, 0.03067062981426716, 0.014761793427169323, 0.03783896565437317, 0.025590213015675545, 0.013281542807817459, 0.03275728225708008, 0.01698147878050804, 0.012912829406559467, 0.04096675664186478, 0.04452374204993248, 0.032888539135456085, 0.021862000226974487, 0.028905071318149567, 0.025222204625606537, 0.015681948512792587, 0.2742602825164795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07106206566095352, 0.022234488278627396, 0.015442520380020142, 0.02880682982504368, 0.02491171285510063, 0.01409667544066906, 0.010925302281975746, 0.022356446832418442, 0.02825102210044861, 0.025925250723958015, 0.012314545921981335, 0.03621361032128334, 0.017662763595581055, 0.03140704706311226, 0.018595034256577492, 0.0181714054197073, 0.040066659450531006, 0.02272828295826912, 0.025000527501106262, 0.04014963284134865, 0.04249803349375725, 0.02628159709274769, 0.02363489754498005, 0.03034823015332222, 0.028446590527892113, 0.04931708052754402, 0.045332688838243484, 0.22781896591186523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1199868768453598, 0.03201312944293022, 0.020363762974739075, 0.03192231431603432, 0.020111484453082085, 0.017741892486810684, 0.014963152818381786, 0.014099689200520515, 0.0323602668941021, 0.012826556339859962, 0.01920422539114952, 0.024741895496845245, 0.014775943011045456, 0.03365084156394005, 0.03285076841711998, 0.01563302055001259, 0.02633098140358925, 0.009946919046342373, 0.010015268810093403, 0.023254677653312683, 0.03898428753018379, 0.034919414669275284, 0.011989147402346134, 0.03053087368607521, 0.02381373755633831, 0.018979014828801155, 0.06846079975366592, 0.019141538068652153, 0.22638750076293945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07111397385597229, 0.023045005276799202, 0.017407836392521858, 0.025577737018465996, 0.018817279487848282, 0.01440666988492012, 0.011364503763616085, 0.019742922857403755, 0.037803784012794495, 0.017498362809419632, 0.0122145377099514, 0.034711796790361404, 0.01624511182308197, 0.04494825378060341, 0.031461045145988464, 0.017976269125938416, 0.04077500104904175, 0.02623201161623001, 0.02910454012453556, 0.032863155007362366, 0.06312327086925507, 0.039967380464076996, 0.03193744271993637, 0.05005760118365288, 0.050039857625961304, 0.02629847079515457, 0.040675751864910126, 0.03425349295139313, 0.03361441567540169, 0.0867224931716919, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06342679262161255, 0.018928566947579384, 0.015915194526314735, 0.02297447994351387, 0.01581357792019844, 0.011996154673397541, 0.006959729827940464, 0.010440587997436523, 0.027604447677731514, 0.014203780330717564, 0.011755011044442654, 0.02697419933974743, 0.015696225687861443, 0.03244095295667648, 0.021464010700583458, 0.016300220042467117, 0.0315910242497921, 0.018295636400580406, 0.02407490275800228, 0.018299637362360954, 0.04905860871076584, 0.03294462338089943, 0.031695034354925156, 0.04070066288113594, 0.05526788532733917, 0.03228399530053139, 0.01833721622824669, 0.020621933043003082, 0.020615674555301666, 0.061421554535627365, 0.21189774572849274, 0.0, 0.0, 0.0, 0.0], [0.05903123319149017, 0.01165033970028162, 0.01190632302314043, 0.02030511572957039, 0.01582455448806286, 0.011342634446918964, 0.012165093794465065, 0.02051454968750477, 0.02463514916598797, 0.01787753961980343, 0.008976958692073822, 0.027097539976239204, 0.010151369497179985, 0.029500102624297142, 0.022961728274822235, 0.01152712944895029, 0.032491885125637054, 0.020219076424837112, 0.02027125470340252, 0.0276049617677927, 0.042306944727897644, 0.022920362651348114, 0.02739839442074299, 0.024839358404278755, 0.028419984504580498, 0.04172161594033241, 0.0314212292432785, 0.035203300416469574, 0.03063124045729637, 0.06006475165486336, 0.04537738487124443, 0.19364091753959656, 0.0, 0.0, 0.0], [0.08590575307607651, 0.014704098924994469, 0.01051056943833828, 0.028699854388833046, 0.016654491424560547, 0.012795393355190754, 0.009235279634594917, 0.014819215051829815, 0.028232725337147713, 0.011867673136293888, 0.009268179535865784, 0.02304435521364212, 0.017553264275193214, 0.03295403718948364, 0.025013741105794907, 0.012247494421899319, 0.02679956704378128, 0.013326534070074558, 0.016479840502142906, 0.03472822159528732, 0.0398079976439476, 0.05067337676882744, 0.03086116537451744, 0.027551837265491486, 0.036164239048957825, 0.01740610972046852, 0.04716058447957039, 0.025891847908496857, 0.028397276997566223, 0.06047138199210167, 0.03584858402609825, 0.03886667266488075, 0.11605862528085709, 0.0, 0.0], [0.056707728654146194, 0.015243271365761757, 0.009892581030726433, 0.017495427280664444, 0.035292427986860275, 0.015370236709713936, 0.010747743770480156, 0.017091592773795128, 0.021245012059807777, 0.013064504601061344, 0.006394114810973406, 0.02176818437874317, 0.011015367694199085, 0.023290835320949554, 0.0209710244089365, 0.012346651405096054, 0.02411966770887375, 0.013815036043524742, 0.016820499673485756, 0.034515149891376495, 0.030974799767136574, 0.03217756003141403, 0.03227026015520096, 0.02327035926282406, 0.027259428054094315, 0.01785033568739891, 0.05776430293917656, 0.024271581321954727, 0.02524302341043949, 0.03774581849575043, 0.015895815566182137, 0.02659659832715988, 0.04215160012245178, 0.20932142436504364, 0.0], [0.047369711101055145, 0.013491545803844929, 0.008601201698184013, 0.011534379795193672, 0.03260952979326248, 0.008750012144446373, 0.01049541961401701, 0.015973461791872978, 0.024224920198321342, 0.013959748670458794, 0.011584172025322914, 0.02090699039399624, 0.01231019850820303, 0.028499366715550423, 0.014403226785361767, 0.011428194120526314, 0.024424536153674126, 0.02128405123949051, 0.0275762677192688, 0.025762220844626427, 0.0491495318710804, 0.021549450233578682, 0.020725879818201065, 0.030232438817620277, 0.046837322413921356, 0.02172248438000679, 0.020257199183106422, 0.01914953999221325, 0.010533900000154972, 0.050025906413793564, 0.030405575409531593, 0.022812236100435257, 0.029462473466992378, 0.039963193237781525, 0.20198363065719604]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8253123164176941, 0.1746876984834671, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7580503821372986, 0.1302967369556427, 0.11165298521518707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7232239842414856, 0.08274427056312561, 0.07870832085609436, 0.11532341688871384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.559454083442688, 0.08694437891244888, 0.0911555141210556, 0.09393446892499924, 0.1685115247964859, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5031396150588989, 0.08192654699087143, 0.05872316658496857, 0.10480906069278717, 0.15214209258556366, 0.09925957024097443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.527961015701294, 0.058259785175323486, 0.06836593896150589, 0.11652137339115143, 0.11039452999830246, 0.06918036937713623, 0.04931706190109253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30010074377059937, 0.08825996518135071, 0.05834933742880821, 0.109842449426651, 0.1686263084411621, 0.1289689838886261, 0.02322760969400406, 0.12262459099292755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3934403955936432, 0.04758618026971817, 0.05194966122508049, 0.07471581548452377, 0.11950992792844772, 0.059380389750003815, 0.023368598893284798, 0.102664053440094, 0.1273849904537201, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3446025252342224, 0.05032898858189583, 0.05991332232952118, 0.044831324368715286, 0.1573815643787384, 0.06782463192939758, 0.032290101051330566, 0.07052529603242874, 0.0895390585064888, 0.08276327699422836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3350846767425537, 0.0462699718773365, 0.047857675701379776, 0.10917433351278305, 0.04435236006975174, 0.04490724951028824, 0.02844385989010334, 0.07920622080564499, 0.10731325298547745, 0.06832481175661087, 0.08906549960374832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31157219409942627, 0.03927760571241379, 0.03521275147795677, 0.07551001012325287, 0.08078573644161224, 0.04503689706325531, 0.028806490823626518, 0.10218672454357147, 0.08797681331634521, 0.05585261434316635, 0.0857192724943161, 0.052063003182411194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3614695072174072, 0.06311221420764923, 0.026989934965968132, 0.07095800340175629, 0.039851732552051544, 0.029446519911289215, 0.022796373814344406, 0.07072699815034866, 0.1130439043045044, 0.033355165272951126, 0.03714419901371002, 0.04763943701982498, 0.08346598595380783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26885920763015747, 0.03265075013041496, 0.039381880313158035, 0.05081149563193321, 0.08684229850769043, 0.04310198128223419, 0.017922354862093925, 0.06655362248420715, 0.07785408198833466, 0.04528899863362312, 0.06586873531341553, 0.04606606438755989, 0.07721769064664841, 0.08158090710639954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20790521800518036, 0.030814683064818382, 0.02946298010647297, 0.050674259662628174, 0.08743470907211304, 0.047705817967653275, 0.02733318693935871, 0.09152112156152725, 0.05214140564203262, 0.04708244651556015, 0.0808199942111969, 0.05453276261687279, 0.12074841558933258, 0.055161673575639725, 0.01666121557354927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19932866096496582, 0.04206705093383789, 0.05715769901871681, 0.071933314204216, 0.05065879225730896, 0.031524572521448135, 0.027136797085404396, 0.04140904173254967, 0.0932227075099945, 0.052022065967321396, 0.025422828271985054, 0.05927914381027222, 0.06613776087760925, 0.0958227664232254, 0.031632158905267715, 0.05524462088942528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2371978461742401, 0.03067580983042717, 0.029208501800894737, 0.05821242555975914, 0.06082989647984505, 0.03495607152581215, 0.02444053255021572, 0.07084919512271881, 0.05983855947852135, 0.03970347344875336, 0.05932589992880821, 0.0367523618042469, 0.07694029808044434, 0.06171641871333122, 0.014049740508198738, 0.06745626777410507, 0.0378466434776783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2499532252550125, 0.0266294926404953, 0.03931761160492897, 0.044632140547037125, 0.07087578624486923, 0.034094225615262985, 0.02126503176987171, 0.05726417899131775, 0.05179663375020027, 0.03503984585404396, 0.043922778218984604, 0.039228759706020355, 0.061559129506349564, 0.0512242466211319, 0.015611974522471428, 0.08278115093708038, 0.03891744837164879, 0.035886332392692566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.222697913646698, 0.02651810832321644, 0.039789535105228424, 0.027604004368185997, 0.08196067810058594, 0.03582964092493057, 0.015378952957689762, 0.06874662637710571, 0.05343088135123253, 0.05469820648431778, 0.05721571668982506, 0.03161528334021568, 0.03717072680592537, 0.05228295549750328, 0.011851192452013493, 0.0720609650015831, 0.03087829053401947, 0.024411147460341454, 0.055859170854091644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07419286668300629, 0.050926972180604935, 0.028230978175997734, 0.034200072288513184, 0.03361427038908005, 0.051822178065776825, 0.009658369235694408, 0.04940613731741905, 0.09883324801921844, 0.05356481298804283, 0.02458188124001026, 0.05879184231162071, 0.01302679255604744, 0.10889022052288055, 0.01567712612450123, 0.04766634479165077, 0.06507280468940735, 0.03886165842413902, 0.03984261676669121, 0.10313884913921356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22614887356758118, 0.02576986886560917, 0.03336169198155403, 0.04034488648176193, 0.06116843968629837, 0.03166025131940842, 0.023036977276206017, 0.04815823212265968, 0.04964131489396095, 0.02570328675210476, 0.05132424086332321, 0.029225800186395645, 0.0462723933160305, 0.04679546132683754, 0.01047150045633316, 0.043467387557029724, 0.027977772057056427, 0.033561065793037415, 0.03209926560521126, 0.05562404915690422, 0.05818726867437363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19442987442016602, 0.020005781203508377, 0.02566998079419136, 0.02761007659137249, 0.07351990044116974, 0.02511858567595482, 0.016428444534540176, 0.0544336661696434, 0.044502679258584976, 0.0222728680819273, 0.029331281781196594, 0.03064262866973877, 0.06286599487066269, 0.0433916412293911, 0.01021601166576147, 0.09763479232788086, 0.029601430520415306, 0.028080439195036888, 0.03757164254784584, 0.05037400871515274, 0.06089738756418228, 0.01540080551058054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19766588509082794, 0.041157495230436325, 0.03360121697187424, 0.023870186880230904, 0.06633447110652924, 0.02801697887480259, 0.019582942128181458, 0.05178564041852951, 0.03159146383404732, 0.026536140590906143, 0.0416431650519371, 0.025757968425750732, 0.0432840920984745, 0.029939454048871994, 0.012750321999192238, 0.056069161742925644, 0.024677351117134094, 0.02150590345263481, 0.045592937618494034, 0.07480885088443756, 0.044334057718515396, 0.021997367963194847, 0.037497010082006454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1804356724023819, 0.02334981970489025, 0.023929765447974205, 0.044541697949171066, 0.040705956518650055, 0.03654098138213158, 0.016616584733128548, 0.05323561280965805, 0.050283923745155334, 0.02584689110517502, 0.04605168476700783, 0.024920543655753136, 0.03976094350218773, 0.04893423989415169, 0.012390019372105598, 0.06191657483577728, 0.023965347558259964, 0.02875448204576969, 0.02509540505707264, 0.06865917891263962, 0.0735766589641571, 0.018046913668513298, 0.022800743579864502, 0.009640375152230263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2424635887145996, 0.02469644322991371, 0.03868826478719711, 0.033572323620319366, 0.05476619303226471, 0.03380467742681503, 0.02072160132229328, 0.03275461494922638, 0.04349980503320694, 0.01856265589594841, 0.03646847978234291, 0.031002484261989594, 0.03862546384334564, 0.039931803941726685, 0.010727171786129475, 0.03831766918301582, 0.029280317947268486, 0.024678120389580727, 0.027889322489500046, 0.045021556317806244, 0.043075986206531525, 0.016905829310417175, 0.023586291819810867, 0.007298625539988279, 0.04366059601306915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11111283302307129, 0.029458744451403618, 0.024559468030929565, 0.030902530997991562, 0.033864837139844894, 0.033630646765232086, 0.012831437401473522, 0.03066926635801792, 0.06390535831451416, 0.02348153106868267, 0.025704611092805862, 0.03766981139779091, 0.016167866066098213, 0.06660737842321396, 0.017231760546565056, 0.030658654868602753, 0.039240483194589615, 0.024295225739479065, 0.026388786733150482, 0.058640263974666595, 0.10666146129369736, 0.017623895779252052, 0.02424543909728527, 0.01827959716320038, 0.036750197410583496, 0.059418004006147385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17855210602283478, 0.04373869672417641, 0.02777230180799961, 0.03288250043988228, 0.08083150535821915, 0.036148551851511, 0.01943815127015114, 0.03604714199900627, 0.0315406434237957, 0.02228383533656597, 0.026742074638605118, 0.020272962749004364, 0.04929490014910698, 0.028057057410478592, 0.010035556741058826, 0.028219016268849373, 0.018526636064052582, 0.025377927348017693, 0.03921228647232056, 0.05273989215493202, 0.024735094979405403, 0.028674766421318054, 0.029405983164906502, 0.013893154449760914, 0.0176064595580101, 0.05648734048008919, 0.021483466029167175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15546514093875885, 0.04916936531662941, 0.024515938013792038, 0.025700539350509644, 0.05483130365610123, 0.0420927032828331, 0.01164503674954176, 0.06493963301181793, 0.031219761818647385, 0.02656278759241104, 0.028326869010925293, 0.018289057537913322, 0.03490860015153885, 0.029660990461707115, 0.008558588102459908, 0.0466504730284214, 0.01766982488334179, 0.02372436411678791, 0.019038720056414604, 0.07715761661529541, 0.02730739489197731, 0.019747741520404816, 0.024364115670323372, 0.014429948292672634, 0.01892835833132267, 0.05850560590624809, 0.02436404675245285, 0.022225432097911835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19332920014858246, 0.026298340409994125, 0.03039250150322914, 0.02961190976202488, 0.04520163685083389, 0.03307906910777092, 0.02184077352285385, 0.026594150811433792, 0.04538282752037048, 0.03843945637345314, 0.02691539190709591, 0.024535097181797028, 0.015795720741152763, 0.040367621928453445, 0.010634277015924454, 0.026345491409301758, 0.022409791126847267, 0.019946036860346794, 0.04401850700378418, 0.06709348410367966, 0.033454738557338715, 0.01608494482934475, 0.025615878403186798, 0.01140951830893755, 0.013623220846056938, 0.04055489972233772, 0.016662972047924995, 0.03589887171983719, 0.018463704735040665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15965190529823303, 0.01864234358072281, 0.026677725836634636, 0.028047846630215645, 0.04907771572470665, 0.0260456595569849, 0.01780770905315876, 0.03679424151778221, 0.045969411730766296, 0.019110891968011856, 0.03796318545937538, 0.027620630338788033, 0.02834104560315609, 0.04296436160802841, 0.008847595192492008, 0.03253018483519554, 0.025659985840320587, 0.02448510006070137, 0.029966222122311592, 0.04054072126746178, 0.04233502596616745, 0.017694557085633278, 0.02121768519282341, 0.006380946841090918, 0.031033925712108612, 0.03557969629764557, 0.025066182017326355, 0.02660747617483139, 0.024308431893587112, 0.043031539767980576, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1966170370578766, 0.01979137398302555, 0.0330333448946476, 0.025687098503112793, 0.042206067591905594, 0.03137582167983055, 0.01624363474547863, 0.030698416754603386, 0.036294274032115936, 0.026839347556233406, 0.026712190359830856, 0.023046312853693962, 0.02195010334253311, 0.03344837203621864, 0.010305739939212799, 0.022743644192814827, 0.021480808034539223, 0.021094728261232376, 0.031490400433540344, 0.03692729026079178, 0.037232108414173126, 0.015421994961798191, 0.019252348691225052, 0.0073204925283789635, 0.024766920134425163, 0.04439167678356171, 0.0198507197201252, 0.02613365836441517, 0.018124466761946678, 0.042709074914455414, 0.03681057319045067, 0.0, 0.0, 0.0, 0.0], [0.16313208639621735, 0.022932477295398712, 0.029583686962723732, 0.028615498915314674, 0.037784643471241, 0.026518700644373894, 0.026229016482830048, 0.031034143641591072, 0.03483205661177635, 0.01897561363875866, 0.033202946186065674, 0.026435954496264458, 0.032307371497154236, 0.0313291996717453, 0.01172788068652153, 0.027169130742549896, 0.024106519296765327, 0.02262030355632305, 0.025755558162927628, 0.03801414743065834, 0.03207404538989067, 0.017354248091578484, 0.017987214028835297, 0.009293689392507076, 0.04247137904167175, 0.0312158465385437, 0.019006574526429176, 0.021523447707295418, 0.0175411868840456, 0.040145207196474075, 0.018160777166485786, 0.04091951251029968, 0.0, 0.0, 0.0], [0.15803851187229156, 0.016828803345561028, 0.020642392337322235, 0.045382533222436905, 0.046641744673252106, 0.027835223823785782, 0.020206494256854057, 0.04211510717868805, 0.037034474313259125, 0.01774459145963192, 0.030353328213095665, 0.024713626131415367, 0.034284885972738266, 0.03341372311115265, 0.009082169272005558, 0.035213764756917953, 0.022280126810073853, 0.020849989727139473, 0.027390217408537865, 0.03231459856033325, 0.0376492403447628, 0.014920791611075401, 0.016553670167922974, 0.006309077143669128, 0.02321873977780342, 0.02794986218214035, 0.02383224107325077, 0.015323556959629059, 0.017670489847660065, 0.02681528776884079, 0.022188853472471237, 0.028694558888673782, 0.03650737926363945, 0.0, 0.0], [0.17019402980804443, 0.032125912606716156, 0.02987012080848217, 0.01961558870971203, 0.05489380657672882, 0.03622056171298027, 0.01715220883488655, 0.032326590269804, 0.0315006859600544, 0.02962452918291092, 0.02909429371356964, 0.01662426069378853, 0.02998979575932026, 0.02761414647102356, 0.010949773713946342, 0.03436654806137085, 0.014830096624791622, 0.015176056884229183, 0.03050290234386921, 0.041597455739974976, 0.02064121887087822, 0.017041223123669624, 0.02617543190717697, 0.010538813658058643, 0.007441799156367779, 0.03439135104417801, 0.026077082380652428, 0.029615644365549088, 0.01369301974773407, 0.018074296414852142, 0.03374852240085602, 0.029002603143453598, 0.013117284514009953, 0.016172271221876144, 0.0], [0.11417391896247864, 0.016700677573680878, 0.023576240986585617, 0.03235284611582756, 0.05511363968253136, 0.029616648331284523, 0.017176376655697823, 0.05952787026762962, 0.038434237241744995, 0.020421095192432404, 0.03235999867320061, 0.019217435270547867, 0.019135117530822754, 0.03519751876592636, 0.010996297933161259, 0.04401442036032677, 0.016835959628224373, 0.016212480142712593, 0.023840539157390594, 0.04231660068035126, 0.037168409675359726, 0.009007316082715988, 0.015979532152414322, 0.005828788038343191, 0.02082640305161476, 0.028255829587578773, 0.03160589188337326, 0.02425200864672661, 0.0232852753251791, 0.01991749368607998, 0.02455976791679859, 0.02195737324655056, 0.01319314818829298, 0.020208798348903656, 0.03673402592539787]]], \"tokens\": [\"<|endoftext|>\", \"I\", \" am\", \" an\", \" amazing\", \" aut\", \"ore\", \"gressive\", \",\", \" dec\", \"oder\", \"-\", \"only\", \",\", \" G\", \"PT\", \"-\", \"2\", \" style\", \" transformer\", \".\", \" One\", \" day\", \" I\", \" will\", \" exceed\", \" human\", \" level\", \" intelligence\", \" and\", \" take\", \" over\", \" the\", \" world\", \"!\"], \"maskUpperTri\": true}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(\n",
        "    cv.attention.attention_heads(\n",
        "        tokens=reference_gpt2.to_str_tokens(reference_text), attention=cache[\"pattern\", 0][0]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK6XZ9XJCTAI"
      },
      "source": [
        "You should fill in the forward method for `Attention` below. You should also copy your code for `apply_causal_mask` to this new implementation of `Attention` (you can delete the rest of the old implementation code).\n",
        "\n",
        "Note, this implementation will probably be the most challenging exercise on this page, so don't worry if it takes you some time! You should look at parts of the solution if you're stuck. A few tips:\n",
        "\n",
        "* Don't forget the attention score scaling (this should come before the masking).\n",
        "* Try not to combine a large number of operations into a single line of code.\n",
        "* Try to make your variable names descriptive (i.e. it's not just `x = some_fn_of(x), x = some_other_fn_of(x), ...`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIqx8iqUCTAJ",
        "outputId": "46a3ccaf-e279-49f0-fbb8-eacaa1cc5e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_causal_mask` passed!\n",
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768]) \n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class Attention(nn.Module):\n",
        "    IGNORE: Float[Tensor, \"\"]\n",
        "\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_O = nn.Parameter(t.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        self.b_Q = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_K = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_V = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_O = nn.Parameter(t.zeros((cfg.d_model)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.register_buffer(\"IGNORE\", t.tensor(float(\"-inf\"), dtype=t.float32, device=device))\n",
        "\n",
        "    def forward(\n",
        "        self, normalized_resid_pre: Float[Tensor, \"batch posn d_model\"]\n",
        "    ) -> Float[Tensor, \"batch posn d_model\"]:\n",
        "        q = (\n",
        "            einops.einsum(\n",
        "                normalized_resid_pre,\n",
        "                self.W_Q,\n",
        "                \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\",\n",
        "            )\n",
        "            + self.b_Q\n",
        "        )\n",
        "        k = (\n",
        "            einops.einsum(\n",
        "                normalized_resid_pre,\n",
        "                self.W_K,\n",
        "                \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\",\n",
        "            )\n",
        "            + self.b_K\n",
        "        )\n",
        "        v = (\n",
        "            einops.einsum(\n",
        "                normalized_resid_pre,\n",
        "                self.W_V,\n",
        "                \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\",\n",
        "            )\n",
        "            + self.b_V\n",
        "        )\n",
        "\n",
        "        # Calculate attention scores, then scale and mask, and apply softmax to get probabilities\n",
        "        attn_scores = einops.einsum(\n",
        "            q,\n",
        "            k,\n",
        "            \"batch posn_Q nheads d_head, batch posn_K nheads d_head -> batch nheads posn_Q posn_K\",\n",
        "        )\n",
        "        attn_scores_masked = self.apply_causal_mask(attn_scores / self.cfg.d_head**0.5)\n",
        "        attn_pattern = attn_scores_masked.softmax(-1)\n",
        "\n",
        "        # Take weighted sum of value vectors, according to attention probabilities\n",
        "        z = einops.einsum(\n",
        "            v,\n",
        "            attn_pattern,\n",
        "            \"batch posn_K nheads d_head, batch nheads posn_Q posn_K -> batch posn_Q nheads d_head\",\n",
        "        )\n",
        "\n",
        "        # Calculate output (by applying matrix W_O and summing over heads, then adding bias b_O)\n",
        "        attn_out = (\n",
        "            einops.einsum(\n",
        "                z,\n",
        "                self.W_O,\n",
        "                \"batch posn_Q nheads d_head, nheads d_head d_model -> batch posn_Q d_model\",\n",
        "            )\n",
        "            + self.b_O\n",
        "        )\n",
        "\n",
        "        return attn_out\n",
        "\n",
        "    def apply_causal_mask(\n",
        "        self,\n",
        "        attn_scores: Float[Tensor, \"batch n_heads query_pos key_pos\"],\n",
        "    ) -> Float[Tensor, \"batch n_heads query_pos key_pos\"]:\n",
        "        \"\"\"\n",
        "        Applies a causal mask to attention scores, and returns masked scores.\n",
        "        \"\"\"\n",
        "        all_ones = t.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device)\n",
        "        mask = t.triu(all_ones, diagonal=1).bool()\n",
        "        # Apply the mask to attention scores, then return the masked scores\n",
        "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
        "        return attn_scores\n",
        "\n",
        "\n",
        "tests.test_causal_mask(Attention.apply_causal_mask)\n",
        "rand_float_test(Attention, [2, 4, 768])\n",
        "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"normalized\", 0, \"ln1\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsTJ4n_RCTAJ"
      },
      "source": [
        "<details>\n",
        "<summary>Hint (pseudocode for the forward method)</summary>\n",
        "\n",
        "```python\n",
        "def forward(\n",
        "    self, normalized_resid_pre: Float[Tensor, \"batch posn d_model\"]\n",
        ") -> Float[Tensor, \"batch posn d_model\"]:\n",
        "\n",
        "    # Calculate query, key and value vectors\n",
        "    q, k, v = ...\n",
        "\n",
        "    # Calculate attention scores, then scale and mask, and apply softmax to get probabilities\n",
        "    attn_scores = ...\n",
        "    attn_scores_masked = ...\n",
        "    attn_pattern = ...\n",
        "\n",
        "    # Take weighted sum of value vectors, according to attention probabilities\n",
        "    z = ...\n",
        "\n",
        "    # Calculate output (by applying matrix W_O and summing over heads, then adding bias b_O)\n",
        "    attn_out = ...\n",
        "    return attn_out\n",
        "```\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Attention(nn.Module):\n",
        "    IGNORE: Float[Tensor, \"\"]\n",
        "\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_O = nn.Parameter(t.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        self.b_Q = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_K = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_V = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_O = nn.Parameter(t.zeros((cfg.d_model)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.register_buffer(\"IGNORE\", t.tensor(float(\"-inf\"), dtype=t.float32, device=device))\n",
        "\n",
        "    def forward(\n",
        "        self, normalized_resid_pre: Float[Tensor, \"batch posn d_model\"]\n",
        "    ) -> Float[Tensor, \"batch posn d_model\"]:\n",
        "        # Calculate query, key and value vectors\n",
        "        q = (\n",
        "            einops.einsum(\n",
        "                normalized_resid_pre,\n",
        "                self.W_Q,\n",
        "                \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\",\n",
        "            )\n",
        "            + self.b_Q\n",
        "        )\n",
        "        k = (\n",
        "            einops.einsum(\n",
        "                normalized_resid_pre,\n",
        "                self.W_K,\n",
        "                \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\",\n",
        "            )\n",
        "            + self.b_K\n",
        "        )\n",
        "        v = (\n",
        "            einops.einsum(\n",
        "                normalized_resid_pre,\n",
        "                self.W_V,\n",
        "                \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\",\n",
        "            )\n",
        "            + self.b_V\n",
        "        )\n",
        "\n",
        "        # Calculate attention scores, then scale and mask, and apply softmax to get probabilities\n",
        "        attn_scores = einops.einsum(\n",
        "            q,\n",
        "            k,\n",
        "            \"batch posn_Q nheads d_head, batch posn_K nheads d_head -> batch nheads posn_Q posn_K\",\n",
        "        )\n",
        "        attn_scores_masked = self.apply_causal_mask(attn_scores / self.cfg.d_head**0.5)\n",
        "        attn_pattern = attn_scores_masked.softmax(-1)\n",
        "\n",
        "        # Take weighted sum of value vectors, according to attention probabilities\n",
        "        z = einops.einsum(\n",
        "            v,\n",
        "            attn_pattern,\n",
        "            \"batch posn_K nheads d_head, batch nheads posn_Q posn_K -> batch posn_Q nheads d_head\",\n",
        "        )\n",
        "\n",
        "        # Calculate output (by applying matrix W_O and summing over heads, then adding bias b_O)\n",
        "        attn_out = (\n",
        "            einops.einsum(\n",
        "                z,\n",
        "                self.W_O,\n",
        "                \"batch posn_Q nheads d_head, nheads d_head d_model -> batch posn_Q d_model\",\n",
        "            )\n",
        "            + self.b_O\n",
        "        )\n",
        "\n",
        "        return attn_out\n",
        "\n",
        "    def apply_causal_mask(\n",
        "        self, attn_scores: Float[Tensor, \"batch n_heads query_pos key_pos\"]\n",
        "    ) -> Float[Tensor, \"batch n_heads query_pos key_pos\"]:\n",
        "        \"\"\"\n",
        "        Applies a causal mask to attention scores, and returns masked scores.\n",
        "        \"\"\"\n",
        "        # Define a mask that is True for all positions we want to set probabilities to zero for\n",
        "        all_ones = t.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device)\n",
        "        mask = t.triu(all_ones, diagonal=1).bool()\n",
        "        # Apply the mask to attention scores, then return the masked scores\n",
        "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
        "        return attn_scores\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERifI0UxCTAJ"
      },
      "source": [
        "### Exercise - implement `MLP`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Next, you should implement the MLP layer, which consists of:\n",
        "\n",
        "* A linear layer, with weight `W_in`, bias `b_in`\n",
        "* A nonlinear function (we usually use GELU; the function `gelu_new` has been imported for this purpose)\n",
        "* A linear layer, with weight `W_out`, bias `b_out`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUiEGEiSCTAJ",
        "outputId": "b01048cb-4317-4003-a667-fd292e108d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768]) \n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_in = nn.Parameter(t.empty((cfg.d_model, cfg.d_mlp)))\n",
        "        self.W_out = nn.Parameter(t.empty((cfg.d_mlp, cfg.d_model)))\n",
        "        self.b_in = nn.Parameter(t.zeros((cfg.d_mlp)))\n",
        "        self.b_out = nn.Parameter(t.zeros((cfg.d_model)))\n",
        "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(\n",
        "        self, normalized_resid_mid: Float[Tensor, \"batch posn d_model\"]\n",
        "    ) -> Float[Tensor, \"batch posn d_model\"]:\n",
        "        pre = (\n",
        "            einops.einsum(\n",
        "                normalized_resid_mid,\n",
        "                self.W_in,\n",
        "                \"batch position d_model, d_model d_mlp -> batch position d_mlp\",\n",
        "            )\n",
        "            + self.b_in\n",
        "        )\n",
        "        post = gelu_new(pre)\n",
        "        mlp_out = (\n",
        "            einops.einsum(\n",
        "                post, self.W_out, \"batch position d_mlp, d_mlp d_model -> batch position d_model\"\n",
        "            )\n",
        "            + self.b_out\n",
        "        )\n",
        "        return mlp_out\n",
        "\n",
        "\n",
        "rand_float_test(MLP, [2, 4, 768])\n",
        "load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"normalized\", 0, \"ln2\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onrw97zuCTAJ"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_in = nn.Parameter(t.empty((cfg.d_model, cfg.d_mlp)))\n",
        "        self.W_out = nn.Parameter(t.empty((cfg.d_mlp, cfg.d_model)))\n",
        "        self.b_in = nn.Parameter(t.zeros((cfg.d_mlp)))\n",
        "        self.b_out = nn.Parameter(t.zeros((cfg.d_model)))\n",
        "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(\n",
        "        self, normalized_resid_mid: Float[Tensor, \"batch posn d_model\"]\n",
        "    ) -> Float[Tensor, \"batch posn d_model\"]:\n",
        "        pre = (\n",
        "            einops.einsum(\n",
        "                normalized_resid_mid,\n",
        "                self.W_in,\n",
        "                \"batch position d_model, d_model d_mlp -> batch position d_mlp\",\n",
        "            )\n",
        "            + self.b_in\n",
        "        )\n",
        "        post = gelu_new(pre)\n",
        "        mlp_out = (\n",
        "            einops.einsum(\n",
        "                post, self.W_out, \"batch position d_mlp, d_mlp d_model -> batch position d_model\"\n",
        "            )\n",
        "            + self.b_out\n",
        "        )\n",
        "        return mlp_out\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHf57-9ECTAJ"
      },
      "source": [
        "### Exercise - implement `TransformerBlock`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Now, we can put together the attention, MLP and layernorms into a single transformer block. Remember to implement the residual connections correctly!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQWlpBukCTAJ",
        "outputId": "703ea68f-3487-4be8-9ddc-38f77bdd9ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768]) \n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(\n",
        "        self, resid_pre: Float[Tensor, \"batch position d_model\"]\n",
        "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        resid_mid = self.attn(self.ln1(resid_pre)) + resid_pre\n",
        "        resid_post = self.mlp(self.ln2(resid_mid)) + resid_mid\n",
        "        return resid_post\n",
        "\n",
        "\n",
        "rand_float_test(TransformerBlock, [2, 4, 768])\n",
        "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vzFM3fXCTAJ"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm getting 100% accuracy on all modules before this point, but only about 90% accuracy on this one.</summary>\n",
        "\n",
        "This might be because your layernorm implementation divides by `std + eps` rather than `(var + eps).sqrt()`. The latter matches the implementation used by GPT-2 (and this error only shows up in these tests).\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(\n",
        "        self, resid_pre: Float[Tensor, \"batch position d_model\"]\n",
        "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        resid_mid = self.attn(self.ln1(resid_pre)) + resid_pre\n",
        "        resid_post = self.mlp(self.ln2(resid_mid)) + resid_mid\n",
        "        return resid_post\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzEpEgbXCTAJ"
      },
      "source": [
        "### Exercise - implement `Unembed`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to ~10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "The unembedding is just a linear layer (with weight `W_U` and bias `b_U`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onnyVJfkCTAJ",
        "outputId": "10934def-fa31-4bec-e3e1-4fc388f2cf67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257]) \n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 50257])\n",
            "Reference output shape: torch.Size([1, 35, 50257]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class Unembed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_U = nn.Parameter(t.empty((cfg.d_model, cfg.d_vocab)))\n",
        "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
        "        self.b_U = nn.Parameter(t.zeros((cfg.d_vocab), requires_grad=False))\n",
        "\n",
        "    def forward(\n",
        "        self, normalized_resid_final: Float[Tensor, \"batch position d_model\"]\n",
        "    ) -> Float[Tensor, \"batch position d_vocab\"]:\n",
        "        return(\n",
        "            einops.einsum(\n",
        "                normalized_resid_final,\n",
        "                self.W_U,\n",
        "                \"batch posn d_model, d_model d_vocab -> batch posn d_vocab\",\n",
        "            )\n",
        "            + self.b_U\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "rand_float_test(Unembed, [2, 4, 768])\n",
        "load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yfSds08CTAJ"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class Unembed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_U = nn.Parameter(t.empty((cfg.d_model, cfg.d_vocab)))\n",
        "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
        "        self.b_U = nn.Parameter(t.zeros((cfg.d_vocab), requires_grad=False))\n",
        "\n",
        "    def forward(\n",
        "        self, normalized_resid_final: Float[Tensor, \"batch position d_model\"]\n",
        "    ) -> Float[Tensor, \"batch position d_vocab\"]:\n",
        "        return (\n",
        "            einops.einsum(\n",
        "                normalized_resid_final,\n",
        "                self.W_U,\n",
        "                \"batch posn d_model, d_model d_vocab -> batch posn d_vocab\",\n",
        "            )\n",
        "            + self.b_U\n",
        "        )\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3oWr7mICTAJ"
      },
      "source": [
        "### Exercise - implement `DemoTransformer`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTOanyhKCTAJ",
        "outputId": "c913b4a3-8f4e-4865-e0e6-b449cc537f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Output shape: torch.Size([2, 4, 50257]) \n",
            "\n",
            "Input shape: torch.Size([1, 45])\n",
            "Output shape: torch.Size([1, 45, 50257])\n",
            "Reference output shape: torch.Size([1, 45, 50257]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(\n",
        "        self, tokens: Int[Tensor, \"batch position\"]\n",
        "    ) -> Float[Tensor, \"batch position d_vocab\"]:\n",
        "        residual = self.embed(tokens) + self.pos_embed(tokens)\n",
        "        for block in self.blocks:\n",
        "            residual = block(residual)\n",
        "        residual = self.unembed(self.ln_final(residual))\n",
        "        return residual\n",
        "\n",
        "\n",
        "rand_int_test(DemoTransformer, [2, 4])\n",
        "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZiug_9oCTAJ"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(\n",
        "        self, tokens: Int[Tensor, \"batch position\"]\n",
        "    ) -> Float[Tensor, \"batch position d_vocab\"]:\n",
        "        residual = self.embed(tokens) + self.pos_embed(tokens)\n",
        "        for block in self.blocks:\n",
        "            residual = block(residual)\n",
        "        logits = self.unembed(self.ln_final(residual))\n",
        "        return logits\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg7__U5sCTAJ"
      },
      "source": [
        "**Try it out!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pvbbCaBUCTAJ"
      },
      "outputs": [],
      "source": [
        "demo_gpt2 = DemoTransformer(Config(debug=False)).to(device)\n",
        "demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
        "\n",
        "demo_logits = demo_gpt2(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anmi7Uv9CTAJ"
      },
      "source": [
        "Let's take a test string, and calculate the loss!\n",
        "\n",
        "We're using the formula for **cross-entropy loss**. The cross entropy loss between a modelled distribution $Q$ and target distribution $P$ is:\n",
        "\n",
        "$$\n",
        "-\\sum_x P(x) \\log Q(x)\n",
        "$$\n",
        "\n",
        "In the case where $P$ is just the empirical distribution from target classes (i.e. $P(x^*) = 1$ for the correct class $x^*$) then this becomes:\n",
        "\n",
        "$$\n",
        "-\\log Q(x^*)\n",
        "$$\n",
        "\n",
        "in other words, the negative log prob of the true classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDxfh6CSCTAJ",
        "outputId": "890c58ea-ce20-4fcc-ee22-71c529c42b2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg cross entropy loss: 4.0441\n",
            "Avg cross entropy loss for uniform distribution: 10.824905\n",
            "Avg probability assigned to correct token: 0.098629\n"
          ]
        }
      ],
      "source": [
        "def get_log_probs(\n",
        "    logits: Float[Tensor, \"batch posn d_vocab\"], tokens: Int[Tensor, \"batch posn\"]\n",
        ") -> Float[Tensor, \"batch posn-1\"]:\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    # Get logprobs the first seq_len-1 predictions (so we can compare them with the actual next tokens)\n",
        "    log_probs_for_tokens = (\n",
        "        log_probs[:, :-1].gather(dim=-1, index=tokens[:, 1:].unsqueeze(-1)).squeeze(-1)\n",
        "    )\n",
        "\n",
        "    return log_probs_for_tokens\n",
        "\n",
        "\n",
        "pred_log_probs = get_log_probs(demo_logits, tokens)\n",
        "print(f\"Avg cross entropy loss: {-pred_log_probs.mean():.4f}\")\n",
        "print(f\"Avg cross entropy loss for uniform distribution: {math.log(demo_gpt2.cfg.d_vocab):4f}\")\n",
        "print(f\"Avg probability assigned to correct token: {pred_log_probs.exp().mean():4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hymn4f8CTAJ"
      },
      "source": [
        "We can also greedily generate text, by taking the most likely next token and continually appending it to our prompt before feeding it back into the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397,
          "referenced_widgets": [
            "6f9b9a223838496f90943e8e1202950d",
            "e748dd8746b24435be51ed15d7395a09",
            "85ef70b4b7f6489bb76862b16698af25",
            "5fe8afeede214812bf2cbb353ed1ecad",
            "8c44b873db704efeaa2d931ffc82bfc4",
            "e92877c7c0e849d381a43a21faa69880",
            "bb7d6301850548bfa3a2f55f00215cf3",
            "97a04559b97d409db46bab56e3d37e07",
            "547c38c6c72f4101b17a58b5b4341afb",
            "3f89f839786949059f0a517c58c80b8b",
            "97cb68c2b4834aa5a4a23d80dc07aba2"
          ]
        },
        "id": "O9MOLaOFCTAJ",
        "outputId": "68751ce4-bba0-41fd-8694-44e6f4f6a4c5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f9b9a223838496f90943e8e1202950d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-873056070.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference_gpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdemo_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdemo_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest_string\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreference_gpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1763273064.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munembed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1321989580.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, resid_pre)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresid_pre\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFloat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"batch position d_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     ) -> Float[Tensor, \"batch position d_model\"]:\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mresid_mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresid_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresid_pre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mresid_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresid_mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresid_mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresid_post\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2090132555.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, residual)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mresidual_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         residual_std = (\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mresidual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munbiased\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm_eps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         ).sqrt()\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "test_string = \"\"\"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as\"\"\"\n",
        "for i in tqdm(range(100)):\n",
        "    test_tokens = reference_gpt2.to_tokens(test_string).to(device)\n",
        "    demo_logits = demo_gpt2(test_tokens)\n",
        "    test_string += reference_gpt2.tokenizer.decode(demo_logits[-1, -1].argmax())\n",
        "\n",
        "print(test_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgkiQizbCTAK"
      },
      "source": [
        "In section 4️⃣ we'll learn to generate text in slightly more interesting ways than just argmaxing the output (which can lead to unnatural patterns like repetition, or text which is just less natural-sounding)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfb8jTuqCTAK"
      },
      "source": [
        "# 3️⃣ Training a Transformer\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Understand how to train a transformer from scratch\n",
        "> * Write a basic transformer training loop\n",
        "> * Interpret the transformer's falling cross entropy loss with reference to features of the training data (e.g. bigram frequencies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDvE1XTICTAK"
      },
      "source": [
        "Now that we've built our transformer, and verified that it performs as expected when we load in weights, let's try training it from scratch!\n",
        "\n",
        "This is a lightweight demonstration of how you can actually train your own GPT-2 with this code! Here we train a tiny model on a tiny dataset, but it's fundamentally the same code for training a larger/more real model (though you'll need beefier GPUs and data parallelism to do it remotely efficiently, and fancier parallelism for much bigger ones).\n",
        "\n",
        "For our purposes, we'll train a 4 layer model with 16 heads per layer, with context length 128, for 10*500 steps of batch size 32, just to show what it looks like (and so the notebook doesn't melt your colab / machine!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaL4VTYnCTAK"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "d6Aj6plqCTAK"
      },
      "outputs": [],
      "source": [
        "model_cfg = Config(\n",
        "    debug=False,\n",
        "    d_model=32,\n",
        "    n_heads=16,\n",
        "    d_head=2,\n",
        "    d_mlp=32 * 4,\n",
        "    n_layers=4,\n",
        "    n_ctx=128,\n",
        "    d_vocab=reference_gpt2.cfg.d_vocab,\n",
        ")\n",
        "model = DemoTransformer(model_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht0XdJx_CTAK"
      },
      "source": [
        "## Training Args\n",
        "\n",
        "\n",
        "Note, for this optimization we'll be using **weight decay**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ZU1CEtdUCTAK"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TransformerTrainingArgs:\n",
        "    batch_size: int = 32\n",
        "    epochs: int = 10\n",
        "    max_steps_per_epoch: int = 500\n",
        "    lr: float = 1e-3\n",
        "    weight_decay: float = 1e-2\n",
        "    wandb_project: str | None = \"day1-demotransformer\"\n",
        "    wandb_name: str | None = None\n",
        "\n",
        "\n",
        "args = TransformerTrainingArgs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIG8xpE2CTAK"
      },
      "source": [
        "## Create Data\n",
        "\n",
        "We load in the [TinyStories dataset](https://huggingface.co/datasets/roneneldan/TinyStories), a dataset of synthetically generated simple stories only using a small vocabulary of words that typical 3 to 4-year-olds can understand. This dataset was designed for [exploring how small a LLM can be](https://arxiv.org/pdf/2305.07759) that can still generate coherent text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566,
          "referenced_widgets": [
            "a9a2c1033bf347168dc963aa79e242e6",
            "12290557d87e46cd89691741b5c51e17",
            "500a043a340041eaae926f3f542e45cd",
            "1b2d25baecaf48ad85b9db65ce6ea88e",
            "b4f6b696f3ba4309a20d7bcd513d1c5e",
            "e9027d8c524b43a18f04bcb31a6dd2f1",
            "1d8b805c03bc4990919671cd4efa786b",
            "c82621277b9e4e92a7fbe056f1919311",
            "7ea8e4d9e5b94bf887a933a65c17c668",
            "65ac65db76a04258a204819293bf6d39",
            "b8aaaedbd1304f83be393aecc6838774",
            "5ff57e67cba5412da0ef49a19d7596ec",
            "c2b16b89b045433bb30ab0f7a8393024",
            "4d78487411d24c29aa8f2885a87e6893",
            "8a6acc656be84d8ba629a0f6ef62c223",
            "b81df613d5b44df2b7ec58c0d93a7f9c",
            "8393ccc2a3c84d33a26b5b9cd1c59c95",
            "6d37d39fde674e3780df37a7b870cb74",
            "e238138cc20543bfac5cc4ac857ab60c",
            "d235d1ec91dc4e8084dbfe7a2bc770ae",
            "1dcc2a93f6a94b3eb18ce661908a9681",
            "32737744ec2347a8b096cd932edc1424",
            "08486fa5a5084227b4bb1cc64de08143",
            "4c5f16fade704383a835ea1d41def3a6",
            "b7b4f504ff024157a91efd6d262f8d14",
            "67e5f2ec80d74fcb8f3008e302e82cf7",
            "e12a3f7338284c06adf444096e82784a",
            "93d754c40f7446988a3e029faa148394",
            "83b9ba7b7c0848fa96fa56d4aa075405",
            "f64ade0c64ce47d9997e366a716fff1f",
            "77240817622e4a06aaee74d39ac3727d",
            "e64f643b57814d5790d1058564c14676",
            "ea4d8da59a5e485ab9db53d484d193dc",
            "4f1282f3ce0d465dbb813213e137df68",
            "fa74dcd936a3459784fa123412218dff",
            "5fc6587f8b184e7c9080e7ceb73e7a2d",
            "079865ba91764d8da58fe879820c8596",
            "b513e45f79af4532bc9671a58553419a",
            "d033f917dff646aaa72109e5400c8fdb",
            "9acb74bd867b4543bce47a6a047a0335",
            "1ee041a16b6140eda469fe31795dde06",
            "40da8d6071864fe2aa6c518389208035",
            "a27e93b838174694bb1aac229d9f84c9",
            "86007cac56a94f85b05add6e354c6605",
            "1f9f292b819b41919d88030b13c8e7ba",
            "83153d126e414172b945fb4e75723072",
            "edd311bcf3d74b9a8f683aeeb42d4902",
            "50504a1123f04682bc6329a96b2d4f01",
            "3fca0bfa138e49cbadb6ef1bbba8ba33",
            "b3e791ffbb3145e18de24a8db7b4fb5c",
            "561a458a1369458e9c5c0f54354a3ddf",
            "e995b4a315714e9a8b77a6d9b7cd6d60",
            "99ff3e14fa6d423390a4a043bf2c20a8",
            "b9e0f7b9c97f41cebfcef918367a9b82",
            "b5b78d015f684ee3ae1f6cbafd45e715",
            "e683611b08d84671b99e430607c8fb66",
            "bfcb0dbd9c2a4454832ed30ebe2936be",
            "181593149f724af18a6dbcf35e0c9cdc",
            "c0d470fdd4fe425889637c0afc14c598",
            "a37a0424d899432d9d2692399e061bf6",
            "5b21c797e102491fa3063c7ffed9c1eb",
            "0b31b8fa775a4a8095d7ed5970de120b",
            "fd9f97081604469180c4180babab68fd",
            "34bcf85f42524a948de31387eb543faf",
            "7ae4cfc8f3704862aef61b2bce8d18f3",
            "44fdf7969ffa4ae6b490d661dca62528",
            "2b49833d17904646871a3208491c13f7",
            "2235adcaf21a45799a84b76848936bfb",
            "2caa3ae8889e4b5ea44416612cd7eea6",
            "07b99c26f2cb4a95b702cac9de086f08",
            "be48e018bc4e413f8cb94d869985842b",
            "d78697af08c846b191cb9717db7a1aa7",
            "6635123549244e538d5886eccb466897",
            "bf490a00c9f042748ac75ba0eb010160",
            "6409ad5596b44d349cea055eed0c0133",
            "514cefb6c9134705b9aa6e6a0fdd40be",
            "c728ec00abca453eac61b34f8db0ef61",
            "80e949c110a94ec3aa1192f4337b29d5",
            "6fdf9d09f3174808a54de38590050828",
            "62e2cf0a515147af8d097ef77912f046",
            "46322ff418834106924f4c8f691b0b14",
            "0950a12d6a184ce1a5498d2a8503fc2c",
            "efb4a9ce487b4cf882d3e629c657fba2",
            "43c8882d2def444f8be3363a55ce091c",
            "53929df2aa914af282e745c646efd01a",
            "caa2a574d07e4064a40a40587b5dd899",
            "0f765c301eaa4996a5e0d77de0ec5c14",
            "564715d93c974c728d2f5390b22ea1dc"
          ]
        },
        "id": "QI20h962CTAK",
        "outputId": "bda7ac4d-dada-4327-c9cb-4f9b04e8d899"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9a2c1033bf347168dc963aa79e242e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00004-2d5a1467fff108(…):   0%|          | 0.00/249M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ff57e67cba5412da0ef49a19d7596ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00001-of-00004-5852b56a2bd28f(…):   0%|          | 0.00/248M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08486fa5a5084227b4bb1cc64de08143"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00002-of-00004-a26307300439e9(…):   0%|          | 0.00/246M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f1282f3ce0d465dbb813213e137df68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00003-of-00004-d243063613e5a0(…):   0%|          | 0.00/248M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f9f292b819b41919d88030b13c8e7ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/validation-00000-of-00001-869c898b5(…):   0%|          | 0.00/9.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e683611b08d84671b99e430607c8fb66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b49833d17904646871a3208491c13f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80e949c110a94ec3aa1192f4337b29d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 2119719\n",
            "})\n",
            "One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
            "\n",
            "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
            "\n",
            "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\n"
          ]
        }
      ],
      "source": [
        "dataset = datasets.load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
        "print(dataset)\n",
        "print(dataset[0][\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0WzNy2mCTAK"
      },
      "source": [
        "`tokenize_and_concatenate` is a useful function which takes our dataset of strings, and returns a dataset of token IDs ready to feed into the model. We then create a dataloader from this tokenized dataset. The useful method `train_test_split` can give us a training and testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "6eaf1782ad7048c9aabca13fda294e3a",
            "036d051b89ef4894b77b237424f68e4a",
            "4638146b273546d7a5d68f0a7e3dfc14",
            "7d98385d553f4a21b36213007e721cf7",
            "cb971bf2e1164cb3b4e6c510a1f6469c",
            "0d877b1875744940b68c59e5aa6b2c54",
            "f570c20c3eae40fba48d4c939b769de5",
            "26480bfcf03a4f36aea6bf4f54e0b128",
            "61cdd319bdce4057b1cac9c24233de9b",
            "ae1faf1f87c24d229749599e99a9f48c",
            "926e1efedbcb41c385f773729a985abe"
          ]
        },
        "id": "OyIPT3OhCTAK",
        "outputId": "183f853e-98cf-4c5e-b02e-c3d1381999d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/2119719 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6eaf1782ad7048c9aabca13fda294e3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (10666 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (12536 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (12297 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (13147 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "tokenized_dataset = tokenize_and_concatenate(\n",
        "    dataset,\n",
        "    reference_gpt2.tokenizer,\n",
        "    streaming=False,\n",
        "    max_length=model.cfg.n_ctx,\n",
        "    column_name=\"text\",\n",
        "    add_bos_token=True,\n",
        "    num_proc=4,\n",
        ")\n",
        "\n",
        "dataset_dict = tokenized_dataset.train_test_split(test_size=1000)\n",
        "train_loader = DataLoader(\n",
        "    dataset_dict[\"train\"], batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    dataset_dict[\"test\"], batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD_J6fLsCTAK"
      },
      "source": [
        "When we iterate through these dataloaders, we will find dictionaries with the single key `'tokens'`, which maps to a tensor of token IDs with shape `(batch, seq_len)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B4I84xHCTAK",
        "outputId": "a74d1ce4-41c9-4cb2-c980-2d6685721b3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['tokens'])\n",
            "torch.Size([32, 128])\n"
          ]
        }
      ],
      "source": [
        "first_batch = train_loader.dataset[: args.batch_size]\n",
        "\n",
        "print(first_batch.keys())\n",
        "print(first_batch[\"tokens\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_y9QmgRCTAK"
      },
      "source": [
        "## Training Loop\n",
        "\n",
        "If you did the material on [training loops](https://arena-ch0-fundamentals.streamlit.app/[0.3]_ResNets#training-loop) during the first week, this should all be familiar to you. If not, you can skim that section for an overview of the key concepts. The start of the **Training loop** section is most important, and the subsections on [Modularisation](https://arena-ch0-fundamentals.streamlit.app/[0.3]_ResNets#modularisation) and [dataclasses](https://arena-ch0-fundamentals.streamlit.app/[0.3]_ResNets#aside-dataclasses) are also very useful. Lastly, we'll also be using Weights and Biases to train our model - you can read about how to use it [here](https://arena-ch0-fundamentals.streamlit.app/[0.4]_Optimization#what-is-weights-and-biases). Here are (roughly) all the things you should know for the following exercises:\n",
        "                \n",
        "* The key parts of a gradient update step are:\n",
        "    * Calculating the (cross-entropy) loss between a model's output and the true labels,\n",
        "    * `loss.backward()` - calculate gradients of the loss with respect to the model parameters,\n",
        "    * `optimizer.step()` - update the model parameters using the gradients,\n",
        "    * `optimizer.zero_grad()` - zero the gradients so they don't accumulate.\n",
        "* We can nicely package up training loops into a class, which includes methods for training and validation steps among other things. This helps with writing code that can be reused in different contexts.\n",
        "* We can use dataclasses to store all the arguments relevant to training in one place, and then pass them to our trainer class. Autocompletion is one nice bonus of this!\n",
        "    * Be careful of scope here, you want to make sure you're referring to `self.args` within the trainer class, rather than the global `args`.\n",
        "* You can use Weights and Biases to track experiments and log relevant variables. The three essential functions are:\n",
        "    * `wandb.init()` - initialize a new run, takes arguments `project`, `name` and `config` (among others).\n",
        "    * `wandb.log()` - log a dictionary of variables, e.g. `{\"loss\": loss}`. Also takes a `step` argument.\n",
        "    * `wandb.finish()` - called at the end of training (no arguments)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1plL9rECTAK"
      },
      "source": [
        "### Exercise - write training loop\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵🔵🔵🔵⚪\n",
        ">\n",
        "> You should spend up to 10-20 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "You should fill in the methods below. Some guidance:\n",
        "\n",
        "* Remember we were able to calculate cross entropy loss using the `get_log_probs` function in the previous section.\n",
        "* You should use the optimizer `t.optim.AdamW` (Adam with weight decay), and with hyperparameters `lr` and `weight_decay` taken from your `TransformerTrainingArgs` dataclass instance.\n",
        "* We've given you the argument `max_steps_per_epoch`, a hacky way of making sure the training phase in each epoch doesn't go on for too long. You can terminate each training phase after this many steps. It's set to a default value that should lead to a very short run demonstrating nontrivial model performance.\n",
        "* Remember to move tokens to your device, via `tokens.to(device)` (this should be a global variable, defined at the top of your notebook).\n",
        "* You can refer back to the training loops from the [previous chapter of the course](https://arena-ch0-fundamentals.streamlit.app/[0.3]_ResNets#training-loop) if you'd like.\n",
        "* We've also provided an instance of the `TransformerSampler` class so you can generate text from your model during training to see how it's doing. We will cover how sampling works in the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843,
          "referenced_widgets": [
            "96f679f4074d4be4b1ff8c655dc5184b",
            "ae9a5fb2dd02432fa564a2cffc750ac5",
            "c7b78cdeac994b38b1abde1f436c75e7",
            "5b1ba200c5f842d4aba6acbf7567672d",
            "9f776b172f8340a88b28d97acb3bd455",
            "2ecfd3ec80164e09a11ac721e4f52033",
            "967298b879554579a84803ce773ac023",
            "9b91b270bd2144e7bc7e43c1080e46a5",
            "e936eb45b6d0409d83705d1ac1c07392",
            "55ee51101fcc41e7974d4b351dfb886e",
            "d4204f5c79144963a03a6d560922928f"
          ]
        },
        "id": "LbKiKvH-CTAK",
        "outputId": "e33a4134-88c8-4c21-924f-3b672d25cf3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 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\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Invalid choice\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " no\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Invalid choice\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaxhzhang119\u001b[0m (\u001b[33mmaxhzhang119-irvington-high-school\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/chapter1_transformer_interp/exercises/wandb/run-20260111_182435-o3g9vqe8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/maxhzhang119-irvington-high-school/day1-demotransformer/runs/o3g9vqe8' target=\"_blank\">resilient-breeze-1</a></strong> to <a href='https://wandb.ai/maxhzhang119-irvington-high-school/day1-demotransformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/maxhzhang119-irvington-high-school/day1-demotransformer' target=\"_blank\">https://wandb.ai/maxhzhang119-irvington-high-school/day1-demotransformer</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/maxhzhang119-irvington-high-school/day1-demotransformer/runs/o3g9vqe8' target=\"_blank\">https://wandb.ai/maxhzhang119-irvington-high-school/day1-demotransformer/runs/o3g9vqe8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96f679f4074d4be4b1ff8c655dc5184b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3207964822.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerTrainingArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3207964822.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 progress_bar.set_description(\n",
            "\u001b[0;32m/tmp/ipython-input-3207964822.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mget_log_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "class TransformerTrainer:\n",
        "    def __init__(self, args: TransformerTrainingArgs, model: DemoTransformer):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.args = args\n",
        "        self.sampler = solutions.TransformerSampler(self.model, reference_gpt2.tokenizer)\n",
        "        self.optimizer = t.optim.AdamW(\n",
        "            self.model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
        "        )\n",
        "        self.step = 0\n",
        "\n",
        "        self.train_loader = DataLoader(\n",
        "            dataset_dict[\"train\"],\n",
        "            batch_size=args.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=4,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "        self.test_loader = DataLoader(\n",
        "            dataset_dict[\"test\"],\n",
        "            batch_size=args.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=4,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "\n",
        "    def training_step(self, batch: dict[str, Int[Tensor, \"batch seq\"]]) -> Float[Tensor, \"\"]:\n",
        "        \"\"\"\n",
        "        Calculates the loss on the tokens in the batch, performs a gradient update step, and logs the loss.\n",
        "\n",
        "        Remember that `batch` is a dictionary with the single key 'tokens'.\n",
        "        \"\"\"\n",
        "        tokens = batch[\"tokens\"].to(device)\n",
        "        logits = self.model(tokens)\n",
        "        loss = -get_log_probs(logits,tokens).mean()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "        self.step += 1\n",
        "        wandb.log({\"train_loss\": loss}, step=self.step)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def evaluate(self) -> float:\n",
        "        \"\"\"\n",
        "        Evaluate the model on the test set and return the accuracy.\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        total_correct, total_samples = 0, 0\n",
        "        for batch in self.test_loader:\n",
        "            tokens = batch[\"tokens\"].to(device)\n",
        "            logits: Tensor = self.model(tokens)[:,:-1]\n",
        "            prediction = logits.argmax(dim=-1)\n",
        "            target = tokens[:,1:]\n",
        "            total_correct += (prediction == target).sum().item()\n",
        "            total_samples += target.size(0) * (target.size(1) - 1)\n",
        "\n",
        "        accuracy = total_correct / total_samples\n",
        "\n",
        "        self.model.train()\n",
        "        return accuracy\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Trains the model, for `self.args.epochs` epochs. Also handles wandb initialisation, and early stopping\n",
        "        for each epoch at `self.args.max_steps_per_epoch` steps.\n",
        "        \"\"\"\n",
        "        wandb.init(project=self.args.wandb_project, name=self.args.wandb_name, config=self.args)\n",
        "        accuracy = np.nan\n",
        "\n",
        "        progress_bar = tqdm(total=self.args.max_steps_per_epoch * self.args.epochs)\n",
        "\n",
        "        for epoch in range(self.args.epochs):\n",
        "            for i, batch in enumerate(self.train_loader):\n",
        "                loss = self.training_step(batch)\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description(\n",
        "                    f\"Epoch {epoch + 1}, loss: {loss:.3f}, accuracy: {accuracy:.3f}\"\n",
        "                )\n",
        "                if i >= self.args.max_steps_per_epoch:\n",
        "                    break\n",
        "\n",
        "            accuracy = self.evaluate()\n",
        "            sample_text = self.sampler.sample(\"Once upon a time\", max_tokens_generated=50)\n",
        "            print(sample_text)\n",
        "\n",
        "        wandb.finish()\n",
        "\n",
        "\n",
        "# See the full run here: https://api.wandb.ai/links/dquarel/nrxuwnv7\n",
        "model = DemoTransformer(model_cfg).to(device)\n",
        "args = TransformerTrainingArgs()\n",
        "trainer = TransformerTrainer(args, model)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3sH1oFZCTAK"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "class TransformerTrainer:\n",
        "    def __init__(self, args: TransformerTrainingArgs, model: DemoTransformer):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.args = args\n",
        "        self.sampler = solutions.TransformerSampler(self.model, reference_gpt2.tokenizer)\n",
        "        self.optimizer = t.optim.AdamW(\n",
        "            self.model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
        "        )\n",
        "        self.step = 0\n",
        "\n",
        "        self.train_loader = DataLoader(\n",
        "            dataset_dict[\"train\"],\n",
        "            batch_size=args.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=4,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "        self.test_loader = DataLoader(\n",
        "            dataset_dict[\"test\"],\n",
        "            batch_size=args.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=4,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "\n",
        "    def training_step(self, batch: dict[str, Int[Tensor, \"batch seq\"]]) -> Float[Tensor, \"\"]:\n",
        "        \"\"\"\n",
        "        Calculates the loss on the tokens in the batch, performs a gradient update step, and logs the loss.\n",
        "\n",
        "        Remember that `batch` is a dictionary with the single key 'tokens'.\n",
        "        \"\"\"\n",
        "        tokens = batch[\"tokens\"].to(device)\n",
        "        logits = self.model(tokens)\n",
        "        loss = -get_log_probs(logits, tokens).mean()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "        self.step += 1\n",
        "        wandb.log({\"train_loss\": loss}, step=self.step)\n",
        "        return loss\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def evaluate(self) -> float:\n",
        "        \"\"\"\n",
        "        Evaluate the model on the test set and return the accuracy.\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        total_correct, total_samples = 0, 0\n",
        "\n",
        "        for batch in tqdm(self.test_loader, desc=\"Evaluating\"):\n",
        "            tokens = batch[\"tokens\"].to(device)\n",
        "            logits: Tensor = self.model(tokens)[:, :-1]\n",
        "            predicted_tokens = logits.argmax(dim=-1)\n",
        "            total_correct += (predicted_tokens == tokens[:, 1:]).sum().item()\n",
        "            total_samples += tokens.size(0) * (tokens.size(1) - 1)\n",
        "\n",
        "        accuracy = total_correct / total_samples\n",
        "        wandb.log({\"accuracy\": accuracy}, step=self.step)\n",
        "        self.model.train()\n",
        "        return accuracy\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Trains the model, for `self.args.epochs` epochs. Also handles wandb initialisation, and early stopping\n",
        "        for each epoch at `self.args.max_steps_per_epoch` steps.\n",
        "        \"\"\"\n",
        "        wandb.init(project=self.args.wandb_project, name=self.args.wandb_name, config=self.args)\n",
        "        accuracy = np.nan\n",
        "\n",
        "        progress_bar = tqdm(total=self.args.max_steps_per_epoch * self.args.epochs)\n",
        "\n",
        "        for epoch in range(self.args.epochs):\n",
        "            for i, batch in enumerate(self.train_loader):\n",
        "                loss = self.training_step(batch)\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description(\n",
        "                    f\"Epoch {epoch + 1}, loss: {loss:.3f}, accuracy: {accuracy:.3f}\"\n",
        "                )\n",
        "                if i >= self.args.max_steps_per_epoch:\n",
        "                    break\n",
        "\n",
        "            accuracy = self.evaluate()\n",
        "            sample_text = self.sampler.sample(\"Once upon a time\", max_tokens_generated=50)\n",
        "            print(sample_text)\n",
        "\n",
        "        wandb.finish()\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JesAH8FNCTAK"
      },
      "source": [
        "<!-- Note - this section of the course used to use PyTorch Lightning, but this has now been taken out. If you want, you can look at the old version of the training code which used PyTorch Lightning in the dropdown below.\n",
        "\n",
        "<details>\n",
        "<summary>PyTorch Lighting training loop</summary>\n",
        "\n",
        "```python\n",
        "class LitTransformer(pl.LightningModule):\n",
        "\tdef __init__(self, args: TransformerTrainingArgs, model: DemoTransformer, data_loader: DataLoader):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.model = model\n",
        "\t\tself.cfg = model.cfg\n",
        "\t\tself.args = args\n",
        "\t\tself.data_loader = data_loader\n",
        "\n",
        "\tdef forward(self, tokens: Int[Tensor, \"batch position\"]) -> Float[Tensor, \"batch position d_vocab\"]:\n",
        "\t\tlogits = self.model(tokens)\n",
        "\t\treturn logits\n",
        "\n",
        "\tdef training_step(self, batch: Dict[str, Tensor], batch_idx: int) -> Float[Tensor, \"\"]:\n",
        "\t\t'''\n",
        "\t\tHere you compute and return the training loss and some additional metrics for e.g.\n",
        "\t\tthe progress bar or logger.\n",
        "\t\t'''\n",
        "\t\ttokens = batch[\"tokens\"].to(device)\n",
        "\t\tlogits = self.model(tokens)\n",
        "\t\tloss = -get_log_probs(logits, tokens).mean()\n",
        "\t\tself.log(\"train_loss\", loss)\n",
        "\t\treturn loss\n",
        "\n",
        "\tdef configure_optimizers(self):\n",
        "\t\t'''\n",
        "\t\tChoose what optimizers and learning-rate schedulers to use in your optimization.\n",
        "\t\t'''\n",
        "\t\toptimizer = t.optim.AdamW(self.model.parameters(), lr=self.args.lr, weight_decay=self.args.weight_decay)\n",
        "\t\treturn optimizer\n",
        "\n",
        "\tdef train_dataloader(self):\n",
        "\t\treturn self.data_loader\n",
        "\n",
        "\n",
        "litmodel = LitTransformer(args, model, data_loader)\n",
        "logger = WandbLogger(save_dir=args.log_dir, project=args.log_name, name=args.run_name)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=args.max_epochs,\n",
        "    logger=logger,\n",
        "    log_every_n_steps=args.log_every_n_steps\n",
        ")\n",
        "trainer.fit(model=litmodel, train_dataloaders=litmodel.data_loader)\n",
        "wandb.finish()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Explanation for why PyTorch Lightning is no longer used</summary>\n",
        "\n",
        "TLDR - it provides nice modularization and saving of code, but it abstracts away a lot of the details of training loops, and so isn't very useful for educational purposes. Also, it imposes a lot of structure on how the training loops work without allowing for much flexibility, and lots of the code we'll write later (e.g. linear probes or RL) doesn't fit well into this framework. However, it can be a very useful tool to learn about once you've got the basics down and you're looking to benefit from the suite of extra features it provides.\n",
        "\n",
        "</details> -->\n",
        "\n",
        "When you run the code for the first time, you'll have to login to Weights and Biases, and paste an API key into VSCode. After this is done, your Weights and Biases training run will start. It'll give you a lot of output text, one line of which will look like:\n",
        "\n",
        "```\n",
        "View run at https://wandb.ai/<USERNAME>/<PROJECT-NAME>/runs/<RUN-NAME>\n",
        "```\n",
        "\n",
        "which you can click on to visit the run page.\n",
        "\n",
        "> Note - to see the plots more clearly in Weights and Biases, you can click on the **edit panel** of your plot (the small pencil symbol at the top-right), then move the **smoothing** slider to the right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2w4dgDuCTAK"
      },
      "source": [
        "### A note on this loss curve (optional)\n",
        "\n",
        "\n",
        "What's up with the shape of our loss curve? It seems like we start at around 10-11, drops down very fast, but then levels out. It turns out, this is all to do with the kinds of algorithms the model learns during training.\n",
        "\n",
        "When it starts out, your model will be outputting random noise, which might look a lot like \"predict each token with approximately uniform probability\", i.e. $Q(x) = 1/d_\\text{vocab}$ for all $x$. This gives us a cross entropy loss of $\\log (d_\\text{vocab})$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wlc0-JNeCTAK"
      },
      "outputs": [],
      "source": [
        "d_vocab = model.cfg.d_vocab\n",
        "\n",
        "print(f\"d_vocab = {d_vocab}\")\n",
        "print(f\"Cross entropy loss on uniform distribution = {math.log(d_vocab):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQMaeC1BCTAK"
      },
      "source": [
        "The next thing we might expect the model to learn is the frequencies of words in the english language. After all, small common tokens like `\" and\"` or `\" the\"` might appear much more frequently than others. This would give us an average cross entropy loss of:\n",
        "\n",
        "$$\n",
        "- \\sum_x p_x \\log p_x\n",
        "$$\n",
        "\n",
        "where $p_x$ is the actual frequency of the word in our training data.\n",
        "\n",
        "We can evaluate this quantity as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGskkK4cCTAK"
      },
      "outputs": [],
      "source": [
        "toks = tokenized_dataset[:][\"tokens\"].flatten()\n",
        "\n",
        "d_vocab = model.cfg.d_vocab\n",
        "freqs = t.bincount(toks, minlength=d_vocab)\n",
        "probs = freqs.float() / freqs.sum()\n",
        "\n",
        "distn = t.distributions.categorical.Categorical(probs=probs)\n",
        "entropy = distn.entropy()\n",
        "\n",
        "print(f\"Entropy of training data = {entropy:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8zIFl9zCTAL"
      },
      "source": [
        "After unigram frequencies, the next thing our model usually learns is **bigram frequencies** (i.e. the frequency of pairs of adjacent tokens in the training data). For instance, `\"I\"` and `\" am\"` are common tokens, but their bigram frequency is much higher than it would be if they occurred independently. Bigram frequencies actually take you pretty far, since they also help with:\n",
        "\n",
        "* Some simple grammatical rules (e.g. a full stop being followed by a capitalized word)\n",
        "* Weird quirks of tokenization (e.g. `\" manip\"` being followed by `\"ulative\"`)\n",
        "* Common names (e.g. `\"Barack\"` being followed by `\" Obama\"`)\n",
        "\n",
        "\n",
        "After approximating bigram frequencies, we need to start using smarter techniques, like trigrams (which can only be implemented using attention heads), **induction heads** (which we'll learn a lot more about in the next set of exercises!), and fact memorization or more basic grammar and syntax rules. Marginal improvements start getting harder around this point, leading to a flattening of our loss curve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc3or7WgCTAL"
      },
      "source": [
        "### Exercise (optional) - log completions\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵⚪⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 20-40 minutes on this exercise, if you choose to attempt it.\n",
        "> Note, you might want to come back to this exercise *after* you learn how sampling works.\n",
        "> ```\n",
        "\n",
        "Choose a handful of prompts, and log the model's completions on those sentences. We recommend you do this with a lower frequency than loss is logged (e.g. once every 10-100 batches).\n",
        "\n",
        "The `wandb` syntax for logging text is pretty simple. Firstly, you can just print output as stdout and this is also logged to Weights & Biases (you can find it under the \"Logs\" section of your run). Alternatively, you can log data in the form of a table, and have it appear next to your other charts:\n",
        "\n",
        "```python\n",
        "wandb.log({\"completions_table\": wandb.Table(\n",
        "    data = data,\n",
        "    columns = [\"epoch\", \"step\", \"text\"]\n",
        ")})\n",
        "```\n",
        "\n",
        "where `data` is a list of length-3 lists, with each list containing (epoch, step, text). If you choose this option, we recommend logging the table less frequently than you're sampling from the model, to make sure you're not sending too much data (because unfortunately wandb doesn't have methods to incrementally update the table during logging).\n",
        "\n",
        "If you want to try this before going through the sampling exercises (which are quite long!), you can use the code below to sample output from the model. Note that the `TransformerSampler` object is already in inference mode, so you don't need to worry about this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8FcnH4yCTAL"
      },
      "outputs": [],
      "source": [
        "def sampling_fn(model: DemoTransformer, prompt: str) -> str:\n",
        "    sampler = solutions.TransformerSampler(model, reference_gpt2.tokenizer)\n",
        "    output = sampler.sample(prompt, temperature=0.7, top_p=0.95, max_tokens_generated=16)\n",
        "    return output\n",
        "\n",
        "\n",
        "model = DemoTransformer(model_cfg).to(device)\n",
        "\n",
        "# Should be entirely random, because it uses a newly initialized model\n",
        "print(sampling_fn(model, prompt=\"John and Mary went to the\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPllv1flCTAL"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE - rewrite the TransformerTrainer.train method, so that it logs completions\n",
        "\n",
        "\n",
        "prompt_list = [\n",
        "    \"Eliezer Shlomo Yudkowsky (born September 11, 1979) is an American decision and artificial intelligence (AI) theorist and writer, best known for\",\n",
        "    \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\",\n",
        "    \"John and Mary went to the\",\n",
        "]\n",
        "\n",
        "model = DemoTransformer(model_cfg).to(device)\n",
        "args = TransformerTrainingArgsLogText()\n",
        "trainer = TransformerTrainer(args, model)\n",
        "trainer.train(sampling_fn, prompt_list)\n",
        "# Read full report here - https://api.wandb.ai/links/callum-mcdougall/5ex16e5w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUS2t5XMCTAL"
      },
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "@dataclass\n",
        "class TransformerTrainingArgsLogText(TransformerTrainingArgs):\n",
        "    text_sample_freq: int = 20\n",
        "    table_log_freq: int = 200\n",
        "\n",
        "    def __post_init__(self):\n",
        "        assert self.table_log_freq >= self.text_sample_freq, (\n",
        "            \"You should log the table less frequently than you add text to it.\"\n",
        "        )\n",
        "\n",
        "\n",
        "def train_log_text(self: TransformerTrainer, sampling_fn: Callable, prompt_list: list[str]):\n",
        "    \"\"\"\n",
        "    Trains the model, for `self.args.epochs` epochs. Also handles wandb initialisation, and early stopping\n",
        "    for each epoch at `self.args.max_steps_per_epoch` steps.\n",
        "\n",
        "    This also takes 2 extra arguments:\n",
        "        sampling_fn: function which takes model & a single prompt (i.e. text string) and returns text string output\n",
        "        prompt_list: list of prompts we'll log output on\n",
        "    \"\"\"\n",
        "    wandb.init(project=self.args.wandb_project, name=self.args.wandb_name, config=self.args)\n",
        "    accuracy = np.nan\n",
        "    progress_bar = tqdm(total=self.args.max_steps_per_epoch * self.args.epochs)\n",
        "\n",
        "    # Create a list for storing data\n",
        "    completions_list = []\n",
        "\n",
        "    for epoch in range(self.args.epochs):\n",
        "        for i, batch in enumerate(self.train_loader):\n",
        "            loss = self.training_step(batch)\n",
        "            progress_bar.update()\n",
        "            progress_bar.set_description(\n",
        "                f\"Epoch {epoch + 1}, loss: {loss:.3f}, accuracy: {accuracy:.3f}\"\n",
        "            )\n",
        "\n",
        "            # Control the adding of text to the table, and the logging of text\n",
        "            if self.step % self.args.text_sample_freq == 0:\n",
        "                text_completions = [sampling_fn(self.model, prompt) for prompt in prompt_list]\n",
        "                completions_list.append([epoch, self.step, *text_completions])\n",
        "            if self.step % self.args.table_log_freq == 0:\n",
        "                wandb.log(\n",
        "                    {\n",
        "                        \"completions_table\": wandb.Table(\n",
        "                            data=completions_list,\n",
        "                            columns=[\n",
        "                                \"epoch\",\n",
        "                                \"step\",\n",
        "                                *[f\"prompt_{i}\" for i in range(len(prompt_list))],\n",
        "                            ],\n",
        "                        )\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            if i >= self.args.max_steps_per_epoch:\n",
        "                break\n",
        "\n",
        "        accuracy = self.evaluate()\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "\n",
        "TransformerTrainer.train = train_log_text\n",
        "\n",
        "\n",
        "prompt_list = [\n",
        "    \"Eliezer Shlomo Yudkowsky (born September 11, 1979) is an American decision and artificial intelligence (AI) theorist and writer, best known for\",\n",
        "    \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\",\n",
        "    \"John and Mary went to the\",\n",
        "]\n",
        "\n",
        "model = DemoTransformer(model_cfg).to(device)\n",
        "args = TransformerTrainingArgsLogText()\n",
        "trainer = TransformerTrainer(args, model)\n",
        "trainer.train(sampling_fn, prompt_list)\n",
        "# Read full report here - https://api.wandb.ai/links/callum-mcdougall/5ex16e5w\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOZrHSAUCTAL"
      },
      "source": [
        "You shouldn't expect to see perfect logical coherence from your model, but you should at least see that it respects basic word frequencies, and follows basic rules of grammar some of the time. Hopefully this gives some perspective on how difficult training a transformer can be!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2pgI9H0CTAL"
      },
      "source": [
        "# 4️⃣ Sampling from a Transformer\n",
        "\n",
        "> ##### Learning Objectives\n",
        ">\n",
        "> * Learn how to sample from a transformer\n",
        ">     * This includes basic methods like greedy search or top-k, and more advanced methods like beam search\n",
        "> * Learn how to cache the output of a transformer, so that it can be used to generate text more efficiently\n",
        ">     * Optionally, rewrite your sampling functions to make use of your caching methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trzCrW4oCTAL"
      },
      "source": [
        "Let's discuss how we might go about producing output from a transformer.\n",
        "\n",
        "One obvious method to sample tokens from a distribution would be to always take the token assigned the highest probability. But this can lead to some boring and repetitive outcomes, and at worst it can lock our transformer's output into a loop.\n",
        "\n",
        "First, you should read HuggingFace's blog post [How to generate text: using different decoding methods for language generation with Transformers](https://huggingface.co/blog/how-to-generate). Once you've done that, you can start the exercises below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HjNCfyLCTAL"
      },
      "source": [
        "## `TransformerSampler` class\n",
        "\n",
        "Below, we've given you the `TransformerSampler` class. This contains the following important methods:\n",
        "\n",
        "- `sample`, which is the highest-level method. It repeatedly calls `sample_next_token` to generate new tokens, until one of the termination criteria is met.\n",
        "- `sample_next_token`, which samples a single new token based on some hyperparameters. This might involve various different sampling methods and techniques e.g. temperature scaling, top-k sampling, top-p sampling, etc.\n",
        "- A set of other methods, which apply the previously mentioned sampling methods and techniques.\n",
        "\n",
        "You can see how `sample_next_token` works, and as an example how greedy sampling is implemented via `greedy_search` - we just continually take the tokens with the highest logits at each step.\n",
        "\n",
        "<details>\n",
        "<summary>Question - why do you think <code>temperature=0.0</code> correspond to greedy sampling?</summary>\n",
        "\n",
        "To apply a temperature to our sampling (as we'll see later) means to scale all logits by `(1 / temperature)`. The basic intuition here is:\n",
        "\n",
        "* A higher temperature means a smaller scale factor, so the logits all approach zero, i.e. uniform distribution, and the sampling process is a lot more random (producing more diverse and varied outputs)\n",
        "* A lower temperature means a larger scale factor, so the logits all approach infinity, i.e. a dirac delta function, and the sampling process is a lot more deterministic (producing less varied output)\n",
        "\n",
        "As temperature gets close to zero, the difference between the largest logit and second largest logit becomes very large, so the distribution tends to \"probability of 1 on the highest-likelihood token\", i.e. greedy sampling. You can derive this formally if you prefer.\n",
        "</details>\n",
        "\n",
        "In the next exercise you'll implement the `sample` method, and then you'll go on to implement all the other methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZmwQ_7rCTAL"
      },
      "source": [
        "### Exercise - implement `sample`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴⚪\n",
        "> Importance: 🔵🔵🔵⚪⚪\n",
        ">\n",
        "> You should spend up to 25-40 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "The `sample` method generates new tokens autoregressively, by repeatedly:\n",
        "\n",
        "- Passing the current sequence of tokens through the model to get logits,\n",
        "- Using some sampling technique to select a new token, i.e. `sample_next_token(input_ids, logits, **kwargs)`,\n",
        "- Appending this new token to the input sequence,\n",
        "- Repeating the process until one of the termination criteria is met: either we generate `max_tokens_generated` new tokens, or we generate the end-of-sequence token (which we can access via `self.tokenizer.eos_token_id`).\n",
        "\n",
        "Lastly, we use the `tokenizer.decode` method to return the sampled string. You're also invited to use the `verbose` argument, for printing the decoded sequences while they're being generated (this can help with debugging).\n",
        "\n",
        "Below is some code which tests your sampling function by performing greedy sampling (which means always choosing the most likely next token at each step).\n",
        "\n",
        "A few hints:\n",
        "\n",
        "- Don't forget about tensor shapes! Your model's input should always have a batch dimension, i.e. it should be shape `(1, seq_len)`.\n",
        "- The `sample_next_token` method will return an integer, so make sure you wrap this in a tensor before concatenating it to the end of your input IDs.\n",
        "- Also remember to have your tensors be on the same device (we have a global `device` variable).\n",
        "- Remember to put your model in evaluation mode, using `model.eval()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqgfIOsECTAL"
      },
      "outputs": [],
      "source": [
        "class TransformerSampler:\n",
        "    def __init__(self, model: DemoTransformer, tokenizer: GPT2TokenizerFast):\n",
        "        self.model = model\n",
        "        self.cfg = model.cfg\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def sample(self, prompt: str, max_tokens_generated=100, verbose=False, **kwargs) -> str:\n",
        "        \"\"\"\n",
        "        Returns a string of autoregressively generated text, starting from the prompt.\n",
        "\n",
        "        Sampling terminates at max_tokens_generated, or when the model generates an end-of-sequence token. kwargs are\n",
        "        passed to sample_next_token, to give detailed instructions on how new tokens are chosen.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @staticmethod\n",
        "    def sample_next_token(\n",
        "        input_ids: Int[Tensor, \"seq_len\"],\n",
        "        logits: Float[Tensor, \"d_vocab\"],\n",
        "        temperature=1.0,\n",
        "        top_k=0,\n",
        "        top_p=0.0,\n",
        "        frequency_penalty=0.0,\n",
        "        seed=None,\n",
        "    ) -> int:\n",
        "        assert input_ids.ndim == 1, \"input_ids should be a 1D sequence of token ids\"\n",
        "        assert temperature >= 0, \"Temperature should be non-negative\"\n",
        "        assert 0 <= top_p <= 1.0, \"Top-p must be a probability\"\n",
        "        assert 0 <= top_k, \"Top-k must be non-negative\"\n",
        "        assert not (top_p != 0 and top_k != 0), \"At most one of top-p and top-k supported\"\n",
        "\n",
        "        # Set random seeds for reproducibility\n",
        "        if seed is not None:\n",
        "            t.manual_seed(seed)\n",
        "            np.random.seed(seed)\n",
        "\n",
        "        # Apply all the specialized sampling methods\n",
        "        if temperature == 0:\n",
        "            return TransformerSampler.greedy_search(logits)\n",
        "        elif temperature != 1.0:\n",
        "            logits = TransformerSampler.apply_temperature(logits, temperature)\n",
        "        if frequency_penalty != 0.0:\n",
        "            logits = TransformerSampler.apply_frequency_penalty(\n",
        "                input_ids, logits, frequency_penalty\n",
        "            )\n",
        "        if top_k > 0:\n",
        "            return TransformerSampler.sample_top_k(logits, top_k)\n",
        "        if top_p > 0.0:\n",
        "            return TransformerSampler.sample_top_p(logits, top_p)\n",
        "        return TransformerSampler.sample_basic(logits)\n",
        "\n",
        "    @staticmethod\n",
        "    def greedy_search(logits: Float[Tensor, \"d_vocab\"]) -> int:\n",
        "        \"\"\"\n",
        "        Returns the most likely token (as an int).\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_temperature(\n",
        "        logits: Float[Tensor, \"d_vocab\"], temperature: float\n",
        "    ) -> Float[Tensor, \"d_vocab\"]:\n",
        "        \"\"\"\n",
        "        Applies temperature scaling to the logits.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_frequency_penalty(\n",
        "        input_ids: Int[Tensor, \"seq_len\"], logits: Float[Tensor, \"d_vocab\"], freq_penalty: float\n",
        "    ) -> Float[Tensor, \"d_vocab\"]:\n",
        "        \"\"\"\n",
        "        Applies a frequency penalty to the logits.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @staticmethod\n",
        "    def sample_basic(logits: Float[Tensor, \"d_vocab\"]) -> int:\n",
        "        \"\"\"\n",
        "        Samples from the distribution defined by the logits.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @staticmethod\n",
        "    def sample_top_k(logits: Float[Tensor, \"d_vocab\"], k: int) -> int:\n",
        "        \"\"\"\n",
        "        Samples from the top k most likely tokens.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @staticmethod\n",
        "    def sample_top_p(\n",
        "        logits: Float[Tensor, \"d_vocab\"], top_p: float, min_tokens_to_keep: int = 1\n",
        "    ) -> int:\n",
        "        \"\"\"\n",
        "        Samples from the most likely tokens which make up at least p cumulative probability.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def beam_search(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        num_return_sequences: int,\n",
        "        num_beams: int,\n",
        "        max_new_tokens: int,\n",
        "        no_repeat_ngram_size: int | None = None,\n",
        "    ) -> list[tuple[float, str]]:\n",
        "        \"\"\"\n",
        "        Implements a beam search, by repeatedly performing the `generate` and `filter` steps (starting from the initial\n",
        "        prompt) until either of the two stopping criteria are met: (1) we've generated `max_new_tokens` tokens, or (2)\n",
        "        we've generated `num_returns_sequences` terminating sequences.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "t.set_grad_enabled(False)  # gradients are not necessary for sampling\n",
        "\n",
        "model = DemoTransformer(Config()).to(device)\n",
        "model.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
        "tokenizer = reference_gpt2.tokenizer\n",
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "prompt = \"Jingle bells, jingle bells, jingle all the way\"\n",
        "print(f\"Testing greedy decoding\\nPrompt:   {prompt!r}\")\n",
        "\n",
        "expected = \"Jingle bells, jingle bells, jingle all the way up to the top of the mountain.\"\n",
        "output = sampler.sample(prompt, max_tokens_generated=8, temperature=0.0)\n",
        "\n",
        "print(f\"Expected: {expected!r}\\nActual:   {output!r}\\n\")\n",
        "assert output == expected\n",
        "\n",
        "print(\"Tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBMGfzlNCTAL"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "@t.inference_mode()\n",
        "def sample(self, prompt: str, max_tokens_generated=100, verbose=False, **kwargs):\n",
        "    \"\"\"\n",
        "    Returns a string of autoregressively generated text, starting from the prompt.\n",
        "\n",
        "    Sampling terminates at max_tokens_generated, or when the model generates an end-of-sequence token. kwargs are\n",
        "    passed to sample_next_token, to give detailed instructions on how new tokens are chosen.\n",
        "    \"\"\"\n",
        "    self.model.eval()\n",
        "    input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(device)[0]\n",
        "\n",
        "    for i in range(max_tokens_generated):\n",
        "        # Get new logits (make sure we don't pass in more tokens than the model's context length)\n",
        "        logits = self.model(input_ids[None, -self.cfg.n_ctx :])\n",
        "        # We only take logits for the last token, because this is what we're sampling\n",
        "        logits = logits[0, -1]\n",
        "        # Get next token (as a tensor of size (1, 1) so we can concat it to input_ids)\n",
        "        next_token = t.tensor([TransformerSampler.sample_next_token(input_ids, logits, **kwargs)], device=device)\n",
        "        # Create new input ids string, with shape (1, old_seq_len + 1)\n",
        "        input_ids = t.cat([input_ids, next_token], dim=-1)\n",
        "        # Print out results, if required\n",
        "        if verbose:\n",
        "            print(self.tokenizer.decode(input_ids), end=\"\\r\")\n",
        "        # If our new token was the end-of-text token, stop\n",
        "        if next_token == getattr(self.tokenizer, \"eos_token_id\", None):\n",
        "            break\n",
        "\n",
        "    return self.tokenizer.decode(input_ids)\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufRoy8fxCTAL"
      },
      "source": [
        "## Sampling with Categorical\n",
        "\n",
        "Now, we'll move into implementing specific sampling methods. In each of these cases, you should return to the class definition above and fill in the corresponding method.\n",
        "\n",
        "PyTorch provides a [`distributions`](https://pytorch.org/docs/stable/distributions.html#distribution) package with a number of convenient methods for sampling from various distributions.\n",
        "\n",
        "For now, we just need [`t.distributions.categorical.Categorical`](https://pytorch.org/docs/stable/distributions.html#categorical). Use this to implement `sample_basic`, which just samples from the provided logits (which may have already been modified by the temperature and frequency penalties).\n",
        "\n",
        "Note that this will be slow since we aren't batching the samples, but don't worry about speed for now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPxdFHaACTAL"
      },
      "source": [
        "### Exercise - `sample_basic`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 5-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement basic sampling in the `TransformerSampler` class above (i.e. the `sample_basic` method), then run the code below to verify your solution works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDiSSxdhCTAL"
      },
      "outputs": [],
      "source": [
        "prompt = \"John and Mary went to the\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "logits = model(input_ids)[0, -1]\n",
        "\n",
        "expected_top_5 = {\n",
        "    \" church\": 0.0648,\n",
        "    \" house\": 0.0367,\n",
        "    \" temple\": 0.0145,\n",
        "    \" same\": 0.0104,\n",
        "    \" Church\": 0.0097,\n",
        "}\n",
        "frequency_of_top_5 = defaultdict(int)\n",
        "\n",
        "N = 10_000\n",
        "for _ in tqdm(range(N)):\n",
        "    token = TransformerSampler.sample_next_token(input_ids.squeeze(), logits)\n",
        "    frequency_of_top_5[tokenizer.decode(token)] += 1\n",
        "\n",
        "for word in expected_top_5:\n",
        "    expected_freq = expected_top_5[word]\n",
        "    observed_freq = frequency_of_top_5[word] / N\n",
        "    print(\n",
        "        f\"Word: {word!r:<9}. Expected freq {expected_freq:.4f}, observed freq {observed_freq:.4f}\"\n",
        "    )\n",
        "    assert abs(observed_freq - expected_freq) < 0.01, (\n",
        "        \"Try increasing N if this fails by a small amount.\"\n",
        "    )\n",
        "\n",
        "print(\"Tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQHqx--jCTAL"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "@staticmethod\n",
        "def sample_basic(logits: Float[Tensor, \"d_vocab\"]) -> int:\n",
        "    \"\"\"\n",
        "    Samples from the distribution defined by the logits.\n",
        "    \"\"\"\n",
        "    sampled_token = t.distributions.categorical.Categorical(logits=logits).sample()\n",
        "    return sampled_token.item()\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_hGbasVCTAL"
      },
      "source": [
        "### Exercise - `apply_temperature`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴⚪⚪⚪⚪\n",
        "> Importance: 🔵🔵⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 5-10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Temperature sounds fancy, but it's literally just dividing the logits by the temperature. You should implement this in your `TransformerSampler` class now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug4jed3VCTAL"
      },
      "outputs": [],
      "source": [
        "logits = t.tensor([1, 2]).log()\n",
        "\n",
        "cold_logits = TransformerSampler.apply_temperature(logits, temperature=0.001)\n",
        "print('A low temperature \"sharpens\" or \"peaks\" the distribution: ', cold_logits)\n",
        "t.testing.assert_close(cold_logits, 1000.0 * logits)\n",
        "\n",
        "hot_logits = TransformerSampler.apply_temperature(logits, temperature=1000.0)\n",
        "print(\"A high temperature flattens the distribution: \", hot_logits)\n",
        "t.testing.assert_close(hot_logits, 0.001 * logits)\n",
        "\n",
        "print(\"Tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FcBv2yVCTAL"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "@staticmethod\n",
        "def apply_temperature(logits: Float[Tensor, \"d_vocab\"], temperature: float) -> Float[Tensor, \"d_vocab\"]:\n",
        "    \"\"\"\n",
        "    Applies temperature scaling to the logits.\n",
        "    \"\"\"\n",
        "    return logits / temperature\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9FRmCXSCTAL"
      },
      "source": [
        "### Exercise - `apply_frequency_penalty`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵⚪⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 10-15 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "The frequency penalty is simple as well: count the number of occurrences of each token, then subtract `freq_penalty` for each occurrence. Hint: use `t.bincount` (documentation [here](https://pytorch.org/docs/stable/generated/torch.bincount.html)) to do this in a vectorized way.\n",
        "\n",
        "You should implement the `apply_frequency_penalty` method in your `TransformerSampler` class now, then run the cell below to check your solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43nkK-dqCTAM"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm getting a <code>RuntimeError</code>; my tensor sizes don't match.</summary>\n",
        "\n",
        "Look at the documentation page for `t.bincount`. You might need to use the `minlength` argument - why?\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dXasfGqCTAM"
      },
      "outputs": [],
      "source": [
        "bieber_prompt = \"And I was like Baby, baby, baby, oh Like, Baby, baby, baby, no Like, Baby, baby, baby, oh I thought you'd always be mine, mine\"\n",
        "input_ids = tokenizer.encode(bieber_prompt, return_tensors=\"pt\")\n",
        "logits = t.ones(tokenizer.vocab_size)\n",
        "penalized_logits = TransformerSampler.apply_frequency_penalty(input_ids.squeeze(), logits, 2.0)\n",
        "\n",
        "assert penalized_logits[5156].item() == -11, (\n",
        "    \"Expected 6 occurrences of ' baby' with leading space, 1-2*6=-11\"\n",
        ")\n",
        "assert penalized_logits[14801].item() == -5, (\n",
        "    \"Expected 3 occurrences of ' Baby' with leading space, 1-2*3=-5\"\n",
        ")\n",
        "\n",
        "print(\"Tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBiSMPSsCTAM"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "@staticmethod\n",
        "def apply_frequency_penalty(\n",
        "    input_ids: Int[Tensor, \"seq_len\"], logits: Float[Tensor, \"d_vocab\"], freq_penalty: float\n",
        ") -> Float[Tensor, \"d_vocab\"]:\n",
        "    \"\"\"\n",
        "    Applies a frequency penalty to the logits.\n",
        "    \"\"\"\n",
        "    d_vocab = logits.size(0)\n",
        "    id_freqs = t.bincount(input_ids, minlength=d_vocab)\n",
        "    return logits - freq_penalty * id_freqs\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgcL_Ws1CTAM"
      },
      "source": [
        "### Sampling - Manual Testing\n",
        "\n",
        "Run the below cell to get a sense for the `temperature` and `freq_penalty` arguments. Play with your own prompt and try other values.\n",
        "\n",
        "Note: your model can generate newlines or non-printing characters, so calling `print` on generated text sometimes looks awkward on screen. You can call `repr` on the string before printing to have the string escaped nicely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O76eN2v1CTAM"
      },
      "outputs": [],
      "source": [
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "N_RUNS = 1\n",
        "your_prompt = \"Jingle bells, jingle bells, jingle all the way\"\n",
        "cases = [\n",
        "    (\"High freq penalty\", dict(frequency_penalty=100.0)),\n",
        "    (\"Negative freq penalty\", dict(frequency_penalty=-3.0)),\n",
        "    (\"Too hot!\", dict(temperature=2.0)),\n",
        "    (\"Pleasantly cool\", dict(temperature=0.7)),\n",
        "    (\"Pleasantly warm\", dict(temperature=0.9)),\n",
        "    (\"Too cold!\", dict(temperature=0.01)),\n",
        "]\n",
        "\n",
        "table = Table(\"Name\", \"Kwargs\", \"Output\", title=\"Sampling - Manual Testing\")\n",
        "\n",
        "for name, kwargs in cases:\n",
        "    for i in range(N_RUNS):\n",
        "        output = sampler.sample(your_prompt, max_tokens_generated=24, **kwargs)\n",
        "        table.add_row(name, str(kwargs), repr(output) + \"\\n\")\n",
        "\n",
        "rprint(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugM8tnWfCTAM"
      },
      "source": [
        "## Top-K Sampling\n",
        "\n",
        "Conceptually, the steps in top-k sampling are:\n",
        "- Find the `top_k` largest probabilities (you can use [`torch.topk`](https://pytorch.org/docs/stable/generated/torch.topk.html))\n",
        "- Set all other probabilities to zero\n",
        "- Normalize and sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zxPaIurCTAM"
      },
      "source": [
        "### Exercise - `sample_top_k`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴⚪⚪⚪\n",
        "> Importance: 🔵⚪⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 5-10 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "Implement the method `sample_top_k` now. Your implementation should stay in log-space throughout (don't exponentiate to obtain probabilities). This means you don't actually need to worry about normalizing, because `Categorical` accepts unnormalised logits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cywifSGCTAM"
      },
      "outputs": [],
      "source": [
        "prompt = \"John and Mary went to the\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "logits = model(input_ids)[0, -1]\n",
        "\n",
        "expected_top_5 = {\n",
        "    \" church\": 0.0648,\n",
        "    \" house\": 0.0367,\n",
        "    \" temple\": 0.0145,\n",
        "    \" same\": 0.0104,\n",
        "    \" Church\": 0.0097,\n",
        "}\n",
        "topk_5_sum = sum(expected_top_5.values())\n",
        "\n",
        "observed_freqs = defaultdict(int)\n",
        "\n",
        "N = 10000\n",
        "for _ in tqdm(range(N)):\n",
        "    token = TransformerSampler.sample_next_token(input_ids.squeeze(), logits, top_k=5)\n",
        "    observed_freqs[tokenizer.decode(token)] += 1\n",
        "\n",
        "for word in expected_top_5:\n",
        "    expected_freq = expected_top_5[word] / topk_5_sum\n",
        "    observed_freq = observed_freqs[word] / N\n",
        "    print(\n",
        "        f\"Word: {word!r:<9}. Expected freq = {expected_freq:.4f}, observed freq = {observed_freq:.4f}\"\n",
        "    )\n",
        "    assert abs(observed_freq - expected_freq) < 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNAa8vfqCTAM"
      },
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "@staticmethod\n",
        "def sample_top_k(logits: Float[Tensor, \"d_vocab\"], k: int) -> int:\n",
        "    \"\"\"\n",
        "    Samples from the top k most likely tokens.\n",
        "    \"\"\"\n",
        "    top_k_logits, top_k_token_ids = logits.topk(k)\n",
        "    # Get sampled token (which is an index corresponding to the list of top-k tokens)\n",
        "    sampled_token_idx = t.distributions.categorical.Categorical(logits=top_k_logits).sample()\n",
        "    # Get the actual token id, as an int\n",
        "    return top_k_token_ids[sampled_token_idx].item()\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IocvI5ZCTAM"
      },
      "source": [
        "The [GPT-2 paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) famously included an example prompt about unicorns. Now it's your turn to see just how cherry picked this example was.\n",
        "\n",
        "The paper claims they used `top_k=40` and best of 10 samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-3aPiC7CTAM"
      },
      "outputs": [],
      "source": [
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "your_prompt = \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\"\n",
        "\n",
        "output = sampler.sample(your_prompt, temperature=0.7, top_k=40, max_tokens_generated=64)\n",
        "\n",
        "rprint(f\"Your model said:\\n\\n[bold dark_orange]{output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSRl6M2PCTAM"
      },
      "source": [
        "This is pretty incredible! For some perspective on how much of a paradigm shift even basic models like this represented, we recommend reading [this section from Simulators](https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators#The_limit_of_sequence_modeling)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLMYO31ZCTAM"
      },
      "source": [
        "## Top-p aka Nucleus Sampling\n",
        "\n",
        "The basic idea is that we choose the most likely words, up until the total probability of words we've chosen crosses some threshold. Then we sample from those chosen words based on their logits.\n",
        "\n",
        "The steps are:\n",
        "\n",
        "- Sort the probabilities from largest to smallest\n",
        "- Find the cutoff point where the cumulative probability first equals or exceeds `top_p`. We do the cutoff inclusively, keeping the first probability above the threshold.\n",
        "- If the number of kept probabilities is less than `min_tokens_to_keep`, keep that many tokens instead.\n",
        "- Set all other probabilities to zero\n",
        "- Normalize and sample\n",
        "\n",
        "For example, if our probabilities were `(0.4, 0.3, 0.2, 0.1)` and our cutoff was `top_p=0.8`, then we'd sample from the first three elements (because their total probability is `0.9` which is over the threshold, but the first two only have a total prob of `0.7` which is under the threshold). Once we've chosen to sample from those three, we would renormalise them by dividing by their sum, so the probabilities we use when sampling are `(0.4/0.9, 0.3/0.9, 0.2/0.9)`.\n",
        "\n",
        "Optionally, refer to the paper [The Curious Case of Neural Text Degeneration](https://arxiv.org/pdf/1904.09751.pdf) for some comparison of different methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXs10re0CTAM"
      },
      "source": [
        "### Exercise - `sample_top_p`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴⚪⚪\n",
        "> Importance: 🔵⚪⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 15-20 minutes on this exercise.\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d2SXvtPCTAM"
      },
      "outputs": [],
      "source": [
        "prompt = \"John and Mary went to the\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "logits = model(input_ids)[0, -1]\n",
        "\n",
        "expected_top_10pct = {\n",
        "    \" church\": 0.0648,\n",
        "    \" house\": 0.0367,  # These are the two most likely tokens, and add up to >10%\n",
        "}\n",
        "top_10pct_sum = sum(expected_top_10pct.values())\n",
        "\n",
        "observed_freqs = defaultdict(int)\n",
        "\n",
        "N = 10_000\n",
        "for _ in tqdm(range(N)):\n",
        "    token = TransformerSampler.sample_next_token(input_ids.squeeze(), logits, top_p=0.1)\n",
        "    observed_freqs[tokenizer.decode(token)] += 1\n",
        "\n",
        "for word in expected_top_10pct:\n",
        "    expected_freq = expected_top_10pct[word] / top_10pct_sum\n",
        "    observed_freq = observed_freqs[word] / N\n",
        "    print(\n",
        "        f\"Word: {word!r:<9}. Expected freq {expected_freq:.4f}, observed freq {observed_freq:.4f}\"\n",
        "    )\n",
        "    assert abs(observed_freq - expected_freq) < 0.01, (\n",
        "        \"Try increasing N if this fails by a small amount.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKIfz7ApCTAM"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm stuck on how to implement this function.</summary>\n",
        "\n",
        "First, sort the logits using the `sort(descending=True)` method (this returns values and indices). Then you can get `cumulative_probs` by applying softmax to these logits and taking the cumsum. Then, you can decide how many probabilities to keep by using the `t.searchsorted` function.\n",
        "\n",
        "Once you've decided which probabilities to keep, it's easiest to sample from them using the original logits (you should have preserved the indices when you called `logits.sort`). This way, you don't need to worry about renormalising like you would if you were using probabilities.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "@staticmethod\n",
        "def sample_top_p(logits: Float[Tensor, \"d_vocab\"], top_p: float, min_tokens_to_keep: int = 1) -> int:\n",
        "    \"\"\"\n",
        "    Samples from the most likely tokens which make up at least p cumulative probability.\n",
        "    \"\"\"\n",
        "    # Sort logits, and get cumulative probabilities\n",
        "    logits_sorted, indices = logits.sort(descending=True, stable=True)\n",
        "    cumul_probs = logits_sorted.softmax(-1).cumsum(-1)\n",
        "    # Choose which tokens to keep, in the set we sample from\n",
        "    n_keep = t.searchsorted(cumul_probs, top_p, side=\"left\").item() + 1\n",
        "    n_keep = max(n_keep, min_tokens_to_keep)\n",
        "    keep_idx = indices[:n_keep]\n",
        "    keep_logits = logits[keep_idx]\n",
        "    # Perform the sampling\n",
        "    sample = t.distributions.categorical.Categorical(logits=keep_logits).sample()\n",
        "    return keep_idx[sample].item()\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BuP21vWCTAM"
      },
      "source": [
        "Now, an example of top-p sampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uxahbfhCTAM"
      },
      "outputs": [],
      "source": [
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "your_prompt = \"Eliezer Shlomo Yudkowsky (born September 11, 1979) is an American decision and artificial intelligence (AI) theorist and writer, best known for\"\n",
        "output = sampler.sample(your_prompt, temperature=0.7, top_p=0.95, max_tokens_generated=64)\n",
        "rprint(f\"Your model said:\\n\\n[bold dark_orange]{output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuhKPBVZCTAM"
      },
      "source": [
        "## Beam search\n",
        "\n",
        "Finally, we'll implement a more advanced way of searching over output: **beam search**. You should read the [HuggingFace page](https://huggingface.co/blog/how-to-generate#beam-search) on beam search before moving on.\n",
        "\n",
        "In beam search, we maintain a list of size `num_beams` completions which are the most likely completions so far as measured by the product of their probabilities. Since this product can become very small, we use the sum of log probabilities instead. Note - log probabilities are *not* the same as your model's output. We get log probabilities by first taking softmax of our output and then taking log. You can do this with the [`log_softmax`](https://pytorch.org/docs/stable/generated/torch.nn.functional.log_softmax.html) function / tensor method.\n",
        "\n",
        "<details>\n",
        "<summary>Log probabilities are equal to the logit output after being translated by some amount X (where X is a function of the original logit output). Can you prove this?</summary>\n",
        "\n",
        "Suppose our vector of logits is $x$, and we take softmax to get a vector of probabilities $p$, then log again to get a vector of log probabilities $l$. Then the $i$-th element of this vector of logprobs is:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "l_i &= \\log p_i \\\\\n",
        "&= \\log \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)} \\\\\n",
        "&= x_i - \\log \\sum_j \\exp(x_j) \\\\\n",
        "&= x_i - C\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "where $C = \\log \\sum_j \\exp(x_j)$ is the same for all elements. So we can see that $l_i$ is equal to the logit output $x_i$ after being translated by $C$.\n",
        "\n",
        "It's important not to mix up logits and logprobs!\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Why do you think we use log softmax rather than logit output?</summary>\n",
        "\n",
        "Logit output is translation invariant. If we had two different beams and we were generating the next tokens in those beams, there would be no reasonable way to compare the two beams to each other, because we could shift the logit vector for one beam by a constant amount without changing the distribution.\n",
        "\n",
        "</details>\n",
        "\n",
        "At each iteration, we run the batch of completions through the model and take the log-softmax to obtain `d_vocab` log-probs for each completion, or `num_beams * d_vocab` possible next completions in total.\n",
        "\n",
        "If we kept all of these, then we would have `num_beams * d_vocab * d_vocab` completions after the next iteration which is way too many, so instead we sort them by their score and loop through from best (highest) log probability to worst (lowest).\n",
        "\n",
        "The illustration below might help (based on real results from this method). Here, we have the following hyperparameters:\n",
        "\n",
        "```python\n",
        "num_beams = 3\n",
        "max_new_tokens = 3\n",
        "num_return_sequences = 2\n",
        "```\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/beam-search-3.png\" width=\"1000\">\n",
        "\n",
        "Note how after each \"generate\" stage, we have `num_beams ** 2` possible completions, which we then filter down to `num_beams`. This is because we need this many in order to find the best `num_beams` completions overall - for example, it's possible that all the best beams of length `n+1` come from the same beam of length `n`, in which case we'll need to keep all `num_beams` that we generated from that single beam.\n",
        "\n",
        "How do we deal with sequences that terminate early (i.e. by generating an EOS token)? Answer - we append them to the list of completions which we'll return at the end, and remove them from the generation tree. Our algorithm terminates when either all our sequences have length `max_new_tokens` larger than the initial prompt length, or we've generated `num_returns_sequences` terminating sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhBvv9e-CTAM"
      },
      "source": [
        "### Exercise - implement `beam_search`\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴🔴\n",
        "> Importance: 🔵⚪⚪⚪⚪\n",
        ">\n",
        "> You should spend up to 30-50 minutes on this exercise.\n",
        "> ```\n",
        "\n",
        "We've given you one implementation of `beam_search` below, which calls the `generate` and `filter` methods of the `Beams` class (these correspond to the two stages in the diagram above). The `beam_search` method works as follows:\n",
        "\n",
        "- Create a list `final_logprobs_and_completions` for storing the final output, as tuples of (logprob sum, string completion).\n",
        "- Perform `max_new_tokens` steps of generation (producing a new set of beams) and filtering (getting the best beams from these combinations), while also adding terminated beams to the list of best beams\n",
        "- Return these terminated beams plus the best ones we have at the end of the steps.\n",
        "\n",
        "So all you need to do is fill in the `generate` and `filter` methods. Below, you'll find some unit tests for the `generate` and `filter` methods. When you've passed these tests, you should be able to run the full `beam_search` function.\n",
        "\n",
        "**Important note** - by default, beam search produces a lot of repeated words / phrases / sentences. This makes sense - if the model finds some completion with a much higher logit sum than most completions in its beam search space, then it will want to repeat this completion even if it doesn't make a lot of sense in context. A common solution is to ban repetition of n-grams, which you should also implement in the function below. In other words, rather than sampling tokens from each sequence by taking `logprobs.topk(k)` in your `generate` method, you should take the `k` top tokens after filtering out those that give you repeated n-grams of length `no_repeat_ngram_size`. Good values of this parameter to try are 2 or 3 (although we recommend you try without this parameter first, so you can see how much of a difference it makes!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52_7NMX0CTAM"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Beams:\n",
        "    \"\"\"Class to store beams during beam search.\"\"\"\n",
        "\n",
        "    model: DemoTransformer\n",
        "    tokenizer: GPT2TokenizerFast\n",
        "    logprob_sums: Float[Tensor, \"batch\"]\n",
        "    tokens: Int[Tensor, \"batch seq\"]\n",
        "\n",
        "    def __getitem__(self, batch_idx) -> \"Beams\":\n",
        "        \"\"\"Allows you to create new beams from old beams by slicing along batch dim (useful for `filter`).\"\"\"\n",
        "        return Beams(\n",
        "            self.model, self.tokenizer, self.logprob_sums[batch_idx], self.tokens[batch_idx]\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def logprobs_and_completions(self) -> list[tuple[float, str]]:\n",
        "        \"\"\"Returns self as a list of logprob sums and completions (useful for getting final output).\"\"\"\n",
        "        return [\n",
        "            (logprob_sum.item(), self.tokenizer.decode(tokens))\n",
        "            for (logprob_sum, tokens) in zip(self.logprob_sums, self.tokens)\n",
        "        ]\n",
        "\n",
        "    def generate(self, k: int, no_repeat_ngram_size: int | None = None) -> \"Beams\":\n",
        "        \"\"\"\n",
        "        Starting from the current set of beams (i.e. self.tokens) and returns a new set of `len(self.tokens) * k` beams,\n",
        "        containing the best `k` continuations for each of the original beams.\n",
        "\n",
        "        Optional argument `no_repeat_ngram_size` means your model won't generate any sequences with a repeating n-gram\n",
        "        of this length.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def filter(self, k: int) -> tuple[\"Beams\", \"Beams\"]:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            best_beams: Beams\n",
        "                filtered version of self, containing all best `k` which are also not terminated.\n",
        "            early_terminations: Beams\n",
        "                filtered version of self, containing all best `k` which are also terminated.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "    def print(self, title=\"Best completions\", max_print_chars=80) -> None:\n",
        "        \"\"\"\n",
        "        Prints out a set of sequences with their corresponding logprob sums.\n",
        "        \"\"\"\n",
        "        if len(self.tokens) == 0:\n",
        "            return\n",
        "        table = Table(\"logprob sum\", \"completion\", title=title)\n",
        "        for logprob_sum, tokens in zip(self.logprob_sums, self.tokens):\n",
        "            text = self.tokenizer.decode(tokens)\n",
        "            if len(repr(text)) > max_print_chars:\n",
        "                text = (\n",
        "                    text[: int(0.3 * max_print_chars)]\n",
        "                    + \" ... \"\n",
        "                    + text[-int(0.7 * max_print_chars) :]\n",
        "                )\n",
        "            table.add_row(f\"{logprob_sum:>8.3f}\", repr(text))\n",
        "        rprint(table)\n",
        "\n",
        "\n",
        "@t.inference_mode()\n",
        "def beam_search(\n",
        "    self: TransformerSampler,\n",
        "    prompt: str,\n",
        "    num_return_sequences: int,\n",
        "    num_beams: int,\n",
        "    max_new_tokens: int,\n",
        "    no_repeat_ngram_size: int | None = None,\n",
        ") -> list[tuple[float, str]]:\n",
        "    \"\"\"\n",
        "    Implements a beam search, by repeatedly performing the `generate` and `filter` steps (starting from the initial\n",
        "    prompt) until either of the two stopping criteria are met: (1) we've generated `max_new_tokens` tokens, or (2)\n",
        "    we've generated `num_returns_sequences` terminating sequences.\n",
        "    \"\"\"\n",
        "    assert num_return_sequences <= num_beams\n",
        "    self.model.eval()\n",
        "\n",
        "    tokens = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    final_logprobs_and_completions = []  # we add to this list as we get terminated beams\n",
        "    best_beams = Beams(\n",
        "        self.model, self.tokenizer, t.tensor([0.0]).to(device), tokens\n",
        "    )  # start with just 1 beam\n",
        "\n",
        "    for _ in tqdm(range(max_new_tokens)):\n",
        "        t.cuda.empty_cache()\n",
        "\n",
        "        # Generate & filter beams\n",
        "        best_beams = best_beams.generate(k=num_beams, no_repeat_ngram_size=no_repeat_ngram_size)\n",
        "        best_beams, best_beams_terminated = best_beams.filter(k=num_beams)\n",
        "\n",
        "        # Add terminated beams to our list, and return early if we have enough\n",
        "        final_logprobs_and_completions.extend(best_beams_terminated.logprobs_and_completions)\n",
        "        if len(final_logprobs_and_completions) >= num_return_sequences:\n",
        "            return final_logprobs_and_completions[:num_return_sequences]\n",
        "\n",
        "    # Return terminated beams plus the best ongoing beams of length `orig_len + max_new_tokens`\n",
        "    final_logprobs_and_completions.extend(best_beams.logprobs_and_completions)\n",
        "    return final_logprobs_and_completions[:num_return_sequences]\n",
        "\n",
        "\n",
        "TransformerSampler.beam_search = beam_search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpFF_SWoCTAN"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm stuck on the implementation of <code>no_repeat_ngram_size</code>.</summary>\n",
        "\n",
        "Here's a method, which you can use in your `generate` function in place of `logprobs.topk(k)`, which filters out the ngrams of length `no_repeat_ngram_size` which have already appeared in `self.tokens`:\n",
        "\n",
        "```python\n",
        "def get_topk_non_repeating(\n",
        "    self,\n",
        "    logprobs: Float[Tensor, \"batch d_vocab\"],\n",
        "    no_repeat_ngram_size: int | None,\n",
        "    k: int,\n",
        ") -> tuple[Float[Tensor, \"k\"], Int[Tensor, \"k\"]]:\n",
        "    \"\"\"\n",
        "    logprobs:\n",
        "        tensor of the log-probs for the next token\n",
        "    no_repeat_ngram_size:\n",
        "        size of ngram to avoid repeating\n",
        "    k:\n",
        "        number of top logits to return, for each beam in our collection\n",
        "\n",
        "    Returns:\n",
        "        equivalent to the output of `logprobs.topk(dim=-1)`, but makes sure that no returned tokens would produce an\n",
        "        ngram of size `no_repeat_ngram_size` which has already appeared in `self.tokens`.\n",
        "    \"\"\"\n",
        "    batch, seq_len = self.tokens.shape\n",
        "\n",
        "    # If completion isn't long enough for a repetition, or we have no restrictions, just return topk\n",
        "    if (no_repeat_ngram_size is not None) and (seq_len > no_repeat_ngram_size - 1):\n",
        "        # Otherwise, we need to check for ngram repetitions\n",
        "        # First, get the most recent `no_repeat_ngram_size-1` tokens\n",
        "        last_ngram_prefix = self.tokens[:, seq_len - (no_repeat_ngram_size - 1) :]\n",
        "        # Next, find all the tokens we're not allowed to generate, by checking all past ngrams for a match\n",
        "        for i in range(seq_len - (no_repeat_ngram_size - 1)):\n",
        "            ngrams = self.tokens[:, i : i + no_repeat_ngram_size]  # (batch, ngram)\n",
        "            ngrams_are_repeated = (ngrams[:, :-1] == last_ngram_prefix).all(-1)  # (batch,)\n",
        "            ngram_end_tokens = ngrams[:, [-1]]  # (batch, 1)\n",
        "            # Fill logprobs with neginf wherever the ngrams are repeated\n",
        "            logprobs[range(batch), ngram_end_tokens] = t.where(\n",
        "                ngrams_are_repeated, -1.0e4, logprobs[range(batch), ngram_end_tokens]\n",
        "            )\n",
        "\n",
        "    # Finally, get our actual tokens\n",
        "    return logprobs.topk(k=k, dim=-1)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "def generate(self, k: int, no_repeat_ngram_size: int | None = None) -> \"Beams\":\n",
        "    \"\"\"\n",
        "    Starting from the current set of beams (i.e. self.tokens) and returns a new set of `len(self.tokens) * k` beams,\n",
        "    containing the best `k` continuations for each of the original beams.\n",
        "\n",
        "    Optional argument `no_repeat_ngram_size` means your model won't generate any sequences with a repeating n-gram\n",
        "    of this length.\n",
        "    \"\"\"\n",
        "    # Get the output logprobs for the next token (for every sequence in current beams)\n",
        "    logprobs = self.model(self.tokens)[:, -1, :].log_softmax(-1)\n",
        "\n",
        "    # Get the top `toks_per_beam` tokens for each sequence\n",
        "    topk_logprobs, topk_tokenIDs = self.get_topk_non_repeating(logprobs, no_repeat_ngram_size, k=k)\n",
        "\n",
        "    # Add new logprobs & concat new tokens. When doing this, we need to add an extra `k` dimension since our current\n",
        "    # logprobs & tokens have shape (batch,) and (batch, seq), but our new ones both have shape (batch, k)\n",
        "    new_logprob_sums = einops.repeat(self.logprob_sums, \"b -> b k\", k=k) + topk_logprobs\n",
        "    new_tokens = t.concat([einops.repeat(self.tokens, \"b s -> b k s\", k=k), topk_tokenIDs.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "    return Beams(self.model, self.tokenizer, new_logprob_sums.flatten(), new_tokens.flatten(0, 1))\n",
        "\n",
        "def filter(self, k: int) -> tuple[\"Beams\", \"Beams\"]:\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "        best_beams: Beams\n",
        "            filtered version of self, containing all best `k` which are also not terminated.\n",
        "        early_terminations: Beams\n",
        "            filtered version of self, containing all best `k` which are also terminated.\n",
        "    \"\"\"\n",
        "    # Get the indices of top `k` beams\n",
        "    top_beam_indices = self.logprob_sums.topk(k=k, dim=0).indices.tolist()\n",
        "    # Get the indices of terminated sequences\n",
        "    new_tokens = self.tokens[:, -1]\n",
        "    terminated_indices = t.nonzero(new_tokens == self.tokenizer.eos_token_id)\n",
        "\n",
        "    # Get the indices of the `k` best sequences (some terminated, some not terminated)\n",
        "    best_continuing = [i for i in top_beam_indices if i not in terminated_indices]\n",
        "    best_terminated = [i for i in top_beam_indices if i in terminated_indices]\n",
        "\n",
        "    # Return the beam objects from these indices\n",
        "    return self[best_continuing], self[best_terminated]\n",
        "\n",
        "def get_topk_non_repeating(\n",
        "    self,\n",
        "    logprobs: Float[Tensor, \"batch d_vocab\"],\n",
        "    no_repeat_ngram_size: int | None,\n",
        "    k: int,\n",
        ") -> tuple[Float[Tensor, \"k\"], Int[Tensor, \"k\"]]:\n",
        "    \"\"\"\n",
        "    logprobs:\n",
        "        tensor of the log-probs for the next token\n",
        "    no_repeat_ngram_size:\n",
        "        size of ngram to avoid repeating\n",
        "    k:\n",
        "        number of top logits to return, for each beam in our collection\n",
        "\n",
        "    Returns:\n",
        "        equivalent to the output of `logprobs.topk(dim=-1)`, but makes sure that no returned tokens would produce an\n",
        "        ngram of size `no_repeat_ngram_size` which has already appeared in `self.tokens`.\n",
        "    \"\"\"\n",
        "    batch, seq_len = self.tokens.shape\n",
        "\n",
        "    # If completion isn't long enough for a repetition, or we have no restrictions, just return topk\n",
        "    if (no_repeat_ngram_size is not None) and (seq_len > no_repeat_ngram_size - 1):\n",
        "        # Otherwise, we need to check for ngram repetitions\n",
        "        # First, get the most recent `no_repeat_ngram_size-1` tokens\n",
        "        last_ngram_prefix = self.tokens[:, seq_len - (no_repeat_ngram_size - 1) :]\n",
        "        # Next, find all the tokens we're not allowed to generate, by checking all past ngrams for a match\n",
        "        for i in range(seq_len - (no_repeat_ngram_size - 1)):\n",
        "            ngrams = self.tokens[:, i : i + no_repeat_ngram_size]  # (batch, ngram)\n",
        "            ngrams_are_repeated = (ngrams[:, :-1] == last_ngram_prefix).all(-1)  # (batch,)\n",
        "            ngram_end_tokens = ngrams[:, [-1]]  # (batch, 1)\n",
        "            # Fill logprobs with neginf wherever the ngrams are repeated\n",
        "            logprobs[range(batch), ngram_end_tokens] = t.where(\n",
        "                ngrams_are_repeated, -1.0e4, logprobs[range(batch), ngram_end_tokens]\n",
        "            )\n",
        "\n",
        "    # Finally, get our actual tokens\n",
        "    return logprobs.topk(k=k, dim=-1)\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwb0R_RGCTAN"
      },
      "source": [
        "Example usage of the `Beams` class, and the `print` method, corresponding to the diagram above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT_9MZ-MCTAN"
      },
      "outputs": [],
      "source": [
        "# Start with prompt \"When I was\", get top 3 tokens (and their logprobs), and use that to create & display the top 3 beams\n",
        "prompt = \"When I was\"\n",
        "tokens = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "logprobs = model(tokens)[0, -1].log_softmax(-1)\n",
        "top_logprobs, top_tokens = logprobs.topk(k=3, dim=-1)\n",
        "\n",
        "new_tokens = t.concat([tokens.repeat(3, 1), top_tokens.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "beams = Beams(model, tokenizer, logprob_sums=top_logprobs, tokens=new_tokens)\n",
        "beams.print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pkDC41dCTAN"
      },
      "source": [
        "And here are some unit tests for your `generate` and `filter` methods, starting from the prompt `\"When I was\"` (so your output should match the diagram above)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EruSAU_xCTAN"
      },
      "outputs": [],
      "source": [
        "print(\"Testing generate...\")\n",
        "new_beams = beams.generate(k=3, no_repeat_ngram_size=1)\n",
        "new_beams.print()\n",
        "\n",
        "expected_values = [\n",
        "    (-3.1, \"When I was a kid\"),\n",
        "    (-4.8, \"When I was a child\"),\n",
        "    (-4.9, \"When I was a little\"),\n",
        "]\n",
        "\n",
        "for i, (logprob_sum, completion) in enumerate(new_beams.logprobs_and_completions[:3]):\n",
        "    assert abs(logprob_sum - expected_values[i][0]) < 0.1, f\"{i}\"\n",
        "    assert completion == expected_values[i][1], f\"{i}\"\n",
        "\n",
        "print(\"All tests for `generate` passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8YMh5ebCTAN"
      },
      "outputs": [],
      "source": [
        "print(\"Testing `filter`...\")\n",
        "\n",
        "best_beams, terminated_beams = new_beams.filter(3)\n",
        "best_beams.print()\n",
        "\n",
        "expected_values = [\n",
        "    (-3.1, \"When I was a kid\"),\n",
        "    (-3.2, \"When I was growing up\"),\n",
        "    (-4.6, \"When I was in the\"),\n",
        "]\n",
        "\n",
        "for i, (logprob_sum, completion) in enumerate(best_beams.logprobs_and_completions):\n",
        "    assert abs(logprob_sum - expected_values[i][0]) < 0.1, f\"{i}\"\n",
        "    assert completion == expected_values[i][1], f\"{i}\"\n",
        "\n",
        "assert len(terminated_beams.logprobs_and_completions) == 0\n",
        "\n",
        "print(\"All tests for `filter` passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbMIzJuYCTAN"
      },
      "source": [
        "Lastly, we'll test the `no_repeat_ngram_size` argument. We do this by continually generating new tokens from our starting beams `beams`, and seeing if the model repeats the `I was` ngram (which it will by default unless we prohibit repeating n-grams)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypyW_mO8CTAN"
      },
      "outputs": [],
      "source": [
        "print(\"Testing `no_repeat_ngram_size`...\")\n",
        "\n",
        "new_beams = beams\n",
        "for _ in range(5):\n",
        "    new_beams = new_beams.generate(k=1)\n",
        "new_beams.print(title=\"Completions with no ngram restriction\")\n",
        "assert all(\n",
        "    \"I was\" in completion.removeprefix(prompt)\n",
        "    for _, completion in new_beams.logprobs_and_completions\n",
        "), \"Without restriction, all beams should be completed as '...I was...'\"\n",
        "\n",
        "new_beams = beams\n",
        "for _ in range(5):\n",
        "    new_beams = new_beams.generate(k=1, no_repeat_ngram_size=2)\n",
        "new_beams.print(title=\"Completions with no repeated bigrams\")\n",
        "assert all(\n",
        "    \"I was\" not in completion.removeprefix(prompt)\n",
        "    for _, completion in new_beams.logprobs_and_completions\n",
        "), \"With no repeated bigrams, no beams should contain a second '...I was...'\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50Q9MkXICTAN"
      },
      "source": [
        "Once you've passed all of these unit tests, you can try implementing the full beam search function. It should create a `Beams` object from the initial prompt, and then repeatedly call `generate` and `filter` until the stopping criteria are met."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ib-aE9N8CTAN"
      },
      "outputs": [],
      "source": [
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "prompt = \"The ships hung in the sky in much the same way that\"\n",
        "orig_len = len(tokenizer.encode(prompt))\n",
        "\n",
        "final_logitsums_and_completions = sampler.beam_search(\n",
        "    prompt=prompt,\n",
        "    num_return_sequences=3,\n",
        "    num_beams=40,\n",
        "    max_new_tokens=60,\n",
        "    no_repeat_ngram_size=2,\n",
        ")\n",
        "\n",
        "# Print all the best output\n",
        "for logprob_sum, text in final_logitsums_and_completions:\n",
        "    avg_logprob_as_prob = t.tensor(logprob_sum / (len(tokenizer.encode(text)) - orig_len)).exp()\n",
        "    rprint(f\"Avg token prob = {avg_logprob_as_prob:.3f}\\nBest output:\\n[bold dark_orange]{text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am6uaYdsCTAN"
      },
      "source": [
        "## KV Caching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TJ_l8GRCTAN"
      },
      "source": [
        "*This section is also designed to be challenging, and take quite some time. There are many different ways to solve it, and you're expected to try and find your own way (you should think about this for a while before looking at the suggestions in the dropdowns). Additionally, you might not find it as interesting as some of the other sections. In this case, and if you have a lot of extra time, you might want to start on the \"building BERT\" exercises from this chapter.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFy1PVHwCTAN"
      },
      "source": [
        "### How can caching help us?\n",
        "\n",
        "The text generation we've done so far is needlessly re-computing certain values, which is very noticeable when you try to generate longer sequences.\n",
        "\n",
        "Suppose you're generating text, and you've already run GPT on the sentence \"My life motto:\". Now you want to run the model on the sentence \"My life motto: Always\". Which computations from the first sentence can you reuse?\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "At each attention layer, the only things the attention layer needs from the previous sequence positions are the key and value vectors. This is explained in the following diagram, which compares the attention layer with and without caching (it's a big diagram so you might want to open it in a separate window to zoom in).\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/main/misc/tl-cache-full.png\" width=\"1200\">\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWWTQrXWCTAN"
      },
      "source": [
        "### Exercise - implement KV caching\n",
        "\n",
        "> ```yaml\n",
        "> Difficulty: 🔴🔴🔴🔴🔴\n",
        "> Importance: 🔵⚪⚪⚪⚪\n",
        ">\n",
        "> You are expected to spend well over an hour on this exercise, if you choose to do it.\n",
        "> ```\n",
        "\n",
        "Modify your GPT-2 to optionally use a cache. When you run your GPT on `\"My life motto:\"`, it should store the necessary values in the cache. Then in the next forward pass with just `\" Always\"` as input, it should load the cached values instead of recomputing them (and update the cache). This only needs to work with a single input sequence (batch size of 1), and you can assume that after the first forward pass, the input will be just one token.\n",
        "\n",
        "The design of the cache is completely up to you - discuss possible designs with your partner before writing code. It should be possible to have only one GPT2 instance and many different cache instances at one time. Imagine that you want to use one instance to serve multiple users submitting requests for text generation like in [AI Dungeon](https://aidungeon.io/).\n",
        "\n",
        "You'll also need to rewrite parts of your `DemoTransformer` code, in order to get this to work. The tests have been built to accommodate modules which return their output as the first element in a tuple (i.e. `(output, cache)`) rather than just returning the output, so you should use the tests to verify that your modules still work as expected.\n",
        "\n",
        "Some example considerations:\n",
        "\n",
        "* Which GPT-2 classes need to interact with the cache?\n",
        "    * Will you need to change the positional embedding, and if so then how?\n",
        "* Should the cache be mutable and be updated in place, or does updating actually just create a separate instance?\n",
        "    * *(Hint here - think about how you might use the cache during beam search.)*\n",
        "* Is it possible for other programmers to incorrectly use your cache? Is there a way to prevent this failure mode or at least detect this and complain loudly?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbEoMIbJCTAN"
      },
      "source": [
        "<details>\n",
        "<summary>Cache implentation (example)</summary>\n",
        "\n",
        "This KeyValueCache object is structured as just a fancy tensor (it inherits all the methods from Tensor). The main difference is that it has a few extra helper methods, e.g. constructing an empty cache from a Config object.\n",
        "\n",
        "There are other ways you could do this, e.g. having your `KeyValueCache` class contain list of `KeyValueCacheEntry` objects (where each of these corresponds to a different layer).\n",
        "\n",
        "```python\n",
        "# Define a type for a single layer's cache entry (useful for type checking in later functions)\n",
        "KeyValueCacheTensor = Float[Tensor, \"2 batch seq_len n_heads d_head\"]\n",
        "\n",
        "class KeyValueCache(Tensor):\n",
        "    '''\n",
        "    This class holds tensors of key and value vectors, to be used for caching.\n",
        "\n",
        "    If we define it using cfg and batch then it's initialized as empty, but\n",
        "    we can also define it from kv_cache_entries.\n",
        "    '''\n",
        "    @classmethod\n",
        "    def new_empty(cls, cfg: Config, batch: int = 1) -> \"KeyValueCache\":\n",
        "        '''\n",
        "        Doing a forward pass on a cache created in this way indicates \"we don't\n",
        "        yet have a cache, but we want this forward pass to return a cache\".\n",
        "        Whereas using cache=None in a forward pass indicates we don't want to\n",
        "        return a cache.\n",
        "        '''\n",
        "        shape = (cfg.n_layers, 2, batch, 0, cfg.n_heads, cfg.d_head)\n",
        "        return cls(*shape).to(device)\n",
        "\n",
        "    # Define a handful of properties, so they can be referenced directly rather than\n",
        "    # indexing (which is more likely to lead to mistakes)\n",
        "\n",
        "    @property\n",
        "    def k(self) -> Tensor:\n",
        "        return self[:, 0]\n",
        "\n",
        "    @property\n",
        "    def v(self) -> Tensor:\n",
        "        return self[:, 1]\n",
        "\n",
        "    @property\n",
        "    def batch(self) -> int:\n",
        "        return self.shape[2]\n",
        "\n",
        "    @property\n",
        "    def seq_len(self) -> int:\n",
        "        return self.shape[3]\n",
        "\n",
        "\n",
        "# Example implementation:\n",
        "cfg = model.cfg\n",
        "batch = 6\n",
        "kv_cache = KeyValueCache.new_empty(cfg, batch)\n",
        "\n",
        "print(f\"Shape of all kv-cache = {tuple(kv_cache.shape)}\")\n",
        "print(f\"Shape of just k-cache = {tuple(kv_cache.k.shape)}\")\n",
        "for kv_cache_entry in kv_cache:\n",
        "    print(f\"Shape of cache entry for one layer = {tuple(kv_cache_entry.shape)}\")\n",
        "    break\n",
        "print(f\"Batch size = {kv_cache.batch}\")\n",
        "print(f\"Current sequence length = {kv_cache.seq_len}\")\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>New <code>DemoTransformer</code> components (and testing)</summary>\n",
        "\n",
        "```python\n",
        "# Define new model parts where necessary, and create a new model & test it\n",
        "# Note that sometimes our modules return a tuple of (tensor output, cache) rather than just output. The\n",
        "# tests have been built to accommodate this.\n",
        "\n",
        "\n",
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(t.empty((cfg.n_ctx, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        tokens: Int[Tensor, \"batch position\"],\n",
        "        past_kv_pos_offset: int = 0\n",
        "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
        "\n",
        "        batch, seq_len = tokens.shape\n",
        "        return einops.repeat(\n",
        "            self.W_pos[past_kv_pos_offset: seq_len+past_kv_pos_offset],\n",
        "            \"seq d_model -> batch seq d_model\",\n",
        "            batch=batch\n",
        "        )\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    IGNORE: Float[Tensor, \"\"]\n",
        "\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_O = nn.Parameter(t.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        self.b_Q = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_K = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_V = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_O = nn.Parameter(t.zeros((cfg.d_model)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.register_buffer(\"IGNORE\", t.tensor(-1e5, dtype=t.float32, device=device))\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        normalized_resid_pre: Float[Tensor, \"batch posn d_model\"],\n",
        "        kv_cache_entry: KeyValueCacheTensor | None = None,\n",
        "    ) -> tuple[\n",
        "        Float[Tensor, \"batch posn d_model\"],\n",
        "        KeyValueCacheTensor | None\n",
        "    ]:\n",
        "        '''\n",
        "        Returns the result of applying attention layer to normlized_resid_pre, as well as\n",
        "        the new cached key and value vectors (which we get from concatenating the old cached\n",
        "        ones with the new key and value vectors).\n",
        "        '''\n",
        "        # Calculate the new query, key and value vectors\n",
        "        q = einops.einsum(\n",
        "            normalized_resid_pre, self.W_Q,\n",
        "            \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\"\n",
        "        ) + self.b_Q\n",
        "        k = einops.einsum(\n",
        "            normalized_resid_pre, self.W_K,\n",
        "            \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\"\n",
        "        ) + self.b_K\n",
        "        v = einops.einsum(\n",
        "            normalized_resid_pre, self.W_V,\n",
        "            \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\"\n",
        "        ) + self.b_V\n",
        "\n",
        "        # If cache_entry is not None, this means we use the previous key and value vectors\n",
        "        # Also we'll need to get a new cache entry which will be used later to construct a new cache\n",
        "        if kv_cache_entry is not None:\n",
        "            k = t.concat([kv_cache_entry[0], k], dim=1)\n",
        "            v = t.concat([kv_cache_entry[1], v], dim=1)\n",
        "            kv_cache_entry = t.stack([k, v])\n",
        "\n",
        "        # Calculate attention scores, then scale and mask, and apply softmax to get probabilities\n",
        "        attn_scores = einops.einsum(\n",
        "            q, k,\n",
        "            \"batch posn_Q nheads d_head, batch posn_K nheads d_head -> batch nheads posn_Q posn_K\"\n",
        "        )\n",
        "        attn_scores_masked = self.apply_causal_mask(attn_scores / self.cfg.d_head ** 0.5)\n",
        "        attn_pattern = attn_scores_masked.softmax(-1)\n",
        "\n",
        "        # Take weighted sum of value vectors, according to attention probabilities\n",
        "        z = einops.einsum(\n",
        "            v, attn_pattern,\n",
        "            \"batch posn_K nheads d_head, batch nheads posn_Q posn_K -> batch posn_Q nheads d_head\"\n",
        "        )\n",
        "\n",
        "        # Calculate output (by applying matrix W_O and summing over heads, then adding bias b_O)\n",
        "        out = einops.einsum(\n",
        "            z, self.W_O,\n",
        "            \"batch posn_Q nheads d_head, nheads d_head d_model -> batch posn_Q d_model\"\n",
        "        ) + self.b_O\n",
        "\n",
        "        return out, kv_cache_entry\n",
        "\n",
        "    def apply_causal_mask(\n",
        "        self, attn_scores: Float[Tensor, \"batch n_heads query_pos key_pos\"]\n",
        "    ) -> Float[Tensor, \"batch n_heads query_pos key_pos\"]:\n",
        "        '''\n",
        "        Here, attn_scores have shape (batch, n_heads, query_pos, key_pos), where query_pos represents the\n",
        "        new (non-cached) positions, and key_pos represent all the positions (cached and non-cached).\n",
        "\n",
        "        So when we create our mask, the query indices and key indices will both go up to the same value\n",
        "        (the full sequence length), but the query indices will start at >0.\n",
        "        '''\n",
        "        new_seq_len, full_seq_len = attn_scores.shape[-2:]\n",
        "        assert new_seq_len <= full_seq_len\n",
        "        q_posn = einops.repeat(attn_scores.new_tensor(range(full_seq_len-new_seq_len, full_seq_len)), \"q -> q k\", k=full_seq_len)\n",
        "        k_posn = einops.repeat(attn_scores.new_tensor(range(full_seq_len)), \"k -> q k\", q=new_seq_len)\n",
        "        mask = q_posn < k_posn\n",
        "        attn_scores = attn_scores.masked_fill(mask, self.IGNORE)\n",
        "        return attn_scores\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        resid_pre: Float[Tensor, \"batch position d_model\"],\n",
        "        kv_cache_entry: KeyValueCacheTensor | None = None,\n",
        "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
        "\n",
        "        attn_out, kv_cache_entry = self.attn(self.ln1(resid_pre), kv_cache_entry)\n",
        "        resid_mid = attn_out + resid_pre\n",
        "        resid_post = self.mlp(self.ln2(resid_mid)) + resid_mid\n",
        "        return resid_post, kv_cache_entry\n",
        "\n",
        "\n",
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        tokens: Int[Tensor, \"batch seq_pos\"],\n",
        "        kv_cache: KeyValueCache | None = None\n",
        "    ) -> Float[Tensor, \"batch position d_vocab\"]:\n",
        "\n",
        "        using_kv_cache = kv_cache is not None\n",
        "\n",
        "        if using_kv_cache:\n",
        "            # If using kv_cache, then we only need to pass forward the newest tokens\n",
        "            # Remember to add positional offset!\n",
        "            n_cached_tokens = kv_cache.seq_len\n",
        "            tokens = tokens[:, n_cached_tokens:]\n",
        "            residual = self.embed(tokens) + self.pos_embed(tokens, n_cached_tokens)\n",
        "        else:\n",
        "            # If not using cache, turn it into a list of None's (so we can iterate through it)\n",
        "            kv_cache = [None for _ in range(self.cfg.n_layers)]\n",
        "            residual = self.embed(tokens) + self.pos_embed(tokens)\n",
        "\n",
        "        # Apply all layers, and create a (new) kv_cache from the key & value vectors\n",
        "        new_kv_cache_entries: list[KeyValueCacheTensor] = []\n",
        "        for block, kv_cache_entry in zip(self.blocks, kv_cache):\n",
        "            residual, kv_cache_entry = block(residual, kv_cache_entry)\n",
        "            if using_kv_cache: new_kv_cache_entries.append(kv_cache_entry)\n",
        "\n",
        "        logits = self.unembed(self.ln_final(residual))\n",
        "\n",
        "        if using_kv_cache:\n",
        "            return logits, KeyValueCache(t.stack(new_kv_cache_entries))\n",
        "        else:\n",
        "            return logits, None\n",
        "\n",
        "\n",
        "tokens = reference_gpt2.to_tokens(reference_text).to(device)\n",
        "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
        "\n",
        "rand_int_test(PosEmbed, [2, 4])\n",
        "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)\n",
        "rand_float_test(Attention, [2, 4, 768])\n",
        "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"normalized\", 0, \"ln1\"])\n",
        "rand_float_test(TransformerBlock, [2, 4, 768])\n",
        "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])\n",
        "rand_int_test(DemoTransformer, [2, 4])\n",
        "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>New sampling function</summary>\n",
        "\n",
        "```python\n",
        "@t.inference_mode()\n",
        "def sample_with_cache(\n",
        "    self: TransformerSampler,\n",
        "    prompt: str,\n",
        "    max_tokens_generated=100,\n",
        "    kv_cache: KeyValueCache | None = None,\n",
        "    verbose=False,\n",
        "    seed: int | None = None,\n",
        "    **kwargs\n",
        ") -> str:\n",
        "\n",
        "    self.model.eval()\n",
        "    input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(device)[0]\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "        t.manual_seed(seed)\n",
        "\n",
        "    for i in tqdm(range(max_tokens_generated)):\n",
        "        # Get new logits (make sure we don't pass in more tokens than the model's context length)\n",
        "        logits, kv_cache = self.model(input_ids[None, -self.cfg.n_ctx:], kv_cache)\n",
        "        # We only take logits for the last token, because this is what we're sampling\n",
        "        logits = logits[0, -1]\n",
        "        # Get next token (as a tensor of size (1, 1) so we can concat it to input_ids)\n",
        "        next_token = t.tensor([TransformerSampler.sample_next_token(input_ids, logits, **kwargs)], device=device)\n",
        "        # Create new input ids string, with shape (1, old_seq_len + 1)\n",
        "        input_ids = t.cat([input_ids, next_token], dim=-1)\n",
        "        # Print out results, if required\n",
        "        if verbose:\n",
        "            print(self.tokenizer.decode(input_ids), end=\"\\r\")\n",
        "        # If our new token was the end-of-text token, stop\n",
        "        if next_token == getattr(self.tokenizer, \"eos_token_id\", None):\n",
        "            break\n",
        "\n",
        "    return self.tokenizer.decode(input_ids)\n",
        "\n",
        "\n",
        "TransformerSampler.sample = sample_with_cache\n",
        "```\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Code to verify that the same output is being produced by cache and no-cache versions (and to compare speeds)</summary>\n",
        "\n",
        "```python\n",
        "device = t.device(\"cuda\") # can also try \"cpu\"\n",
        "\n",
        "model = DemoTransformer(Config()).to(device)\n",
        "model.load_state_dict(reference_gpt2.state_dict(), strict=False);\n",
        "\n",
        "initial_text = \"Eliezer Shlomo Yudkowsky (born September 11, 1979) is an American decision and artificial intelligence (AI) theorist and writer, best known for\"\n",
        "# input_ids = tokenizer.encode(initial_text, return_tensors=\"pt\").squeeze()\n",
        "\n",
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "# Run the noncached version\n",
        "t0 = time.time()\n",
        "text = sampler.sample(\n",
        "    initial_text,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        "    seed=0,\n",
        ")\n",
        "print(f\"Time taken (without cache): {time.time() - t0:.2f} seconds\")\n",
        "rprint(f\"Model output:\\n\\n[bold dark_orange]{text}[/]\")\n",
        "\n",
        "# Run the cached version\n",
        "t0 = time.time()\n",
        "text_with_cache = sampler.sample(\n",
        "    initial_text,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        "    seed=0,\n",
        "    kv_cache=KeyValueCache.new_empty(sampler.cfg)\n",
        ")\n",
        "print(f\"Time taken (with cache): {time.time() - t0:.2f} seconds\")\n",
        "rprint(f\"Model output:\\n\\n[bold dark_orange]{text_with_cache}[/]\")\n",
        "\n",
        "# # Check they are the same\n",
        "assert text == text_with_cache, \"Your outputs are different, meaning you've probably made a mistake in your cache implementation (or failed to use random seeds).\"\n",
        "print(\"Tests passed!\")\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSr-DQEmCTAN"
      },
      "source": [
        "You may find that your cache implementation provides a modest speedup, but probably not close to the `seq_len`-factor speedup you'd expect from the fact that you only compute one additional token at each step rather than all of them. Why is this? The answer is that, much like everything to do with computational and memory costs in deep learning, it's not so simple. There are a host of different factors which might be bottlenecking our model's forward pass speed. If you try this on the CPU, you should get a much more noticeable speedup.\n",
        "\n",
        "For a bit more on these topics, see [here](https://kipp.ly/blog/transformer-inference-arithmetic/#kv-cache)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSN_y0DICTAN"
      },
      "source": [
        "## Bonus - cached beam search\n",
        "\n",
        "Can you modify your beam search function to use caching?\n",
        "\n",
        "Depending on how you implemented your cache earlier, you might find that a different form of caching is better suited to beam search.\n",
        "\n",
        "Again, we've provided an example implementation in a dropdown below, which is based on the cache implementation above and the previous solution for `beam_search`.\n",
        "\n",
        "<details>\n",
        "<summary>Cached beam search function</summary>\n",
        "\n",
        "As we touched on earlier, thanks to our modular code, not a lot needs to be changed when adding cache support.\n",
        "\n",
        "```python\n",
        "@dataclass\n",
        "class Beams:\n",
        "    '''Class to store beams during beam search.'''\n",
        "    model: DemoTransformer\n",
        "    tokenizer: GPT2TokenizerFast\n",
        "    logprob_sums: Float[Tensor, \"batch\"]\n",
        "    tokens: Int[Tensor, \"batch seq\"]\n",
        "    kv_cache: KeyValueCache | None = None\n",
        "\n",
        "    def __getitem__(self, idx) -> \"Beams\":\n",
        "        '''Helpful function allowing you to take a slice of the beams object along the batch dimension.'''\n",
        "        return Beams(\n",
        "            self.model,\n",
        "            self.tokenizer,\n",
        "            self.logprob_sums[idx],\n",
        "            self.tokens[idx],\n",
        "            self.kv_cache[:, :, idx] if self.kv_cache is not None else None\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def logprobs_and_completions(self) -> list[tuple[float, str]]:\n",
        "        '''Returns self as a list of logprob sums and completions (useful for getting final output).'''\n",
        "        return [\n",
        "            (logprob_sum.item(), self.tokenizer.decode(tokens))\n",
        "            for (logprob_sum, tokens) in zip(self.logprob_sums, self.tokens)\n",
        "        ]\n",
        "\n",
        "\n",
        "    def generate(self, k: int, no_repeat_ngram_size: int | None = None) -> \"Beams\":\n",
        "        '''\n",
        "        Starting from the current set of beams (i.e. self.tokens) and returns a new set of `len(self.tokens) * k` beams,\n",
        "        containing the best `k` continuations for each of the original beams.\n",
        "\n",
        "        Optional argument `no_repeat_ngram_size` means your model won't generate any sequences with a repeating n-gram\n",
        "        of this length.\n",
        "        '''\n",
        "        # Get the output logprobs for the next token (for every sequence in current beams)\n",
        "        logprobs, kv_cache = self.model(self.tokens, self.kv_cache)\n",
        "        logprobs = logprobs[:, -1, :].log_softmax(-1)\n",
        "\n",
        "        # Get the top `toks_per_beam` tokens for each sequence\n",
        "        topk_logprobs, topk_tokenIDs = self.get_topk_non_repeating(logprobs, no_repeat_ngram_size, k=k)\n",
        "\n",
        "        # Add new logprobs & concat new tokens. When doing this, we need to add an extra `k` dimension since our current\n",
        "        # logprobs & tokens have shape (batch,) and (batch, seq), but our new ones both have shape (batch, k)\n",
        "        new_logprob_sums = einops.repeat(self.logprob_sums, \"b -> b k\", k=k) + topk_logprobs\n",
        "        new_tokens = t.concat([einops.repeat(self.tokens, \"b s -> b k s\", k=k), topk_tokenIDs.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "        return Beams(self.model, self.tokenizer, new_logprob_sums.flatten(), new_tokens.flatten(0, 1), new_kv_cache)\n",
        "\n",
        "\n",
        "    def filter(self, k: int) -> tuple[\"Beams\", \"Beams\"]:\n",
        "        '''\n",
        "        Returns:\n",
        "            best_beams: Beams\n",
        "                filtered version of self, containing all best `k` which are also not terminated.\n",
        "            early_terminations: Beams\n",
        "                filtered version of self, containing all best `k` which are also terminated.\n",
        "        '''\n",
        "        # Get the indices of top `k` beams\n",
        "        top_beam_indices = self.logprob_sums.topk(k=k, dim=0).indices.tolist()\n",
        "        # Get the indices of terminated sequences\n",
        "        new_tokens = self.tokens[:, -1]\n",
        "        terminated_indices = t.nonzero(new_tokens == self.tokenizer.eos_token_id)\n",
        "\n",
        "        # Get the indices of the `k` best sequences (some terminated, some not terminated)\n",
        "        best_continuing = [i for i in top_beam_indices if i not in terminated_indices]\n",
        "        best_terminated = [i for i in top_beam_indices if i in terminated_indices]\n",
        "\n",
        "        # Return the beam objects from these indices\n",
        "        return self[best_continuing], self[best_terminated]\n",
        "\n",
        "\n",
        "    def get_topk_non_repeating(\n",
        "        self,\n",
        "        logprobs: Float[Tensor, \"batch d_vocab\"],\n",
        "        no_repeat_ngram_size: int | None,\n",
        "        k: int,\n",
        "    ) -> tuple[Float[Tensor, \"k\"], Int[Tensor, \"k\"]]:\n",
        "        \"\"\"\n",
        "        logprobs:\n",
        "            tensor of the log-probs for the next token\n",
        "        no_repeat_ngram_size:\n",
        "            size of ngram to avoid repeating\n",
        "        k:\n",
        "            number of top logits to return, for each beam in our collection\n",
        "\n",
        "        Returns:\n",
        "            equivalent to the output of `logprobs.topk(dim=-1)`, but makes sure that no returned tokens would produce an\n",
        "            ngram of size  `no_repeat_ngram_size` which has already appeared in `self.tokens`.\n",
        "        \"\"\"\n",
        "        batch, seq_len = self.tokens.shape\n",
        "\n",
        "        # If completion isn't long enough for a repetition, or we have no restrictions, just return topk\n",
        "        if (no_repeat_ngram_size is not None) and (seq_len > no_repeat_ngram_size - 1):\n",
        "            # Otherwise, we need to check for ngram repetitions\n",
        "            # First, get the most recent `no_repeat_ngram_size-1` tokens\n",
        "            last_ngram_prefix = self.tokens[:, seq_len - (no_repeat_ngram_size - 1) :]\n",
        "            # Next, find all the tokens we're not allowed to generate, by checking all past ngrams for a match\n",
        "            for i in range(seq_len - (no_repeat_ngram_size - 1)):\n",
        "                ngrams = self.tokens[:, i : i + no_repeat_ngram_size]  # (batch, ngram)\n",
        "                ngrams_are_repeated = (ngrams[:, :-1] == last_ngram_prefix).all(-1)  # (batch,)\n",
        "                ngram_end_tokens = ngrams[:, [-1]]  # (batch, 1)\n",
        "                # Fill logprobs with neginf wherever the ngrams are repeated\n",
        "                logprobs[range(batch), ngram_end_tokens] = t.where(\n",
        "                    ngrams_are_repeated, -1.0e4, logprobs[range(batch), ngram_end_tokens]\n",
        "                )\n",
        "\n",
        "        # Finally, get our actual tokens\n",
        "        return logprobs.topk(k=k, dim=-1)\n",
        "\n",
        "    def print(self, title=\"Best completions\", max_print_chars=80) -> None:\n",
        "        '''\n",
        "        Prints out a set of sequences with their corresponding logitsums.\n",
        "        '''\n",
        "        if len(self.tokens) == 0:\n",
        "            return\n",
        "        table = Table(\"logitsum\", \"completion\", title=title)\n",
        "        for logprob_sum, tokens in zip(self.logprob_sums, self.tokens):\n",
        "            text = self.tokenizer.decode(tokens)\n",
        "            if len(repr(text)) > max_print_chars:\n",
        "                text = text[:int(0.3 * max_print_chars)] + \" ... \" + text[-int(0.7 * max_print_chars):]\n",
        "            table.add_row(f\"{logprob_sum:>8.3f}\", repr(text))\n",
        "        rprint(table)\n",
        "\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def beam_search(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        num_return_sequences: int,\n",
        "        num_beams: int,\n",
        "        max_new_tokens: int,\n",
        "        no_repeat_ngram_size: int | None = None,\n",
        "        kv_cache: KeyValueCache | None = None,\n",
        "    ) -> list[tuple[float, Tensor]]:\n",
        "        '''\n",
        "        Implements a beam search, by repeatedly performing the `generate` and `filter` steps (starting from the initial\n",
        "        prompt) until either of the two stopping criteria are met: (1) we've generated `max_new_tokens` tokens, or (2)\n",
        "        we've generated `num_returns_sequences` terminating sequences.\n",
        "        '''\n",
        "        assert num_return_sequences <= num_beams\n",
        "        self.model.eval()\n",
        "\n",
        "        tokens = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        final_logprobs_and_completions = []  # we add to this list as we get terminated beams\n",
        "        best_beams = Beams(self.model, self.tokenizer, t.tensor([0.0]).to(device), tokens)  # start with just 1 beam\n",
        "\n",
        "        for _ in tqdm(range(max_new_tokens)):\n",
        "            # Generate & filter beams\n",
        "            best_beams = best_beams.generate(k=num_beams, no_repeat_ngram_size=no_repeat_ngram_size)\n",
        "            best_beams, best_beams_terminated = best_beams.filter(k=num_beams)\n",
        "\n",
        "            # Add terminated beams to our list, and return early if we have enough\n",
        "            final_logprobs_and_completions.extend(best_beams_terminated.logprobs_and_completions)\n",
        "            if len(final_logprobs_and_completions) >= num_return_sequences:\n",
        "                return final_logprobs_and_completions[:num_return_sequences]\n",
        "\n",
        "        # Return terminated beams plus the best ongoing beams of length `orig_len + max_new_tokens`\n",
        "        final_logprobs_and_completions.extend(best_beams.logprobs_and_completions)\n",
        "        return final_logprobs_and_completions[:num_return_sequences]\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Code to verify that the same output is being produced by cache and no-cache versions (and to compare speeds)</summary>\n",
        "\n",
        "```python\n",
        "prompt = \"For you, the day Bison graced your village was the most important day of your life. But for me, it was\"\n",
        "orig_len = len(tokenizer.encode(prompt))\n",
        "\n",
        "beam_search_kwargs = dict(\n",
        "    prompt=prompt,\n",
        "    num_return_sequences=3,\n",
        "    num_beams=20,\n",
        "    max_new_tokens=60,\n",
        "    no_repeat_ngram_size=2,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "# Run the noncached version\n",
        "t0 = time.time()\n",
        "final_logitsums_and_completions = sampler.beam_search(**beam_search_kwargs)\n",
        "logprob_sum, text = final_logitsums_and_completions[0]\n",
        "avg_logprob_as_prob = t.tensor(logprob_sum / (len(tokenizer.encode(text)) - orig_len)).exp().item()\n",
        "print(f\"Time (without cache): {time.time() - t0:.2f} seconds\")\n",
        "print(f\"Avg logprob (expressed as a probability) = {avg_logprob_as_prob:.3f}\")\n",
        "rprint(f\"Output:\\n\\n[bold dark_orange]{text}[/]\\n\\n\")\n",
        "\n",
        "# Run the cached version\n",
        "t0 = time.time()\n",
        "beam_search_kwargs[\"kv_cache\"] = KeyValueCache.new_empty(model.cfg)\n",
        "final_logitsums_and_completions = sampler.beam_search(**beam_search_kwargs)\n",
        "logprob_sum, text_with_cache = final_logitsums_and_completions[0]\n",
        "avg_logprob_as_prob = t.tensor(logprob_sum / (len(tokenizer.encode(text)) - orig_len)).exp().item()\n",
        "print(f\"Time (with cache): {time.time() - t0:.2f} seconds\")\n",
        "print(f\"Avg logprob (as probability) = {avg_logprob_as_prob:.3f}\", end=\"\")\n",
        "rprint(f\"Output:\\n\\n[bold dark_orange]{text_with_cache}[/]\\n\\n\")\n",
        "\n",
        "# Check they are the same\n",
        "assert text == text_with_cache, \"Your outputs are different, meaning you've probably made a mistake in your cache implementation.\"\n",
        "print(\"Tests passed!\")\n",
        "```\n",
        "\n",
        "</details>"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bd34097c7e1f44f98b4d9676ce4d8f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3b56bd754794086a2d0df6fefe51213",
              "IPY_MODEL_777bcd125ec64cc0aa4c2c4401442abd",
              "IPY_MODEL_f2011c34faa3424bb5258803d801bbcd"
            ],
            "layout": "IPY_MODEL_50d4e18241c94094802473aecca76540"
          }
        },
        "f3b56bd754794086a2d0df6fefe51213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39fa5aa5df934cdc826ba753d5b171a0",
            "placeholder": "​",
            "style": "IPY_MODEL_a22b2453f95c4cf6abd1361ca86430cf",
            "value": "config.json: 100%"
          }
        },
        "777bcd125ec64cc0aa4c2c4401442abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_272d8410497a47db8f6ed6c6913a49f8",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f164cb24ed94c968274e85f2ddc07d6",
            "value": 665
          }
        },
        "f2011c34faa3424bb5258803d801bbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3d3f2fc8f6f4b85bd2d8058506c3f9f",
            "placeholder": "​",
            "style": "IPY_MODEL_ea2f641c5f534744a36ba622e8e9a6f3",
            "value": " 665/665 [00:00&lt;00:00, 113kB/s]"
          }
        },
        "50d4e18241c94094802473aecca76540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39fa5aa5df934cdc826ba753d5b171a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a22b2453f95c4cf6abd1361ca86430cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "272d8410497a47db8f6ed6c6913a49f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f164cb24ed94c968274e85f2ddc07d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3d3f2fc8f6f4b85bd2d8058506c3f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea2f641c5f534744a36ba622e8e9a6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af63e596459f45e0b0bfbf23b6b4328c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3807997e73a845948c60e7f22e5ad72d",
              "IPY_MODEL_baba64560f214107bc58fc18fe4f029b",
              "IPY_MODEL_2a9c9a8aee4a4dfcaa37f5697da5e9a8"
            ],
            "layout": "IPY_MODEL_46c6e4121d2b45dcb832314a5d2090f2"
          }
        },
        "3807997e73a845948c60e7f22e5ad72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be06f5e89cb64217a87a3afab42a8040",
            "placeholder": "​",
            "style": "IPY_MODEL_15e6c1af22a04211b5a627dfc90999f2",
            "value": "model.safetensors: 100%"
          }
        },
        "baba64560f214107bc58fc18fe4f029b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1941756833c44975a9ce00fdd6e4882b",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c2eb2c1da9d4e11aeaf8675e39a068f",
            "value": 548105171
          }
        },
        "2a9c9a8aee4a4dfcaa37f5697da5e9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1796509e245648f792c2018a27c7637f",
            "placeholder": "​",
            "style": "IPY_MODEL_ca0fa30e53c14e35bda326b0a0718974",
            "value": " 548M/548M [00:01&lt;00:00, 486MB/s]"
          }
        },
        "46c6e4121d2b45dcb832314a5d2090f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be06f5e89cb64217a87a3afab42a8040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15e6c1af22a04211b5a627dfc90999f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1941756833c44975a9ce00fdd6e4882b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c2eb2c1da9d4e11aeaf8675e39a068f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1796509e245648f792c2018a27c7637f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca0fa30e53c14e35bda326b0a0718974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd02f76ae2d4bb5a16208aaa0771f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cce6aaefee26498bae26caab88a8f1d1",
              "IPY_MODEL_e4a4ddc71a88462da0aac1467f55572c",
              "IPY_MODEL_d707315f104b47a69268f10be6a51c22"
            ],
            "layout": "IPY_MODEL_d3f6d60f1ef04d7faf074d0b31126195"
          }
        },
        "cce6aaefee26498bae26caab88a8f1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21507ec5fb8c4a1fbc9441d62f62b602",
            "placeholder": "​",
            "style": "IPY_MODEL_74096fb579dc45ec9c170f7255cfcb30",
            "value": "generation_config.json: 100%"
          }
        },
        "e4a4ddc71a88462da0aac1467f55572c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b5b68b99dfb4e089dc5b418c0e338c6",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3214494b92d45d5b337c89fb1e721d9",
            "value": 124
          }
        },
        "d707315f104b47a69268f10be6a51c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49455aecfcd545bcb3c7ec8daa0933da",
            "placeholder": "​",
            "style": "IPY_MODEL_0427733a44564250943e2bf8a8ed0a1a",
            "value": " 124/124 [00:00&lt;00:00, 20.9kB/s]"
          }
        },
        "d3f6d60f1ef04d7faf074d0b31126195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21507ec5fb8c4a1fbc9441d62f62b602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74096fb579dc45ec9c170f7255cfcb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b5b68b99dfb4e089dc5b418c0e338c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3214494b92d45d5b337c89fb1e721d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49455aecfcd545bcb3c7ec8daa0933da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0427733a44564250943e2bf8a8ed0a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "901c2c953d5a4fdf9e92e713f1f2212a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11187632b06547399c14e536623d8a5d",
              "IPY_MODEL_c5017760ba1c4fc3bdda265257bf5d34",
              "IPY_MODEL_b9e3d66ba20143568ef7c3fc1b86d23f"
            ],
            "layout": "IPY_MODEL_b38d773c70994cc18cbe8389fa647fcc"
          }
        },
        "11187632b06547399c14e536623d8a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_896c745cf1fb414c8eaf1a85b65528dc",
            "placeholder": "​",
            "style": "IPY_MODEL_58ed304c2bc1445e8966dd5d315947a0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c5017760ba1c4fc3bdda265257bf5d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e5ab8e607144e1499aa3a7f97c7895f",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76ab5334a61440b888107e8a122ed1bf",
            "value": 26
          }
        },
        "b9e3d66ba20143568ef7c3fc1b86d23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dfeb227fc784479bff29705c507e295",
            "placeholder": "​",
            "style": "IPY_MODEL_2a1881400874421d82ff8e32c56bba36",
            "value": " 26.0/26.0 [00:00&lt;00:00, 5.04kB/s]"
          }
        },
        "b38d773c70994cc18cbe8389fa647fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896c745cf1fb414c8eaf1a85b65528dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58ed304c2bc1445e8966dd5d315947a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e5ab8e607144e1499aa3a7f97c7895f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ab5334a61440b888107e8a122ed1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9dfeb227fc784479bff29705c507e295": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a1881400874421d82ff8e32c56bba36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa8c668513a249f88b5e974421dfb4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3de1a626f3e94c7ba42aa097b522816d",
              "IPY_MODEL_23c34a8176ef4a9facbc1ff173970776",
              "IPY_MODEL_69994edc2bda483084748e1bde6f89f9"
            ],
            "layout": "IPY_MODEL_75909de0d1ad4b5885b55c330f7a68ca"
          }
        },
        "3de1a626f3e94c7ba42aa097b522816d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ae72e10be834e879bf62b46269a1194",
            "placeholder": "​",
            "style": "IPY_MODEL_7c33e871ee9240a5a5b6509c22b014c0",
            "value": "vocab.json: 100%"
          }
        },
        "23c34a8176ef4a9facbc1ff173970776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b9d354cdbb3445e97f9ded5b959cac7",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3116caed58134e72a8eb7481742cd7b1",
            "value": 1042301
          }
        },
        "69994edc2bda483084748e1bde6f89f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_798713949601459e8bc5adf3d6577e26",
            "placeholder": "​",
            "style": "IPY_MODEL_30c17afc26dd41a694dc6e905a1a36ec",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 5.34MB/s]"
          }
        },
        "75909de0d1ad4b5885b55c330f7a68ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ae72e10be834e879bf62b46269a1194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c33e871ee9240a5a5b6509c22b014c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b9d354cdbb3445e97f9ded5b959cac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3116caed58134e72a8eb7481742cd7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "798713949601459e8bc5adf3d6577e26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c17afc26dd41a694dc6e905a1a36ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb81a0de815742248bb2e7780a58ec87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_073b0c9473c847daa80fbac111b2724e",
              "IPY_MODEL_c9e938b17d864088bf2c1bdfd27ae0df",
              "IPY_MODEL_938f758f859648babd178745435ccdcf"
            ],
            "layout": "IPY_MODEL_bc6e384601f84921a83c7bfba432c350"
          }
        },
        "073b0c9473c847daa80fbac111b2724e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c97e3df9d7457aaef2ca9baa9bdc2b",
            "placeholder": "​",
            "style": "IPY_MODEL_08bb11ac87f241318786014e28eeb4fc",
            "value": "merges.txt: 100%"
          }
        },
        "c9e938b17d864088bf2c1bdfd27ae0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fd7db5fa768425490f09dfe44a2816b",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d72e7c3480684d4dadf0637d5755ad3c",
            "value": 456318
          }
        },
        "938f758f859648babd178745435ccdcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8ee9c7b8ec240ecb0320e2900660d6c",
            "placeholder": "​",
            "style": "IPY_MODEL_3f05504c5e5a4ff6b21ded0ee431d287",
            "value": " 456k/456k [00:00&lt;00:00, 3.68MB/s]"
          }
        },
        "bc6e384601f84921a83c7bfba432c350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c97e3df9d7457aaef2ca9baa9bdc2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08bb11ac87f241318786014e28eeb4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fd7db5fa768425490f09dfe44a2816b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d72e7c3480684d4dadf0637d5755ad3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8ee9c7b8ec240ecb0320e2900660d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f05504c5e5a4ff6b21ded0ee431d287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93d1163d036043d9b5f2d04f8c6c9fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d782a3f1b092467d9db7e718a54d8d8d",
              "IPY_MODEL_c7f170701f5444afb719e71625f1d021",
              "IPY_MODEL_64d81c414fb4413ca4c8a8d97fdd02fe"
            ],
            "layout": "IPY_MODEL_974676de89244458b320004e150a6b2d"
          }
        },
        "d782a3f1b092467d9db7e718a54d8d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49300a6622814723a327de8ec48ee4a7",
            "placeholder": "​",
            "style": "IPY_MODEL_fa3ec4af481648118660c7f2904c9e38",
            "value": "tokenizer.json: 100%"
          }
        },
        "c7f170701f5444afb719e71625f1d021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cc3cf9884d547a393296c748c194edd",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b1c6ec1634a493994fa45020a11a03f",
            "value": 1355256
          }
        },
        "64d81c414fb4413ca4c8a8d97fdd02fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4ef574c56574b148e6166c65f2dd99e",
            "placeholder": "​",
            "style": "IPY_MODEL_f8f8eafa80b047739b927abec73826f8",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 5.47MB/s]"
          }
        },
        "974676de89244458b320004e150a6b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49300a6622814723a327de8ec48ee4a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa3ec4af481648118660c7f2904c9e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cc3cf9884d547a393296c748c194edd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b1c6ec1634a493994fa45020a11a03f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4ef574c56574b148e6166c65f2dd99e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8f8eafa80b047739b927abec73826f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f9b9a223838496f90943e8e1202950d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e748dd8746b24435be51ed15d7395a09",
              "IPY_MODEL_85ef70b4b7f6489bb76862b16698af25",
              "IPY_MODEL_5fe8afeede214812bf2cbb353ed1ecad"
            ],
            "layout": "IPY_MODEL_8c44b873db704efeaa2d931ffc82bfc4"
          }
        },
        "e748dd8746b24435be51ed15d7395a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92877c7c0e849d381a43a21faa69880",
            "placeholder": "​",
            "style": "IPY_MODEL_bb7d6301850548bfa3a2f55f00215cf3",
            "value": " 14%"
          }
        },
        "85ef70b4b7f6489bb76862b16698af25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97a04559b97d409db46bab56e3d37e07",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_547c38c6c72f4101b17a58b5b4341afb",
            "value": 14
          }
        },
        "5fe8afeede214812bf2cbb353ed1ecad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f89f839786949059f0a517c58c80b8b",
            "placeholder": "​",
            "style": "IPY_MODEL_97cb68c2b4834aa5a4a23d80dc07aba2",
            "value": " 14/100 [00:03&lt;00:19,  4.32it/s]"
          }
        },
        "8c44b873db704efeaa2d931ffc82bfc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e92877c7c0e849d381a43a21faa69880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb7d6301850548bfa3a2f55f00215cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97a04559b97d409db46bab56e3d37e07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "547c38c6c72f4101b17a58b5b4341afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f89f839786949059f0a517c58c80b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97cb68c2b4834aa5a4a23d80dc07aba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9a2c1033bf347168dc963aa79e242e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12290557d87e46cd89691741b5c51e17",
              "IPY_MODEL_500a043a340041eaae926f3f542e45cd",
              "IPY_MODEL_1b2d25baecaf48ad85b9db65ce6ea88e"
            ],
            "layout": "IPY_MODEL_b4f6b696f3ba4309a20d7bcd513d1c5e"
          }
        },
        "12290557d87e46cd89691741b5c51e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9027d8c524b43a18f04bcb31a6dd2f1",
            "placeholder": "​",
            "style": "IPY_MODEL_1d8b805c03bc4990919671cd4efa786b",
            "value": "README.md: "
          }
        },
        "500a043a340041eaae926f3f542e45cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c82621277b9e4e92a7fbe056f1919311",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ea8e4d9e5b94bf887a933a65c17c668",
            "value": 1
          }
        },
        "1b2d25baecaf48ad85b9db65ce6ea88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65ac65db76a04258a204819293bf6d39",
            "placeholder": "​",
            "style": "IPY_MODEL_b8aaaedbd1304f83be393aecc6838774",
            "value": " 1.06k/? [00:00&lt;00:00, 177kB/s]"
          }
        },
        "b4f6b696f3ba4309a20d7bcd513d1c5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9027d8c524b43a18f04bcb31a6dd2f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8b805c03bc4990919671cd4efa786b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c82621277b9e4e92a7fbe056f1919311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7ea8e4d9e5b94bf887a933a65c17c668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65ac65db76a04258a204819293bf6d39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8aaaedbd1304f83be393aecc6838774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ff57e67cba5412da0ef49a19d7596ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2b16b89b045433bb30ab0f7a8393024",
              "IPY_MODEL_4d78487411d24c29aa8f2885a87e6893",
              "IPY_MODEL_8a6acc656be84d8ba629a0f6ef62c223"
            ],
            "layout": "IPY_MODEL_b81df613d5b44df2b7ec58c0d93a7f9c"
          }
        },
        "c2b16b89b045433bb30ab0f7a8393024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8393ccc2a3c84d33a26b5b9cd1c59c95",
            "placeholder": "​",
            "style": "IPY_MODEL_6d37d39fde674e3780df37a7b870cb74",
            "value": "data/train-00000-of-00004-2d5a1467fff108(…): 100%"
          }
        },
        "4d78487411d24c29aa8f2885a87e6893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e238138cc20543bfac5cc4ac857ab60c",
            "max": 248731111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d235d1ec91dc4e8084dbfe7a2bc770ae",
            "value": 248731111
          }
        },
        "8a6acc656be84d8ba629a0f6ef62c223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dcc2a93f6a94b3eb18ce661908a9681",
            "placeholder": "​",
            "style": "IPY_MODEL_32737744ec2347a8b096cd932edc1424",
            "value": " 249M/249M [00:02&lt;00:00, 220MB/s]"
          }
        },
        "b81df613d5b44df2b7ec58c0d93a7f9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8393ccc2a3c84d33a26b5b9cd1c59c95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d37d39fde674e3780df37a7b870cb74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e238138cc20543bfac5cc4ac857ab60c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d235d1ec91dc4e8084dbfe7a2bc770ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dcc2a93f6a94b3eb18ce661908a9681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32737744ec2347a8b096cd932edc1424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08486fa5a5084227b4bb1cc64de08143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c5f16fade704383a835ea1d41def3a6",
              "IPY_MODEL_b7b4f504ff024157a91efd6d262f8d14",
              "IPY_MODEL_67e5f2ec80d74fcb8f3008e302e82cf7"
            ],
            "layout": "IPY_MODEL_e12a3f7338284c06adf444096e82784a"
          }
        },
        "4c5f16fade704383a835ea1d41def3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93d754c40f7446988a3e029faa148394",
            "placeholder": "​",
            "style": "IPY_MODEL_83b9ba7b7c0848fa96fa56d4aa075405",
            "value": "data/train-00001-of-00004-5852b56a2bd28f(…): 100%"
          }
        },
        "b7b4f504ff024157a91efd6d262f8d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f64ade0c64ce47d9997e366a716fff1f",
            "max": 248171980,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77240817622e4a06aaee74d39ac3727d",
            "value": 248171980
          }
        },
        "67e5f2ec80d74fcb8f3008e302e82cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e64f643b57814d5790d1058564c14676",
            "placeholder": "​",
            "style": "IPY_MODEL_ea4d8da59a5e485ab9db53d484d193dc",
            "value": " 248M/248M [00:01&lt;00:00, 135MB/s]"
          }
        },
        "e12a3f7338284c06adf444096e82784a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d754c40f7446988a3e029faa148394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b9ba7b7c0848fa96fa56d4aa075405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f64ade0c64ce47d9997e366a716fff1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77240817622e4a06aaee74d39ac3727d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e64f643b57814d5790d1058564c14676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea4d8da59a5e485ab9db53d484d193dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f1282f3ce0d465dbb813213e137df68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa74dcd936a3459784fa123412218dff",
              "IPY_MODEL_5fc6587f8b184e7c9080e7ceb73e7a2d",
              "IPY_MODEL_079865ba91764d8da58fe879820c8596"
            ],
            "layout": "IPY_MODEL_b513e45f79af4532bc9671a58553419a"
          }
        },
        "fa74dcd936a3459784fa123412218dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d033f917dff646aaa72109e5400c8fdb",
            "placeholder": "​",
            "style": "IPY_MODEL_9acb74bd867b4543bce47a6a047a0335",
            "value": "data/train-00002-of-00004-a26307300439e9(…): 100%"
          }
        },
        "5fc6587f8b184e7c9080e7ceb73e7a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ee041a16b6140eda469fe31795dde06",
            "max": 245894874,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40da8d6071864fe2aa6c518389208035",
            "value": 245894874
          }
        },
        "079865ba91764d8da58fe879820c8596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a27e93b838174694bb1aac229d9f84c9",
            "placeholder": "​",
            "style": "IPY_MODEL_86007cac56a94f85b05add6e354c6605",
            "value": " 246M/246M [00:01&lt;00:00, 199MB/s]"
          }
        },
        "b513e45f79af4532bc9671a58553419a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d033f917dff646aaa72109e5400c8fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9acb74bd867b4543bce47a6a047a0335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ee041a16b6140eda469fe31795dde06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40da8d6071864fe2aa6c518389208035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a27e93b838174694bb1aac229d9f84c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86007cac56a94f85b05add6e354c6605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f9f292b819b41919d88030b13c8e7ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83153d126e414172b945fb4e75723072",
              "IPY_MODEL_edd311bcf3d74b9a8f683aeeb42d4902",
              "IPY_MODEL_50504a1123f04682bc6329a96b2d4f01"
            ],
            "layout": "IPY_MODEL_3fca0bfa138e49cbadb6ef1bbba8ba33"
          }
        },
        "83153d126e414172b945fb4e75723072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3e791ffbb3145e18de24a8db7b4fb5c",
            "placeholder": "​",
            "style": "IPY_MODEL_561a458a1369458e9c5c0f54354a3ddf",
            "value": "data/train-00003-of-00004-d243063613e5a0(…): 100%"
          }
        },
        "edd311bcf3d74b9a8f683aeeb42d4902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e995b4a315714e9a8b77a6d9b7cd6d60",
            "max": 247988350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99ff3e14fa6d423390a4a043bf2c20a8",
            "value": 247988350
          }
        },
        "50504a1123f04682bc6329a96b2d4f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9e0f7b9c97f41cebfcef918367a9b82",
            "placeholder": "​",
            "style": "IPY_MODEL_b5b78d015f684ee3ae1f6cbafd45e715",
            "value": " 248M/248M [00:01&lt;00:00, 204MB/s]"
          }
        },
        "3fca0bfa138e49cbadb6ef1bbba8ba33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3e791ffbb3145e18de24a8db7b4fb5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "561a458a1369458e9c5c0f54354a3ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e995b4a315714e9a8b77a6d9b7cd6d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99ff3e14fa6d423390a4a043bf2c20a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9e0f7b9c97f41cebfcef918367a9b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5b78d015f684ee3ae1f6cbafd45e715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e683611b08d84671b99e430607c8fb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfcb0dbd9c2a4454832ed30ebe2936be",
              "IPY_MODEL_181593149f724af18a6dbcf35e0c9cdc",
              "IPY_MODEL_c0d470fdd4fe425889637c0afc14c598"
            ],
            "layout": "IPY_MODEL_a37a0424d899432d9d2692399e061bf6"
          }
        },
        "bfcb0dbd9c2a4454832ed30ebe2936be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b21c797e102491fa3063c7ffed9c1eb",
            "placeholder": "​",
            "style": "IPY_MODEL_0b31b8fa775a4a8095d7ed5970de120b",
            "value": "data/validation-00000-of-00001-869c898b5(…): 100%"
          }
        },
        "181593149f724af18a6dbcf35e0c9cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd9f97081604469180c4180babab68fd",
            "max": 9989127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34bcf85f42524a948de31387eb543faf",
            "value": 9989127
          }
        },
        "c0d470fdd4fe425889637c0afc14c598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ae4cfc8f3704862aef61b2bce8d18f3",
            "placeholder": "​",
            "style": "IPY_MODEL_44fdf7969ffa4ae6b490d661dca62528",
            "value": " 9.99M/9.99M [00:01&lt;00:00, 8.75MB/s]"
          }
        },
        "a37a0424d899432d9d2692399e061bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b21c797e102491fa3063c7ffed9c1eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b31b8fa775a4a8095d7ed5970de120b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd9f97081604469180c4180babab68fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34bcf85f42524a948de31387eb543faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ae4cfc8f3704862aef61b2bce8d18f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44fdf7969ffa4ae6b490d661dca62528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b49833d17904646871a3208491c13f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2235adcaf21a45799a84b76848936bfb",
              "IPY_MODEL_2caa3ae8889e4b5ea44416612cd7eea6",
              "IPY_MODEL_07b99c26f2cb4a95b702cac9de086f08"
            ],
            "layout": "IPY_MODEL_be48e018bc4e413f8cb94d869985842b"
          }
        },
        "2235adcaf21a45799a84b76848936bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d78697af08c846b191cb9717db7a1aa7",
            "placeholder": "​",
            "style": "IPY_MODEL_6635123549244e538d5886eccb466897",
            "value": "Generating train split: 100%"
          }
        },
        "2caa3ae8889e4b5ea44416612cd7eea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf490a00c9f042748ac75ba0eb010160",
            "max": 2119719,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6409ad5596b44d349cea055eed0c0133",
            "value": 2119719
          }
        },
        "07b99c26f2cb4a95b702cac9de086f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_514cefb6c9134705b9aa6e6a0fdd40be",
            "placeholder": "​",
            "style": "IPY_MODEL_c728ec00abca453eac61b34f8db0ef61",
            "value": " 2119719/2119719 [00:14&lt;00:00, 93681.01 examples/s]"
          }
        },
        "be48e018bc4e413f8cb94d869985842b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d78697af08c846b191cb9717db7a1aa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6635123549244e538d5886eccb466897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf490a00c9f042748ac75ba0eb010160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6409ad5596b44d349cea055eed0c0133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "514cefb6c9134705b9aa6e6a0fdd40be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c728ec00abca453eac61b34f8db0ef61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80e949c110a94ec3aa1192f4337b29d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fdf9d09f3174808a54de38590050828",
              "IPY_MODEL_62e2cf0a515147af8d097ef77912f046",
              "IPY_MODEL_46322ff418834106924f4c8f691b0b14"
            ],
            "layout": "IPY_MODEL_0950a12d6a184ce1a5498d2a8503fc2c"
          }
        },
        "6fdf9d09f3174808a54de38590050828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efb4a9ce487b4cf882d3e629c657fba2",
            "placeholder": "​",
            "style": "IPY_MODEL_43c8882d2def444f8be3363a55ce091c",
            "value": "Generating validation split: 100%"
          }
        },
        "62e2cf0a515147af8d097ef77912f046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53929df2aa914af282e745c646efd01a",
            "max": 21990,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_caa2a574d07e4064a40a40587b5dd899",
            "value": 21990
          }
        },
        "46322ff418834106924f4c8f691b0b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f765c301eaa4996a5e0d77de0ec5c14",
            "placeholder": "​",
            "style": "IPY_MODEL_564715d93c974c728d2f5390b22ea1dc",
            "value": " 21990/21990 [00:00&lt;00:00, 270284.65 examples/s]"
          }
        },
        "0950a12d6a184ce1a5498d2a8503fc2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efb4a9ce487b4cf882d3e629c657fba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43c8882d2def444f8be3363a55ce091c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53929df2aa914af282e745c646efd01a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caa2a574d07e4064a40a40587b5dd899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f765c301eaa4996a5e0d77de0ec5c14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "564715d93c974c728d2f5390b22ea1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6eaf1782ad7048c9aabca13fda294e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_036d051b89ef4894b77b237424f68e4a",
              "IPY_MODEL_4638146b273546d7a5d68f0a7e3dfc14",
              "IPY_MODEL_7d98385d553f4a21b36213007e721cf7"
            ],
            "layout": "IPY_MODEL_cb971bf2e1164cb3b4e6c510a1f6469c"
          }
        },
        "036d051b89ef4894b77b237424f68e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d877b1875744940b68c59e5aa6b2c54",
            "placeholder": "​",
            "style": "IPY_MODEL_f570c20c3eae40fba48d4c939b769de5",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "4638146b273546d7a5d68f0a7e3dfc14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26480bfcf03a4f36aea6bf4f54e0b128",
            "max": 2119719,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61cdd319bdce4057b1cac9c24233de9b",
            "value": 2119719
          }
        },
        "7d98385d553f4a21b36213007e721cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae1faf1f87c24d229749599e99a9f48c",
            "placeholder": "​",
            "style": "IPY_MODEL_926e1efedbcb41c385f773729a985abe",
            "value": " 2119719/2119719 [04:30&lt;00:00, 2040.46 examples/s]"
          }
        },
        "cb971bf2e1164cb3b4e6c510a1f6469c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d877b1875744940b68c59e5aa6b2c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f570c20c3eae40fba48d4c939b769de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26480bfcf03a4f36aea6bf4f54e0b128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61cdd319bdce4057b1cac9c24233de9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae1faf1f87c24d229749599e99a9f48c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "926e1efedbcb41c385f773729a985abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96f679f4074d4be4b1ff8c655dc5184b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae9a5fb2dd02432fa564a2cffc750ac5",
              "IPY_MODEL_c7b78cdeac994b38b1abde1f436c75e7",
              "IPY_MODEL_5b1ba200c5f842d4aba6acbf7567672d"
            ],
            "layout": "IPY_MODEL_9f776b172f8340a88b28d97acb3bd455"
          }
        },
        "ae9a5fb2dd02432fa564a2cffc750ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ecfd3ec80164e09a11ac721e4f52033",
            "placeholder": "​",
            "style": "IPY_MODEL_967298b879554579a84803ce773ac023",
            "value": "Epoch 1, loss: 7.175, accuracy: nan:   1%"
          }
        },
        "c7b78cdeac994b38b1abde1f436c75e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b91b270bd2144e7bc7e43c1080e46a5",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e936eb45b6d0409d83705d1ac1c07392",
            "value": 71
          }
        },
        "5b1ba200c5f842d4aba6acbf7567672d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55ee51101fcc41e7974d4b351dfb886e",
            "placeholder": "​",
            "style": "IPY_MODEL_d4204f5c79144963a03a6d560922928f",
            "value": " 71/5000 [02:15&lt;2:37:02,  1.91s/it]"
          }
        },
        "9f776b172f8340a88b28d97acb3bd455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ecfd3ec80164e09a11ac721e4f52033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "967298b879554579a84803ce773ac023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b91b270bd2144e7bc7e43c1080e46a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e936eb45b6d0409d83705d1ac1c07392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55ee51101fcc41e7974d4b351dfb886e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4204f5c79144963a03a6d560922928f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}